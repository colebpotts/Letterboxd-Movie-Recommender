{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "334e0b06",
   "metadata": {
    "id": "334e0b06"
   },
   "source": [
    "# Capstone Project: I want to watch a movie...\n",
    "**Author:** Cole Beevor-Potts\n",
    "\n",
    "**Current Date:** December 11th 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd0b9d9",
   "metadata": {
    "id": "0fd0b9d9"
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "   - [Data Dictionary](#Data-Dictionary)\n",
    "\n",
    "2. [Pre-Processing and Vectorization](#Pre-Processing-and-Vectorization)\n",
    "   - [TF-IDF Vectorizer](#TF-IDF-Vectorizer)\n",
    "   - [Genres - MultiLabel Binarizer](#Genres-MultiLabel-Binarizer)\n",
    "   - [Pre-Processing Summary](#Pre-Processing-Summary)\n",
    "\n",
    "3. [Initial Modelling](#Initial-Modelling)\n",
    "   - [Initial Modelling Insights](#Initial-Modelling-Insights)\n",
    "   - [Initial Modelling Conclusion](#Initial-Modelling-Conclusion)\n",
    "\n",
    "4. [Hugging Face NLP Transformer](#Hugging-Face-NLP-Transformer)\n",
    "   - [BERT Text Embeddings with Hugging Face](#BERT-Text-Embeddings-with-Hugging-Face)\n",
    "     - [Pre-Processing for our Model](#Pre-Processing-for-our-Model)\n",
    "     - [Modelling with BERT Embeddings](#Modelling-with-BERT-Embeddings)\n",
    "     - [Qualitative Evaluation on BERT Model](#Qualitative-Evaluation-on-BERT-Model)\n",
    "     - [Insights from BERT Embedding Model](#Insights-from-BERT-Embedding-Model)\n",
    "   - [Modelling with BERT Embeddings and Numerical Features](#Modelling-with-BERT-Embeddings-and-Numerical-Features)\n",
    "     - [Evaluations for BERT & Numerical Columns](#Evaluations-for-BERT-&-Numerical-Columns)\n",
    "     - [Hugging Face Content Recommender Insights](#Hugging-Face-Content-Recommender-Insights)\n",
    "\n",
    "5. [GPT Based Model](#GPT-Based-Model)\n",
    "   - [Modelling with GPT](#Modelling-with-GPT)\n",
    "   - [GPT Evaluation](#GPT-Evaluation)\n",
    "\n",
    "6. [Content Based Recommendation Conclusion](#Content-Based-Recommendation-Conclusion)\n",
    "\n",
    "7. [Next Steps](#Next-Steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f4b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41fb22b-f5c9-4ed5-9204-a54bd8a74196",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome back!\n",
    "\n",
    "This workbook will be step 2 of my Movie Reccomender System. So far we have done some early EDA and processing of our data.\n",
    "\n",
    "In this workbook we will be picking back up where we left off and getting ready to do the **Content** side of our reccomendation system.\n",
    "\n",
    "We will looking at doing natural language processing (NLP) on movie decription with a TF_IDF vectorizer apporach, as well as with a deep learning appraoch using Hugging Face.\n",
    "\n",
    "The goal for this workbook is to take a movie and find the most similar movie we can. \n",
    "\n",
    "Lets dive in! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcff5d0-b5ff-4dfe-a334-9eab627507b4",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "| Column             | Data Type   | Non-Null Count | Description                                           |\n",
    "|--------------------|-------------|----------------|-------------------------------------------------------|\n",
    "| _id                | Object      | 5061          | Global unique ID for the movie                        |\n",
    "| genres             | Object      | 5061          | Array of associated movie genres                      |\n",
    "| movie_id           | Object      | 5061          | Letterboxd movie ID                                   |\n",
    "| original_language  | Object      | 5061          | Original language of the movie (from TMDB)             |\n",
    "| overview           | Object      | 5061          | Description of the movie (from TMDB)                  |\n",
    "| popularity         | Float64     | 5061          | Numeric popularity score of the movie (from TMDB)      |\n",
    "| runtime            | Float64     | 5061          | Duration of the movie in minutes                      |\n",
    "| year_released      | Float64     | 5061          | Year when the movie was released                      |\n",
    "| avg_rating         | Float64     | 5061          | Average rating for this movie within the dataset      |\n",
    "| rating_count       | Int64       | 5061          | Number of ratings for a particular movie within this dataset |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab520a-b5d8-4ec4-9065-6a1f51732c55",
   "metadata": {},
   "source": [
    "# Pre-Processing & Vectorization\n",
    "\n",
    "Based on the data we have currently we are going to need to leverage our overview column, which contains a description of a movie. This will be a chance to see how much we can get out of NLP for this project.\n",
    "\n",
    "We will vectorize the overview and prepare to test for similarity between movies based on their description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec7e5ac-2230-44e9-bacf-6dfd727ef79a",
   "metadata": {},
   "source": [
    "Lets re-load our data from the csv we saved.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fb41862-9483-4dd2-a5e7-dff8095a3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movies_data_content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e9c8fcd-383d-452e-8940-2e4ecbcfe09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fc85ff26758f696344ad07f</td>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>en</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fc85ff26758f696344aceeb</td>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>en</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fc85ff26758f696344acf29</td>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>en</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5fc85ff26758f696344ad019</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>en</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fc85ff26758f696344ad100</td>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>en</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5fc85ff26758f696344ad07f   \n",
       "1  5fc85ff26758f696344aceeb   \n",
       "2  5fc85ff26758f696344acf29   \n",
       "3  5fc85ff26758f696344ad019   \n",
       "4  5fc85ff26758f696344ad100   \n",
       "\n",
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id original_language  \\\n",
       "0  house-at-the-end-of-the-street                en   \n",
       "1          green-street-hooligans                en   \n",
       "2           beverly-hills-cop-iii                en   \n",
       "3                     bad-boys-ii                en   \n",
       "4                    a-single-man                en   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  \n",
       "0         2012.0    3.880987           689  \n",
       "1         2005.0    5.953771           411  \n",
       "2         1994.0    4.492424           528  \n",
       "3         2003.0    6.021593          1343  \n",
       "4         2009.0    7.660256          1404  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d82bbe-5e89-402f-b3fa-845a4bd7e757",
   "metadata": {},
   "source": [
    "We will need to convert all of our columns we want to use to numeric in order to prepare for modelling.\n",
    "\n",
    "## TF-IDF Vectorizer\n",
    "We will use TF-IDF Vectorizer initially as it does a good job handling common word occurences and more unique occurances simultanesously. \n",
    "\n",
    "Note: We know we already dropped all movies with nulls in the overview column.\n",
    "\n",
    "Lets instantiate our TF_IDF. We will use the default stop words as english, cap the features at 500, and make sure we dont consider any words that have less than 2 occurances (though this probably won't make a difference with 500 max features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "784463ed-6769-45ba-8b76-804aa9a3fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate our TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = \"english\", max_features=500,min_df=2) \n",
    "#Fit and transform our vectorizer on our overview column, assigning it as a sparse matrix\n",
    "TF_IDF_matrix = vectorizer.fit_transform(df['overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe7863-e7b6-4310-af32-e41d7391d8f9",
   "metadata": {},
   "source": [
    "Now we have instantiated our TD IDF vectorizer. I decided to set max_features to 500 for the time being to simplify processing and save some computing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1c2a80b-b4fc-46b2-83cf-10de48584ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5061, 500)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_IDF_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52bf2f5-ce7f-4faa-b7c1-6d4edf7570c0",
   "metadata": {},
   "source": [
    "Lets take a random early look to see what we can see. We will look at the Indiana Jones movie, Raiders of the Lost Ark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ae8f071-b126-449b-a7ed-c6283b3d46c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.37070257, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.42156431, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.28022224, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.37811787, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32778693, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.41007954, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.43330821,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check it out for Raiders of the lost Arc\n",
    "TF_IDF_matrix[(df['movie_id'] == 'raiders-of-the-lost-ark').values].todense().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9b53f-dbe8-475e-8155-732670e156f0",
   "metadata": {},
   "source": [
    "Not much to see yet, though we can see that TF_IDF does not just treat word occurances as binary but rather somwhere between 0 and 1, depending on the deemed uniqueness of the word. \n",
    "\n",
    "Lets take a look at what our most common words within movie description were!\n",
    "\n",
    "**Note:** We added stopwords default group \"english\" already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5f034aac-70ba-4a53-b038-99f7362d57ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNYAAAHgCAYAAABpbuCoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACVuElEQVR4nOzdd1gU1/v38XsVQVRARQVRBHvvBcWKWGKPxt5rjCW2qLG32GPU2JPYuzHWxG7ssbdYkmjMF7tIogZFERHu5w+fnR8rYNkgsPh+XddeFzszu3sOMzvls2fOMamqCgAAAAAAAIC3kiyhCwAAAAAAAADYIoI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AEiiTCbTGz327dv3Tstx584dGTZsmJQrV04yZMggzs7OUrJkSfn2228lIiIi2vIhISHSp08f8fDwkJQpU0qxYsVk9erV77SM78Lhw4dl1KhR8u+//77xa2bOnCm5cuUSe3t7MZlMb/VaW3f79m0ZNWqUnD17Ntq8UaNGiclkiv9C2Yh9+/bFy3fZVphMJhk1alSCfX6VKlWkSpUqxvMnT57IqFGjYlw/5m37n3/+ee37ent7S/v27eOsnIsXL37lcUBVJVeuXGIymSzq8y7E9TqrUqWKUbdkyZKJk5OT5MqVS5o0aSI//PCDREZGxtlnvQv/ZV1v3bo11v9lXG9DAIAX7BK6AACAd+PIkSMWz7/44gvZu3ev7Nmzx2J6gQIF3mk5Tp06JUuXLpW2bdvK8OHDJUWKFLJt2zbp1q2bHD16VBYuXGixfKNGjeTEiRMyceJEyZMnj6xcuVJatGghkZGR0rJly3da1rh0+PBhGT16tLRv317Spk372uXPnj0rvXr1ks6dO0u7du3Ezs5OnJyc3n1BE4nbt2/L6NGjxdvbW4oVK5bQxbEpJUqUkCNHjrzz7zLezJw5cyyeP3nyREaPHi0i8p8Cqg0bNoizs/N/KVqMnJycZMGCBdHKtn//fvnrr7/iZT905MgRyZo1a5y+Z44cOWTFihUiIvL48WMJCAiQjRs3SpMmTaRixYry448/iouLS5x+Zlz5L+t669atMnv27BjDtXe1DQHA+45gDQCSqLJly1o8z5gxoyRLliza9HetfPny8tdff0mKFCmMadWrV5dnz57J7NmzZfTo0eLp6SkiLy4Idu3aZYRpIiJ+fn5y7do1GTBggDRr1kySJ08er+WPLxcvXhQRkS5dukiZMmVeueyTJ08kVapU8VEsJAKhoaHi6OgYbXp4eLiYTCZxdnaO9+91Qkrs2/+7CjiLFy/+Tt63WbNmsmLFCpk9e7ZF6LJgwQIpV66cPHz48J18blTvYvt1dHSM9r6dO3eWRYsWSceOHeXjjz+WNWvWxPnn/hfm7/q7Wtfv6n0B4H3HraAA8B67f/++dO/eXbJkySL29vaSI0cOGTp0qISFhVksZzKZpGfPnvLNN99Injx5xMHBQQoUKPBGt2imS5fOIlQzM4dHN2/eNKZt2LBB0qRJI02aNLFYtkOHDnL79m05duzYKz+rffv2kiZNGvnjjz+kZs2akjp1asmcObNMnDhRRESOHj0qFSpUkNSpU0uePHlkyZIl0d7jwoUL0qBBA0mXLp1xK+rLy0VGRsrYsWMlb9684ujoKGnTppUiRYrI119/LSIvbu8aMGCAiIhkz579tbfdVqlSRVq3bi0iIj4+PmIymYzbdapUqSKFChWSAwcOiK+vr6RKlUo6duwoIiIPHz6U/v37S/bs2cXe3l6yZMkiffr0kcePH1u8/8OHD6VLly7i6uoqadKkkQ8++EAuX74c7far9u3bi7e3d7TyxXQrpqrKnDlzpFixYuLo6Cjp0qWTxo0by//+979odStUqJCcOHFCKlasKKlSpZIcOXLIxIkTjdux9u3bJ6VLlxaRF+va/P+K7XamTp06Sfr06eXJkyfR5lWtWlUKFiwY4+uiWrhwoRQtWlRSpkwp6dOnl4YNG8rvv/8ebbljx45JvXr1xNXVVVKmTCk5c+aUPn36WCzzxx9/SIsWLcTNzU0cHBwkW7Zs0rZtW+N7FNutrOZb8a5evWpM8/b2lrp168r69eulePHikjJlShk9erRxu+eyZcvks88+kyxZsoiDg4NcuXIlxltBzd+FK1euSO3atSVNmjTi6ekpn332WbTv982bN6Vx48bi5OQkadOmlVatWsmJEyfEZDLJ4sWLY/0fPnz4UOzs7OTLL780pv3zzz+SLFkycXFxkefPnxvTe/XqJRkzZhRVfat1YK7H+fPnpUaNGuLk5CT+/v7G58e0Xb/s77//lo8//lg8PT3FwcFBMmbMKOXLl5fdu3fHWreLFy+KyWSStWvXGtNOnTolJpMp2vZVv359KVmypPE86q2gV69elYwZM4qIyOjRo41t++Xb8e7evSstWrQQFxcXcXNzk44dO0pwcLDFMi/fxmde76tWrZKhQ4eKh4eHODs7S7Vq1eTSpUux1u1l5h8xVq1aZUwLDg6WdevWGfual73JsaN48eJSsWLFaK+NiIiQLFmySKNGjYxpMX3fAwMDpWvXrpI1a1axt7eX7Nmzy+jRoy22K2t06NBBateuLWvXrpVr164Z0990n3bmzBmpW7euZMqUSRwcHMTDw0Pq1KljcSyLjIyUmTNnGu+VNm1aKVu2rGzevNlYJrbvunleTOt6+fLl0q9fP3F3dxdHR0epXLmynDlzxliuffv2Mnv2bON/an6Y9zEx3Qp6/fp1ad26tVGf/Pnzy1dffWVxu+zVq1fFZDLJlClTZOrUqZI9e3ZJkyaNlCtXTo4ePWrdigCAJIRgDQDeU0+fPhU/Pz9ZunSp9OvXT7Zs2SKtW7eWyZMnW1zwmG3evFlmzJghY8aMkR9++EG8vLykRYsW8sMPP1j1+Xv27BE7OzvJkyePMe3ChQuSP39+sbOzbFBdpEgRY/7rhIeHS6NGjaROnTqyadMmqVWrlgwePFiGDBki7dq1k44dO8qGDRskb9680r59ezl16pTx2kuXLomvr69cvHhRZsyYIevXr5cCBQpI+/btZfLkycZykydPllGjRkmLFi1ky5YtsmbNGunUqZPRJ1rnzp3l008/FRGR9evXy5EjR+TIkSNSokSJGMs8Z84cGTZsmIiILFq0SI4cOSLDhw835t+5c0dat24tLVu2lK1bt0r37t3lyZMnUrlyZVmyZIn06tVLtm3bJp9//rksXrxY6tevbwQYqioffvihEchs2LBBypYtK7Vq1Xrt//JVunbtKn369JFq1arJxo0bZc6cOXLx4kXx9fWVu3fvWiwbGBgorVq1ktatW8vmzZuNdbJ8+XIReXEr46JFi0REZNiwYcb/q3PnzjF+du/eveXBgweycuVKi+m//fab7N27V3r06PHKsk+YMEE6deokBQsWlPXr18vXX38t586dk3Llysmff/5pLLdjxw6pWLGiXL9+XaZOnSrbtm2TYcOGWdTv119/ldKlS8vRo0dlzJgxsm3bNpkwYYKEhYXJs2fP3vwfGsXp06dlwIAB0qtXL9m+fbt89NFHxrzBgwfL9evXZd68efLjjz9KpkyZYn2f8PBwqV+/vvj7+8umTZukY8eOMm3aNJk0aZKxzOPHj8XPz0/27t0rkyZNku+//17c3NykWbNmry2ns7OzlC5d2iKg+vnnn8XBwUEePXokx48fN6bv3r1bqlatagSMb7oORESePXsm9evXl6pVq8qmTZtk9OjRb7Vdt2nTRjZu3CgjRoyQnTt3yvz586VatWpy7969WOtWsGBByZw5s0Xddu/eLY6OjvLbb7/J7du3RUTk+fPnsn//fqlWrVqM75M5c2bZvn27iLwIhM3bdtTvt4jIRx99JHny5JF169bJoEGDZOXKldK3b99YyxfVkCFD5Nq1azJ//nz59ttv5c8//5R69erF2IdlTJydnaVx48YWt+WvWrVKkiVLFuN28KbHjg4dOsihQ4eirc+dO3fK7du3pUOHDrGWKTAwUMqUKSM7duyQESNGyLZt26RTp04yYcIE6dKlyxvV61XM+8iDBw8a095kn/b48WOpXr263L17V2bPni27du2S6dOnS7Zs2eTRo0fGe7Vv31569+4tpUuXljVr1sjq1aulfv36FiG6yKu/6zEZMmSI/O9//5P58+fL/Pnz5fbt21KlShUj/Bs+fLg0btxYRMTY1o4cOSKZM2eO8f3+/vtv8fX1lZ07d8oXX3whmzdvlmrVqkn//v2lZ8+e0ZaPWucVK1bI48ePpXbt2tFCYAB47ygA4L3Qrl07TZ06tfF83rx5KiL6/fffWyw3adIkFRHduXOnMU1E1NHRUQMDA41pz58/13z58mmuXLneuiw7duzQZMmSad++fS2m586dW2vWrBlt+du3b6uI6Pjx41/5vu3atVMR0XXr1hnTwsPDNWPGjCoievr0aWP6vXv3NHny5NqvXz9jWvPmzdXBwUGvX79u8b61atXSVKlS6b///quqqnXr1tVixYq9sixffvmliogGBAS8cjmzRYsWqYjoiRMnLKZXrlxZRUR//vlni+kTJkzQZMmSRVv+hx9+UBHRrVu3qqrqtm3bVET066+/tlhu3LhxKiI6cuRIY1q7du3Uy8srWtlGjhypUU8Zjhw5oiKiX331lcVyN27cUEdHRx04cGC08h87dsxi2QIFClis6xMnTqiI6KJFi177+eb3fXkddOvWTZ2dnfXRo0fR3sPswYMH6ujoqLVr17aYfv36dXVwcNCWLVsa03LmzKk5c+bU0NDQWN+vatWqmjZtWg0KCop1mZjKr/p/6zzqNuLl5aXJkyfXS5cuWSy7d+9eFRGtVKlStPcxz9u7d68xzfxdePn7Xbt2bc2bN6/xfPbs2Soium3bNovlunbtGuv6iGrYsGHq6OioT58+VVXVzp076wcffKBFihTR0aNHq6rqrVu3VET022+/VdW3WwfmeixcuNBi2bfZrtOkSaN9+vR5ZT1i0rp1a82RI4fxvFq1atqlSxdNly6dLlmyRFVVf/nll2j7y8qVK2vlypWN53///Xe0MpmZt43JkydbTO/evbumTJlSIyMjjWleXl7arl0747l5vb/8f/z+++9VRPTIkSOvrF/UfY75vS5cuKCqqqVLl9b27durqmrBggUt6vOmx45//vlH7e3tdciQIRbLNW3aVN3c3DQ8PNyY9vL/p2vXrpomTRq9du2axWunTJmiIqIXL158Zd0qV66sBQsWjHW+efuZNGmSqr75Pu3kyZMqIrpx48ZY3/vAgQMqIjp06NBXljG277p5XkzrukSJEhbbxNWrVzVFihTauXNnY1qPHj1i3N/E9L6DBg2Kcf/crVs3NZlMRtkCAgJURLRw4cL6/PlzY7njx4+riOiqVateWVcASOposQYA76k9e/ZI6tSpjV+3zcy3ifz8888W0/39/cXNzc14njx5cmnWrJlcuXLF4haY1zl9+rQ0bdpUypYtKxMmTIg2/1WjP77JyJAmk0lq165tPLezs5NcuXJJ5syZLfqXSZ8+vWTKlMniVqA9e/aIv7+/0eebWfv27eXJkyfGgBBlypSRX3/9Vbp37y47dux4530QpUuXTqpWrWox7aeffpJChQpJsWLF5Pnz58ajZs2aFrcF7t27V0REWrVqZfH6/zIQxE8//SQmk0lat25t8dnu7u5StGjRaLe8uru7R+s3rkiRIhb/+7fVu3dvOXv2rPzyyy8i8uK2wGXLlkm7du0kTZo0sb7uyJEjEhoaGu12KE9PT6lataqx3V++fFn++usv6dSpk6RMmTLG93ry5Ins379fmjZtatzuFxeKFCli0ZIzqte1aInKZDJJvXr1or131P/7/v37xcnJST744AOL5cy3B76Ov7+/hIaGyuHDh0XkRauu6tWrS7Vq1WTXrl3GNBExWnW96TqI6uV6v812XaZMGVm8eLGMHTtWjh49KuHh4W9ct//9738SEBAgT58+lUOHDskHH3wgfn5+FnVzcHCQChUqvNF7xqZ+/foWz4sUKSJPnz6VoKAgq14rIm/1/apcubLkzJlTFi5cKOfPn5cTJ07Eehvomx47XF1dpV69erJkyRLjtsIHDx7Ipk2bpG3bttFaJkf1008/iZ+fn3h4eFjsY8wtEvfv3//GdYuJRrkl2fx5b7JPy5Url6RLl04+//xzmTdvnvz222/R3nvbtm0iIq9tOSvy6u96TFq2bGlxHPTy8hJfX1/j+/C29uzZIwUKFIi2f27fvr2oarTBjurUqWPRz6k12xoAJEUEawDwnrp37564u7tHC6syZcokdnZ20W6Tcnd3j/Ye5mmvuqUqqjNnzkj16tUld+7csnXrVnFwcLCY7+rqGuN73b9/X0RehGGvkypVqmhBiL29fYyvtbe3l6dPnxrP7927F+MtMx4eHsZ8kRe3402ZMkWOHj0qtWrVEldXV/H395eTJ0++tnzWiKlMd+/elXPnzkmKFCksHk5OTqKq8s8//xhltrOzE1dXV4vXx7Q+39Tdu3dFVcXNzS3a5x89etT4bLOXP1tExMHBQUJDQ60uQ4MGDcTb29voT2jx4sXy+PHj117MmtdhbOvZPP/vv/8WEXnlSIUPHjyQiIiIOB/NMLbbtl4372UxfRccHByibfNRA3OzmKbFxNzv3+7du+XKlSty9epVI1g7duyYhISEyO7duyVHjhySPXt24zNjq0vUdRC1Hi+PZPg22/WaNWukXbt2Mn/+fClXrpykT59e2rZtK4GBga+smzkI3L17txw6dEjCw8OlatWqUq1aNSM82r17t5QvXz7GwSXexsv1MO8b3+Q78l9ea2YymaRDhw6yfPlymTdvnuTJkyfG/tFE3u7Y0bFjR7l165YRRK5atUrCwsKihaovu3v3rvz444/R9i/m/u1e3se8LXMQZN63v+k+zcXFRfbv3y/FihWTIUOGSMGCBcXDw0NGjhxpBLZ///23JE+e/I32sW/zfRaJ/Tj8psfgl73pMc8sLrY1AEiKGBUUAN5Trq6ucuzYMVFViwukoKAgef78uWTIkMFi+ZguQs3TYgpOXnbmzBmpVq2aeHl5yc6dO8XFxSXaMoULF5ZVq1bJ8+fPLVoznD9/XkREChUq9GaVs5Krq6vcuXMn2nRzf0rm/4mdnZ3069dP+vXrJ//++6/s3r1bhgwZIjVr1pQbN27E+YiFMbXUy5Ahgzg6Olr0i/TyfJEXdXr+/Lncu3fPYj3FtD5TpkwZrWN7kegXsRkyZBCTySQHDx6MFo6KSIzT4lqyZMmkR48eMmTIEPnqq69kzpw54u/vL3nz5n3l68z/g9jWs/n/Zm6B9qrWmOnTp5fkyZO/tsWmOdwKCwuz+N/EFg7811abb8PV1dWiLzSz14VOZvb29lKhQgXZvXu3ZM2aVdzd3aVw4cKSI0cOEXnR6frPP/8sdevWtfhMkdevA7OY6vw223WGDBlk+vTpMn36dLl+/bps3rxZBg0aJEFBQUb/ZzHJmjWr5MmTR3bv3i3e3t5SqlQpSZs2rfj7+0v37t3l2LFjcvToUaPDeVvXvn17GTFihMybN0/GjRsX63Jvc+yoWbOmeHh4yKJFi6RmzZqyaNEi8fHxee3IqRkyZJAiRYrEWg5z8GOtzZs3i8lkkkqVKhmf96b7tMKFC8vq1atFVeXcuXOyePFiGTNmjDg6OsqgQYMkY8aMEhERIYGBga8Nzt72+xzbcfhNjsExedNjHgDg1WixBgDvKX9/fwkJCZGNGzdaTF+6dKkxP6qff/7ZotP2iIgIWbNmjeTMmfO1LXbOnj0r1apVk6xZs8quXbskXbp0MS7XsGFDCQkJkXXr1llMX7JkiXh4eIiPj8+bVs8q/v7+smfPHuOiwmzp0qWSKlUqKVu2bLTXpE2bVho3biw9evSQ+/fvG51Tv+tf8uvWrSt//fWXuLq6SqlSpaI9zKN7+vn5iYjIihUrLF7/csf/Ii9GjAsKCrJYz8+ePZMdO3ZE+2xVlVu3bsX42YULF37r+ljz/+rcubPY29tLq1at5NKlSzF2tv2ycuXKiaOjozFwgtnNmzeNW4FFRPLkyWPcGhdT2Cgixqh8a9eufWULGvO6OHfunMX0H3/88bXlfdcqV64sjx49Mm5fM3uTEX/NqlWrJqdOnZJ169YZrbxSp04tZcuWlZkzZ8rt27ctOvd/03XwKm+zXUeVLVs26dmzp1SvXl1Onz79RnXbs2eP7Nq1S6pXry4iL7aNbNmyyYgRIyQ8PDzWgQvMbKVVT5YsWWTAgAFSr149adeuXazLvc2xI3ny5MbgEQcPHpSTJ0/GeotpVHXr1pULFy5Izpw5Y9zH/JdgbdGiRbJt2zZp0aKFZMuWzfi8t92nmUwmKVq0qEybNk3Spk1rbE/m21Xnzp1rdRljs2rVKovbWK9duyaHDx82RqEVebvtzd/fX3777bdo34WlS5eKyWQyvmcAgFejxRoAvKfatm0rs2fPlnbt2snVq1elcOHCcujQIRk/frzUrl072sVihgwZpGrVqjJ8+HBJnTq1zJkzR/7444/XXoBfunTJeK9x48bJn3/+aTFKXM6cOY3WQbVq1ZLq1atLt27d5OHDh5IrVy5ZtWqVbN++XZYvX27Rt8u7MHLkSKNvnxEjRkj69OllxYoVsmXLFpk8ebLRyq5evXpSqFAhKVWqlGTMmFGuXbsm06dPFy8vL8mdO7eIiHEh9vXXX0u7du0kRYoUkjdvXnFycoqTsvbp00fWrVsnlSpVkr59+0qRIkUkMjJSrl+/Ljt37pTPPvtMfHx8pEaNGlKpUiUZOHCgPH78WEqVKiW//PKLLFu2LNp7NmvWTEaMGCHNmzeXAQMGyNOnT2XGjBnRRhcsX768fPzxx9KhQwc5efKkVKpUSVKnTi137tyRQ4cOSeHChaVbt25vVZ+cOXOKo6OjrFixQvLnzy9p0qQRDw+PV15Ap02bVtq2bStz584VLy+vaP2Jxfaa4cOHy5AhQ6Rt27bSokULuXfvnowePVpSpkwpI0eONJadPXu21KtXT8qWLSt9+/aVbNmyyfXr12XHjh1GoDN16lSpUKGC+Pj4yKBBgyRXrlxy9+5d2bx5s3zzzTfi5OQktWvXlvTp00unTp1kzJgxYmdnJ4sXL5YbN2681f/oXWjXrp1MmzZNWrduLWPHjpVcuXLJtm3bjDA1WbLX/wbr7+8vERER8vPPP8uSJUuM6dWqVZORI0eKyWSy6CPwbdZBbN50uw4ODhY/Pz9p2bKl5MuXT5ycnOTEiROyffv2GEc/jqluc+bMkX/++UemT59uMX3RokWSLl06KVmy5Cvfw8nJSby8vGTTpk3i7+8v6dOnlwwZMhiBa2IyceLE1y7ztseOjh07yqRJk6Rly5bi6Oj4RiPOjhkzRnbt2iW+vr7Sq1cvyZs3rzx9+lSuXr0qW7dulXnz5r32B53Q0FA5evSo8ff//vc/2bhxo/z0009SuXJlmTdvnrHsm+7TfvrpJ5kzZ458+OGHkiNHDlFVWb9+vfz7779G8FqxYkVp06aNjB07Vu7evSt169YVBwcHOXPmjKRKlcoYMdoaQUFB0rBhQ+nSpYsEBwfLyJEjJWXKlDJ48GBjGfOxZ9KkSVKrVi1Jnjy5FClSROzt7aO9X9++fWXp0qVSp04dGTNmjHh5ecmWLVtkzpw50q1bt7fq/w0A3msJM2YCACC+vTwqqOqLkTE/+eQTzZw5s9rZ2amXl5cOHjzYGOHPTES0R48eOmfOHM2ZM6emSJFC8+XLpytWrHjt55pHnovt8fKog48ePdJevXqpu7u72tvba5EiRd54xLGY6qga+whxXl5eWqdOHYtp58+f13r16qmLi4va29tr0aJFo5Xxq6++Ul9fX82QIYPa29trtmzZtFOnTnr16lWL5QYPHqweHh6aLFmyaKM2vuxVo4LGNrpdSEiIDhs2TPPmzav29vbq4uKihQsX1r59+1qM4Prvv/9qx44dNW3atJoqVSqtXr26/vHHHzGOVLh161YtVqyYOjo6ao4cOXTWrFmxjmq5cOFC9fHx0dSpU6ujo6PmzJlT27ZtqydPnnxt+WMagXTVqlWaL18+TZEihUXZYvt8VdV9+/apiOjEiRNjnB+b+fPna5EiRYz/W4MGDWIcafDIkSNaq1YtdXFxUQcHB82ZM2e00Wx/++03bdKkibq6uhrbQ/v27S2+R8ePH1dfX19NnTq1ZsmSRUeOHKnz58+PcVTQl7dJ1f8bFXDt2rWxznt5VNCYvgsx/S+vX7+ujRo10jRp0qiTk5N+9NFHunXrVhUR3bRpU6z/Q7PIyEjNkCGDiojeunXLmG4eMbNEiRIxvu5N1kFs9VB9s+366dOn+sknn2iRIkXU2dlZHR0dNW/evDpy5Eh9/Pjxa+v24MEDTZYsmaZOnVqfPXtmTF+xYoWKiDZq1Cjaa14eFVRVdffu3Vq8eHF1cHBQETFGZjSvj7///tti+dhGjI1ppMiXtwnzCI6vG9E1tn3Oy14eFVT1zY8dZr6+vioi2qpVqxjnx7Qv+vvvv7VXr16aPXt2TZEihaZPn15LliypQ4cO1ZCQkFeW2TwasfmROnVqzZEjhzZu3FjXrl2rERERMb7udfu0P/74Q1u0aKE5c+ZUR0dHdXFx0TJlyujixYst3iciIkKnTZumhQoVMrbvcuXK6Y8//mgsE9t33TwvpnW9bNky7dWrl2bMmFEdHBy0YsWKFvtbVdWwsDDt3LmzZsyYUU0mk8V29PL7qqpeu3ZNW7Zsqa6urpoiRQrNmzevfvnllxb/I/M29eWXX0Yra0zrDgDeNybVl4bFAQDgJSaTSXr06CGzZs1K6KIgDplMJhk5cqSMGjUqoYtitc8++0zmzp0rN27csLqfIUQ3fvx4GTZsmFy/fj3OB2cA8Hb27dsnfn5+snbt2mijsQIAEh63ggIAAJtz9OhRuXz5ssyZM0e6du1KqPYfmAPzfPnySXh4uOzZs0dmzJghrVu3JlQDAAB4DYI1AABgc8qVKyepUqWSunXrytixYxO6ODYtVapUMm3aNLl69aqEhYVJtmzZ5PPPP5dhw4YldNEAAAASPW4FBQAAAAAAAKzw+qGeAAAAAAAAAESToMHagQMHpF69euLh4SEmk0k2btwYbZnff/9d6tevLy4uLuLk5CRly5aV69evG/PDwsLk008/lQwZMkjq1Kmlfv36cvPmzXisBQAAAAAAAN5HCdrH2uPHj6Vo0aLSoUMH+eijj6LN/+uvv6RChQrSqVMnGT16tLi4uMjvv/8uKVOmNJbp06eP/Pjjj7J69WpxdXWVzz77TOrWrSunTp2S5MmTv1E5IiMj5fbt2+Lk5CQmkynO6gcAAAAAAADboqry6NEj8fDwkGTJXt0mLdH0sWYymWTDhg3y4YcfGtOaN28uKVKkkGXLlsX4muDgYMmYMaMsW7ZMmjVrJiIit2/fFk9PT9m6davUrFnzjT775s2b4unp+Z/rAAAAAAAAgKThxo0brx0lPdGOChoZGSlbtmyRgQMHSs2aNeXMmTOSPXt2GTx4sBG+nTp1SsLDw6VGjRrG6zw8PKRQoUJy+PDhWIO1sLAwCQsLM56bs8UbN26Is7Pzu6sUAAAAAAAAErWHDx+Kp6enODk5vXbZRBusBQUFSUhIiEycOFHGjh0rkyZNku3bt0ujRo1k7969UrlyZQkMDBR7e3tJly6dxWvd3NwkMDAw1veeMGGCjB49Otp0Z2dngjUAAAAAAAC8UXdhiXZU0MjISBERadCggfTt21eKFSsmgwYNkrp168q8efNe+VpVfWXlBw8eLMHBwcbjxo0bcVp2AAAAAAAAJH2JNljLkCGD2NnZSYECBSym58+f3xgV1N3dXZ49eyYPHjywWCYoKEjc3NxifW8HBwejdRqt1AAAAAAAAGCNRBus2dvbS+nSpeXSpUsW0y9fvixeXl4iIlKyZElJkSKF7Nq1y5h/584duXDhgvj6+sZreQEAAAAAAPB+SdA+1kJCQuTKlSvG84CAADl79qykT59esmXLJgMGDJBmzZpJpUqVxM/PT7Zv3y4//vij7Nu3T0REXFxcpFOnTvLZZ5+Jq6urpE+fXvr37y+FCxeWatWqJVCtAAAAAAAA8D4wqXlIzASwb98+8fPziza9Xbt2snjxYhERWbhwoUyYMEFu3rwpefPmldGjR0uDBg2MZZ8+fSoDBgyQlStXSmhoqPj7+8ucOXPE09Pzjcvx8OFDcXFxkeDgYG4LBQAAAAAAeI+9TU6UoMFaYkGwBgAAAAAAAJG3y4kSbR9rAAAAAAAAQGJGsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYwS6hC2DrvAdtiffPvDqxTrx/JgAAAAAAACzRYg0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKdgldANgO70Fb4v0zr06sE++fCQAAAAAA8CZosQYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArJGiwduDAAalXr554eHiIyWSSjRs3xrps165dxWQyyfTp0y2mh4WFyaeffioZMmSQ1KlTS/369eXmzZvvtuAAAAAAAAB47yVosPb48WMpWrSozJo165XLbdy4UY4dOyYeHh7R5vXp00c2bNggq1evlkOHDklISIjUrVtXIiIi3lWxAQAAAAAAALFLyA+vVauW1KpV65XL3Lp1S3r27Ck7duyQOnXqWMwLDg6WBQsWyLJly6RatWoiIrJ8+XLx9PSU3bt3S82aNd9Z2QEAAAAAAPB+S9R9rEVGRkqbNm1kwIABUrBgwWjzT506JeHh4VKjRg1jmoeHhxQqVEgOHz4c6/uGhYXJw4cPLR4AAAAAAADA20jUwdqkSZPEzs5OevXqFeP8wMBAsbe3l3Tp0llMd3Nzk8DAwFjfd8KECeLi4mI8PD0947TcAAAAAAAASPoSbbB26tQp+frrr2Xx4sViMpne6rWq+srXDB48WIKDg43HjRs3/mtxAQAAAAAA8J5JtMHawYMHJSgoSLJlyyZ2dnZiZ2cn165dk88++0y8vb1FRMTd3V2ePXsmDx48sHhtUFCQuLm5xfreDg4O4uzsbPEAAAAAAAAA3kaiDdbatGkj586dk7NnzxoPDw8PGTBggOzYsUNEREqWLCkpUqSQXbt2Ga+7c+eOXLhwQXx9fROq6AAAAAAAAHgPJOiooCEhIXLlyhXjeUBAgJw9e1bSp08v2bJlE1dXV4vlU6RIIe7u7pI3b14REXFxcZFOnTrJZ599Jq6urpI+fXrp37+/FC5c2BglFAAAAAAAAHgXEjRYO3nypPj5+RnP+/XrJyIi7dq1k8WLF7/Re0ybNk3s7OykadOmEhoaKv7+/rJ48WJJnjz5uygyAAAAAAAAICIJHKxVqVJFVPWNl7969Wq0aSlTppSZM2fKzJkz47BkAAAAAAAAwKsl2j7WAAAAAAAAgMSMYA0AAAAAAACwAsEaAAAAAAAAYIUE7WMNSIy8B22J98+8OrFOvH8mAAAAAAD4b2ixBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwgl1CFwBAwvAetCXeP/PqxDrx/pkAAAAAALwrtFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFQjWAAAAAAAAACsQrAEAAAAAAABWIFgDAAAAAAAArECwBgAAAAAAAFiBYA0AAAAAAACwAsEaAAAAAAAAYAWCNQAAAAAAAMAKBGsAAAAAAACAFRI0WDtw4IDUq1dPPDw8xGQyycaNG4154eHh8vnnn0vhwoUlderU4uHhIW3btpXbt29bvEdYWJh8+umnkiFDBkmdOrXUr19fbt68Gc81AQAAAAAAwPsmQYO1x48fS9GiRWXWrFnR5j158kROnz4tw4cPl9OnT8v69evl8uXLUr9+fYvl+vTpIxs2bJDVq1fLoUOHJCQkROrWrSsRERHxVQ0AAAAAAAC8h+wS8sNr1aoltWrVinGei4uL7Nq1y2LazJkzpUyZMnL9+nXJli2bBAcHy4IFC2TZsmVSrVo1ERFZvny5eHp6yu7du6VmzZrvvA4AAAAAAAB4P9lUH2vBwcFiMpkkbdq0IiJy6tQpCQ8Plxo1ahjLeHh4SKFCheTw4cOxvk9YWJg8fPjQ4gEAAAAAAAC8DZsJ1p4+fSqDBg2Sli1birOzs4iIBAYGir29vaRLl85iWTc3NwkMDIz1vSZMmCAuLi7Gw9PT852WHQAAAAAAAElPgt4K+qbCw8OlefPmEhkZKXPmzHnt8qoqJpMp1vmDBw+Wfv36Gc8fPnxIuAYkUd6DtsT7Z16dWCfePxMAAAAAEP8SfYu18PBwadq0qQQEBMiuXbuM1moiIu7u7vLs2TN58OCBxWuCgoLEzc0t1vd0cHAQZ2dniwcAAAAAAADwNhJ1sGYO1f7880/ZvXu3uLq6WswvWbKkpEiRwmKQgzt37siFCxfE19c3vosLAAAAAACA90iC3goaEhIiV65cMZ4HBATI2bNnJX369OLh4SGNGzeW06dPy08//SQRERFGv2np06cXe3t7cXFxkU6dOslnn30mrq6ukj59eunfv78ULlzYGCUUAAAAAAAAeBcSNFg7efKk+Pn5Gc/N/Z61a9dORo0aJZs3bxYRkWLFilm8bu/evVKlShUREZk2bZrY2dlJ06ZNJTQ0VPz9/WXx4sWSPHnyeKkDAAAAAAAA3k8JGqxVqVJFVDXW+a+aZ5YyZUqZOXOmzJw5My6LBgAAAAAAALxSou5jDQAAAAAAAEisErTFGgAgbngP2hLvn3l1Yp14/0wAAAAASExosQYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGCFBA3WDhw4IPXq1RMPDw8xmUyyceNGi/mqKqNGjRIPDw9xdHSUKlWqyMWLFy2WCQsLk08//VQyZMggqVOnlvr168vNmzfjsRYAAAAAAAB4HyVosPb48WMpWrSozJo1K8b5kydPlqlTp8qsWbPkxIkT4u7uLtWrV5dHjx4Zy/Tp00c2bNggq1evlkOHDklISIjUrVtXIiIi4qsaAAAAAAAAeA/ZJeSH16pVS2rVqhXjPFWV6dOny9ChQ6VRo0YiIrJkyRJxc3OTlStXSteuXSU4OFgWLFggy5Ytk2rVqomIyPLly8XT01N2794tNWvWjLe6AAAAAAAA4P2SaPtYCwgIkMDAQKlRo4YxzcHBQSpXriyHDx8WEZFTp05JeHi4xTIeHh5SqFAhY5mYhIWFycOHDy0eAAAAAAAAwNtItMFaYGCgiIi4ublZTHdzczPmBQYGir29vaRLly7WZWIyYcIEcXFxMR6enp5xXHoAAAAAAAAkdYk2WDMzmUwWz1U12rSXvW6ZwYMHS3BwsPG4ceNGnJQVAAAAAAAA749EG6y5u7uLiERreRYUFGS0YnN3d5dnz57JgwcPYl0mJg4ODuLs7GzxAAAAAAAAAN5Gog3WsmfPLu7u7rJr1y5j2rNnz2T//v3i6+srIiIlS5aUFClSWCxz584duXDhgrEMAAAAAAAA8C4k6KigISEhcuXKFeN5QECAnD17VtKnTy/ZsmWTPn36yPjx4yV37tySO3duGT9+vKRKlUpatmwpIiIuLi7SqVMn+eyzz8TV1VXSp08v/fv3l8KFCxujhAIAAAAAAADvQoIGaydPnhQ/Pz/jeb9+/UREpF27drJ48WIZOHCghIaGSvfu3eXBgwfi4+MjO3fuFCcnJ+M106ZNEzs7O2natKmEhoaKv7+/LF68WJInTx7v9QEAAAAAAMD7I0GDtSpVqoiqxjrfZDLJqFGjZNSoUbEukzJlSpk5c6bMnDnzHZQQAAAAAAAAiFmi7WMNAAAAAAAASMwI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsIJVwVqOHDnk3r170ab/+++/kiNHjv9cKAAAAAAAACCxs7PmRVevXpWIiIho08PCwuTWrVv/uVAAAMTEe9CWeP/MqxPrxPtnAgAAALANbxWsbd682fh7x44d4uLiYjyPiIiQn3/+Wby9veOscAAAAAAAAEBi9VbB2ocffigiIiaTSdq1a2cxL0WKFOLt7S1fffVVnBUOAAAAAAAASKzeKliLjIwUEZHs2bPLiRMnJEOGDO+kUAAAAAAAAEBiZ1UfawEBAXFdDgAAAAAAAMCmWBWsiYj8/PPP8vPPP0tQUJDRks1s4cKF/7lgAAAAAAAAQGJmVbA2evRoGTNmjJQqVUoyZ84sJpMprssFAAAAAAAAJGpWBWvz5s2TxYsXS5s2beK6PAAAvPe8B22J98+8OrFOvH8mAAAAYOusCtaePXsmvr6+cV0WAADwHiFABAAAgK2zKljr3LmzrFy5UoYPHx7X5QEAAEhyCBEBAACSJquCtadPn8q3334ru3fvliJFikiKFCks5k+dOjVOCgcAAAAAAAAkVlYFa+fOnZNixYqJiMiFCxcs5jGQAQAAAAAAAN4HVgVre/fujetyAAAAAAAAADYlWUIXAAAAAAAAALBFVrVY8/Pze+Utn3v27LG6QFE9f/5cRo0aJStWrJDAwEDJnDmztG/fXoYNGybJkr3IBFVVRo8eLd9++608ePBAfHx8ZPbs2VKwYME4KQMAAADeDIM0AACA941VwZq5fzWz8PBwOXv2rFy4cEHatWsXF+USEZFJkybJvHnzZMmSJVKwYEE5efKkdOjQQVxcXKR3794iIjJ58mSZOnWqLF68WPLkySNjx46V6tWry6VLl8TJySnOygIAAAAAAABEZVWwNm3atBinjxo1SkJCQv5TgaI6cuSINGjQQOrUefFLpLe3t6xatUpOnjwpIi9aq02fPl2GDh0qjRo1EhGRJUuWiJubm6xcuVK6du0aZ2UBAAAAAAAAoorTPtZat24tCxcujLP3q1Chgvz8889y+fJlERH59ddf5dChQ1K7dm0REQkICJDAwECpUaOG8RoHBwepXLmyHD58ONb3DQsLk4cPH1o8AAAAAAAAgLdhVYu12Bw5ckRSpkwZZ+/3+eefS3BwsOTLl0+SJ08uERERMm7cOGnRooWIiAQGBoqIiJubm8Xr3Nzc5Nq1a7G+74QJE2T06NFxVk4AAAAAAAC8f6wK1sy3XZqpqty5c0dOnjwpw4cPj5OCiYisWbNGli9fLitXrpSCBQvK2bNnpU+fPuLh4WHRl9vLAymo6isHVxg8eLD069fPeP7w4UPx9PSMs3IDAAAg6XpfBml4X+oJAMB/YVWw5uLiYvE8WbJkkjdvXhkzZozFbZn/1YABA2TQoEHSvHlzEREpXLiwXLt2TSZMmCDt2rUTd3d3ERFjxFCzoKCgaK3YonJwcBAHB4c4KycAAAAA20SACAD4L6wK1hYtWhTX5YjRkydPJFkyy27gkidPLpGRkSIikj17dnF3d5ddu3ZJ8eLFRUTk2bNnsn//fpk0aVK8lBEAAAAAAADvp//Ux9qpU6fk999/F5PJJAUKFDDCrbhSr149GTdunGTLlk0KFiwoZ86ckalTp0rHjh1F5MUtoH369JHx48dL7ty5JXfu3DJ+/HhJlSqVtGzZMk7LAgAAAAAAAERlVbAWFBQkzZs3l3379knatGlFVSU4OFj8/Pxk9erVkjFjxjgp3MyZM2X48OHSvXt3CQoKEg8PD+natauMGDHCWGbgwIESGhoq3bt3lwcPHoiPj4/s3LlTnJyc4qQMAAAAAGDruOUVAN6NZK9fJLpPP/1UHj58KBcvXpT79+/LgwcP5MKFC/Lw4UPp1atXnBXOyclJpk+fLteuXZPQ0FD566+/ZOzYsWJvb28sYzKZZNSoUXLnzh15+vSp7N+/XwoVKhRnZQAAAAAAAABiYlWLte3bt8vu3bslf/78xrQCBQrI7Nmz43TwAgAAAAAAACCxsqrFWmRkpKRIkSLa9BQpUhgDCwAAAAAAAABJmVXBWtWqVaV3795y+/ZtY9qtW7ekb9++4u/vH2eFAwAAAAAAABIrq4K1WbNmyaNHj8Tb21ty5swpuXLlkuzZs8ujR49k5syZcV1GAAAAAAAAINGxqo81T09POX36tOzatUv++OMPUVUpUKCAVKtWLa7LBwAAAADAG2H0UwDx7a1arO3Zs0cKFCggDx8+FBGR6tWry6effiq9evWS0qVLS8GCBeXgwYPvpKAAAAAAAABAYvJWwdr06dOlS5cu4uzsHG2ei4uLdO3aVaZOnRpnhQMAAAAAAAASq7cK1n799Vf54IMPYp1fo0YNOXXq1H8uFAAAAAAAAJDYvVWwdvfuXUmRIkWs8+3s7OTvv//+z4UCAAAAAAAAEru3CtayZMki58+fj3X+uXPnJHPmzP+5UAAAAAAAAEBi91ajgtauXVtGjBghtWrVkpQpU1rMCw0NlZEjR0rdunXjtIAAAAAAAOD/MPopkHi8VbA2bNgwWb9+veTJk0d69uwpefPmFZPJJL///rvMnj1bIiIiZOjQoe+qrAAAAAAAAECi8VbBmpubmxw+fFi6desmgwcPFlUVERGTySQ1a9aUOXPmiJub2zspKAAAAAAAeL/QOg+J3VsFayIiXl5esnXrVnnw4IFcuXJFVFVy584t6dKlexflAwAAAAAAABKltw7WzNKlSyelS5eOy7IAAAAAAAAANsPqYA0AAAAAAAD/Hbe82q5kCV0AAAAAAAAAwBYRrAEAAAAAAABWIFgDAAAAAAAArEAfawAAAAAAAHjnkmJfcrRYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKyQ6IO1W7duSevWrcXV1VVSpUolxYoVk1OnThnzVVVGjRolHh4e4ujoKFWqVJGLFy8mYIkBAAAAAADwPkjUwdqDBw+kfPnykiJFCtm2bZv89ttv8tVXX0natGmNZSZPnixTp06VWbNmyYkTJ8Td3V2qV68ujx49SriCAwAAAAAAIMmzS+gCvMqkSZPE09NTFi1aZEzz9vY2/lZVmT59ugwdOlQaNWokIiJLliwRNzc3WblypXTt2jW+iwwAAAAAAID3RKJusbZ582YpVaqUNGnSRDJlyiTFixeX7777zpgfEBAggYGBUqNGDWOag4ODVK5cWQ4fPhzr+4aFhcnDhw8tHgAAAAAAAMDbSNTB2v/+9z+ZO3eu5M6dW3bs2CGffPKJ9OrVS5YuXSoiIoGBgSIi4ubmZvE6Nzc3Y15MJkyYIC4uLsbD09Pz3VUCAAAAAAAASVKiDtYiIyOlRIkSMn78eClevLh07dpVunTpInPnzrVYzmQyWTxX1WjToho8eLAEBwcbjxs3bryT8gMAAAAAACDpStTBWubMmaVAgQIW0/Lnzy/Xr18XERF3d3cRkWit04KCgqK1YovKwcFBnJ2dLR4AAAAAAADA20jUwVr58uXl0qVLFtMuX74sXl5eIiKSPXt2cXd3l127dhnznz17Jvv37xdfX994LSsAAAAAAADeL4l6VNC+ffuKr6+vjB8/Xpo2bSrHjx+Xb7/9Vr799lsReXELaJ8+fWT8+PGSO3duyZ07t4wfP15SpUolLVu2TODSAwAAAAAAIClL1MFa6dKlZcOGDTJ48GAZM2aMZM+eXaZPny6tWrUylhk4cKCEhoZK9+7d5cGDB+Lj4yM7d+4UJyenBCw5AAAAAAAAkrpEHayJiNStW1fq1q0b63yTySSjRo2SUaNGxV+hAAAAAAAA8N5L1H2sAQAAAAAAAIkVwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAK9hUsDZhwgQxmUzSp08fY5qqyqhRo8TDw0McHR2lSpUqcvHixYQrJAAAAAAAAN4LNhOsnThxQr799lspUqSIxfTJkyfL1KlTZdasWXLixAlxd3eX6tWry6NHjxKopAAAAAAAAHgf2ESwFhISIq1atZLvvvtO0qVLZ0xXVZk+fboMHTpUGjVqJIUKFZIlS5bIkydPZOXKlQlYYgAAAAAAACR1NhGs9ejRQ+rUqSPVqlWzmB4QECCBgYFSo0YNY5qDg4NUrlxZDh8+HOv7hYWFycOHDy0eAAAAAAAAwNuwS+gCvM7q1avl9OnTcuLEiWjzAgMDRUTEzc3NYrqbm5tcu3Yt1vecMGGCjB49Om4LCgAAAAAAgPdKom6xduPGDendu7csX75cUqZMGetyJpPJ4rmqRpsW1eDBgyU4ONh43LhxI87KDAAAAAAAgPdDom6xdurUKQkKCpKSJUsa0yIiIuTAgQMya9YsuXTpkoi8aLmWOXNmY5mgoKBordiicnBwEAcHh3dXcAAAAAAAACR5ibrFmr+/v5w/f17Onj1rPEqVKiWtWrWSs2fPSo4cOcTd3V127dplvObZs2eyf/9+8fX1TcCSAwAAAAAAIKlL1C3WnJycpFChQhbTUqdOLa6ursb0Pn36yPjx4yV37tySO3duGT9+vKRKlUpatmyZEEUGAAAAAADAeyJRB2tvYuDAgRIaGirdu3eXBw8eiI+Pj+zcuVOcnJwSumgAAAAAAABIwmwuWNu3b5/Fc5PJJKNGjZJRo0YlSHkAAAAAAADwfkrUfawBAAAAAAAAiRXBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArEKwBAAAAAAAAViBYAwAAAAAAAKxAsAYAAAAAAABYgWANAAAAAAAAsALBGgAAAAAAAGAFgjUAAAAAAADACgRrAAAAAAAAgBUI1gAAAAAAAAArJOpgbcKECVK6dGlxcnKSTJkyyYcffiiXLl2yWEZVZdSoUeLh4SGOjo5SpUoVuXjxYgKVGAAAAAAAAO+LRB2s7d+/X3r06CFHjx6VXbt2yfPnz6VGjRry+PFjY5nJkyfL1KlTZdasWXLixAlxd3eX6tWry6NHjxKw5AAAAAAAAEjq7BK6AK+yfft2i+eLFi2STJkyyalTp6RSpUqiqjJ9+nQZOnSoNGrUSERElixZIm5ubrJy5Urp2rVrQhQbAAAAAAAA74FE3WLtZcHBwSIikj59ehERCQgIkMDAQKlRo4axjIODg1SuXFkOHz4c6/uEhYXJw4cPLR4AAAAAAADA27CZYE1VpV+/flKhQgUpVKiQiIgEBgaKiIibm5vFsm5ubsa8mEyYMEFcXFyMh6en57srOAAAAAAAAJIkmwnWevbsKefOnZNVq1ZFm2cymSyeq2q0aVENHjxYgoODjceNGzfivLwAAAAAAABI2hJ1H2tmn376qWzevFkOHDggWbNmNaa7u7uLyIuWa5kzZzamBwUFRWvFFpWDg4M4ODi8uwIDAAAAAAAgyUvULdZUVXr27Cnr16+XPXv2SPbs2S3mZ8+eXdzd3WXXrl3GtGfPnsn+/fvF19c3vosLAAAAAACA90iibrHWo0cPWblypWzatEmcnJyMftNcXFzE0dFRTCaT9OnTR8aPHy+5c+eW3Llzy/jx4yVVqlTSsmXLBC49AAAAAAAAkrJEHazNnTtXRESqVKliMX3RokXSvn17EREZOHCghIaGSvfu3eXBgwfi4+MjO3fuFCcnp3guLQAAAAAAAN4niTpYU9XXLmMymWTUqFEyatSod18gAAAAAAAA4P9L1H2sAQAAAAAAAIkVwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAACsQLAGAAAAAAAAWIFgDQAAAAAAALACwRoAAAAAAABgBYI1AAAAAAAAwAoEawAAAAAAAIAVCNYAAAAAAAAAKySZYG3OnDmSPXt2SZkypZQsWVIOHjyY0EUCAAAAAABAEpYkgrU1a9ZInz59ZOjQoXLmzBmpWLGi1KpVS65fv57QRQMAAAAAAEASZZfQBYgLU6dOlU6dOknnzp1FRGT69OmyY8cOmTt3rkyYMCHa8mFhYRIWFmY8Dw4OFhGRhw8fvvVnR4Y9sbLU1rOmnHHhfakr9Xx3qOe7Qz3fHer57rwv9RR5f+pKPd8d6vnuUM93h3q+O+9LPUXen7pSz3fHmnqaX6Oqr13WpG+yVCL27NkzSZUqlaxdu1YaNmxoTO/du7ecPXtW9u/fH+01o0aNktGjR8dnMQEAAAAAAGBDbty4IVmzZn3lMjbfYu2ff/6RiIgIcXNzs5ju5uYmgYGBMb5m8ODB0q9fP+N5ZGSk3L9/X1xdXcVkMr3T8po9fPhQPD095caNG+Ls7Bwvn5kQqGfSQj2TnvelrtQzaaGeSQv1TFrel3qKvD91pZ5JC/VMWqjnu6Oq8ujRI/Hw8HjtsjYfrJm9HIipaqwhmYODgzg4OFhMS5s27bsq2is5Ozsn6S+AGfVMWqhn0vO+1JV6Ji3UM2mhnknL+1JPkfenrtQzaaGeSQv1fDdcXFzeaDmbH7wgQ4YMkjx58mit04KCgqK1YgMAAAAAAADiis0Ha/b29lKyZEnZtWuXxfRdu3aJr69vApUKAAAAAAAASV2SuBW0X79+0qZNGylVqpSUK1dOvv32W7l+/bp88sknCV20WDk4OMjIkSOj3ZKa1FDPpIV6Jj3vS12pZ9JCPZMW6pm0vC/1FHl/6ko9kxbqmbRQz8TB5kcFNZszZ45MnjxZ7ty5I4UKFZJp06ZJpUqVErpYAAAAAAAASKKSTLAGAAAAAAAAxCeb72MNAAAAAAAASAgEawAAAAAAAIAVCNYAAAAAAAAAKxCsAQAAAAAAAFYgWAMAAAAAAIZHjx6JiAhjHQKvR7AGJJCkdpCaOHGi9OnTJ6GLEa+irsPIyMgELAkAs6S2b50yZYrMmDEjoYsBAHiPrFixQjJnzizXr18Xk8mU5I6tQFwjWEOCeh930idPnhQRSVIHKVUVFxcXmTFjhowYMSKhixNvTCaTiIgsXrxYvv/+exEhYAMSmvl7+ddffyVwSf67x48fy61bt+Tzzz+X7777LqGLA8S5pHIe9CrvQx2R9Pj4+Ejx4sWlSpUqcuPGjSR13fK+GT9+vJw7dy6hixFvzNvpmTNnJDw8PN4+l2AtkXlfLsp3794tmzdvNi6A3heHDx+WOnXqyOLFi0Uk6YRrJpNJOnXqJAsXLpRJkybJ0KFDE7pI8SYiIkLmzp0r69atExGRZMmS1m41KWyfL3tVnZJifV8nIiLC4nlS+B8sW7ZMBgwYICK2XZ/UqVNL//795bPPPpP+/fvLvHnzErpI8cq87i5cuCDHjh1L4NLEPXP9Hj16JP/880+M85ISc51CQkKM812TyZSkz31nzJgh33zzjTx8+DChixIvzOv45MmTsnPnzgQuzbuXFL+nZrly5ZJly5aJl5eXVKhQIUmEa7Hta5LyPmjlypUybNgwefr0aUIXJd6YTCbZsmWLlCxZUn755Zd4W79J6wrQxph3THfu3JFr167J33//neQuymMSHh4uW7dulTFjxsj//ve/hC5OvFm6dKksW7ZMnjx5IkOGDJGFCxeKiO2Ha6oqqir29vZSsWJFGTt2rEyYMEEmT56c0EV75yIjIyV58uQydepUOX78eJI6iQwODhaR/zvZsOVtNCpVFZPJJHv27JG+fftKw4YNZfbs2XLz5k0Rkfcu7Df/H4YNGyZHjx4VEdvfJ4mIpEuXTjZu3CiHDx+22XVq/u5lyZJFmjRpIh9//LH07NlTVq5cmcAlix/m7+r69eulTp06cvDgQbl27VpCFyvOmOu3efNmqVevnpQqVUrq1asnX331lYSGhtrsdvsqJpNJfvrpJ6lZs6bUrl1b+vbtKyIvfpBKihe2AwcOlIkTJ0pYWJiEhYVZzLP1fWxMzNv0unXrpGHDhrJr1y65evVqQhcrzpjX2fPnz42Qwvw9TYrrU0TE29tbFi5cKDly5LD5cC0yMtK4zt67d6/s3r1bfvnlFxFJej+Km23cuFFCQkJkyZIlUqZMmYQuTrwJCgqS27dvy/Tp06VKlSrxt34V8SYyMlIjIyONv1VVN2zYoAUKFNCCBQtqlixZdMiQIXr+/PmELGa82LVrl1aoUEG//fZbVVWNiIhI4BK9W4MGDVI3Nzf95ptv9KuvvlI/Pz/NlSuXzps3z1jGvE3YqnXr1mm+fPm0TZs2milTJjWZTDps2LCELlacev78eYzTb926pdWrV9cRI0aoqu1vzz/++KNWqVJFK1WqpOPGjdMbN26oqu3Xy2zDhg3q4uKiHTp00DFjxqiDg4M2adLEqOf7YseOHZo8eXJt3LixZsqUSStVqqQzZsww5tvKPsm8XZqPseZyt23bVjt37qxPnjyxmbrEZMOGDVq+fHlt0KCB2tvbq729vXHsTOq2bdumqVOn1lmzZumjR4+izbf1fdLWrVs1VapUOnHiRD1//ry2atVKXV1ddfv27QldtHfi6NGj6uDgoAMGDNAuXbponjx5tHLlysZ8W1+fUc2bN08zZsyov/76qzEtPDxcQ0NDjee2vF96mbkuO3fuVEdHR/3mm2/02bNnCVyquGOu39atW/Wjjz7SYsWKabdu3XTHjh0JXLL4ERAQoBUrVtRs2bLp9evXVdW2tt+oZe3bt69mypRJM2bMqFmyZNEaNWrogwcPoi1n63777TdNnz69mkwm/eabb1Q19uuYpOTixYvq5OSk2bNn17Vr18brZxOsxaN79+5ZPP/55581TZo0+vXXX2toaKh+8cUXmjx58njfCOLLnj17dOrUqcbz4cOHa8aMGfXvv/9W1aR1QhXV//73Py1QoID+8MMPxrQLFy7oJ598ot7e3rp48eIELF3c+O2339TJyUnnzJmjT5480YCAAJ0yZYra2dnp8OHDE7p4/9mSJUuMEwlV1W+//db43prNnj1b06RJo3/99VdCFDHOnDhxQh0dHXX48OHatGlTrVChgtavX1//97//qartf0+vX7+uBQsW1Dlz5qjqi5MoFxcXHTBgQAKXLH7duHFD+/btq3PnzlVV1bt372r79u21fPnyOn36dGM5WzrJDA4Otng+ffp0zZEjh/7zzz+qajt1ifodO336tDo4OOjcuXM1MDBQjx07pp988ommSZNGv/vuuwQsZdzbtGmTPnz40Hj++PFjbdCggfbv319VVR89eqS///67Tpo0Sb/88ktjOVtZr1FFRERoaGioNmnSREeNGqWqqv/++69mzZpVP/30U4vlkopz587p9u3bjXUXFham+/btUy8vL61YsaKxXFKp84ABA7RHjx6qqnrp0iX97rvvtEiRIlqnTh2LH1Vt2YYNG/TIkSPG89DQUO3QoYN+9tlnqvpimz558qQOHDhQhwwZonfv3k2oosaJzZs3a+rUqXXQoEG6ceNGLVq0qBYuXFhPnTqV0EWLM+b96R9//KGHDx/WX375xTjXvXnzplaoUMGmwrWoP7apqv7yyy9auHBhPXbsmP7++++6Z88ezZs3r5YtW9YInRJ7nd7Uo0ePdMWKFZozZ06tUaOGMT2ph2uXL1/Wrl27qqOjo3GuH1/HFYK1eNKtWzctVqyYhoWFaXh4uKqq9uzZU7t166aqLy5ycuXKpV27djVeE/Wi3ZZFRkbqgwcP1NnZWU0mk3bo0EEPHTqkT5480Q8//FBr166dpL/kt2/f1gwZMuj8+fMtpp8/f15z5cqlmTJl0gULFiRQ6d7e/Pnz9cqVKxbT9u7dqzly5NA7d+4Y00JCQnTixIlqMpn0q6++iu9ixpk1a9ZolixZdODAgXrjxg0NCQnRrl27asqUKbVmzZr62WefaUhIiD548EAbNWqkY8eO1YiICJs8MP/+++/65Zdf6oQJE4xpK1as0KpVq2qdOnWSRLh2/fp1LVWqlIaHh+uVK1fUw8NDu3TpYsw/efJkApYufpw8eVJr166txYsX14MHDxrT79y5ox06dFBfX1+LlmuJVdTtcOPGjZolSxZdsmSJ/v7778b0kiVLaqdOnRKieG9t9erVxt/mY+LKlSu1cOHCFucDAQEB2qVLF7W3t7d4jS27ceOGmkwmbd68uYaEhBjTmzdvrm3bttUzZ85ot27dtFq1apojRw718vLSxo0bJ2CJ40bVqlV17969evPmTfXw8NCPP/7YmLdlyxY9fvx4ApYu7gQGBmrWrFk1RYoUOm7cOGP68+fPdd++fert7a1+fn4JWMK4M27cOOPH03Tp0umXX36ppUqV0nr16umAAQO0QYMGWr58ef33338TuqhWi4yM1Js3b2ratGn1o48+sgiW2rdvrz4+Pvr7779ru3bt1N/fX8uWLaseHh5at27dBCy19SIjI/X+/ftapUoVnTJliqqqPn36VN3d3bV3794JW7g4ZD5v/eGHH9Td3V3z58+vJpNJa9WqZRxrbt68qRUrVtQcOXJoQEBAApb29czHEvO5wvfff6+NGzfWjh07Wiz3119/qZeXl7Zv3z7ey/iuBQcH66pVqzRjxozarFkzY3pSuu6O6Xrr6tWr2qFDB02RIoX+9NNPsS4X1wjW4sHatWs1Y8aMxsn+kydPVFW1fv36unz5cn3y5IlxQmVe6d9//73u3bs3oYr8TixZskSLFCmi5cuX1w4dOminTp106tSp+tFHH+mqVasSunjvzD///KO1atXSXr16aVBQkMW8Fi1aaOXKlbV06dK6devWBCrhmwsJCVFPT08tVKiQxQH17Nmzamdnpzt37rRY/o8//tC0adOqyWTSMWPGxHNp4864ceO0ZMmSOmDAAL1//76qql67dk1HjhyppUuXVi8vLx06dKj6+Pho3bp1LW5NsxUBAQFauXJldXd318mTJ1vMW7Fihfr5+WmDBg30zz//TKAS/jePHz9W1Rfbqru7u/7000+aM2dO7dKli3GCce7cOa1Xr56eOXMmAUv67l2+fFn9/PzU0dEx2rq+e/eudunSRQsUKGC0ZkvsRowYocOGDdORI0dqjhw5tGzZstqnTx+9fv26TpkyRZs2bWrc5ptYv5M3btxQBwcHi1+VVV+EK2nSpLG4nUxVdf/+/Zo8eXI1mUw29cPMq+zfv1/Tp0+vrVq1MlqujR8/XsuVK6d2dnbapEkTXb16tYaEhOjYsWO1Xr16NhvyP3/+XMPCwrRs2bLaoUMHzZkzp3788cfGD6/37t3TZs2a6fz58xPtNvumzC1Gly5dqnny5NHq1atbzI+IiNADBw6ok5OT1qpVKyGKGGdWrFihJpPJ6NKlRYsWWrp0aZ0yZYqeO3dOVV90hVK6dGmbb72lqnro0CHNkyePNmvWzGi59uOPP2r58uWN7+z69etVVXXVqlVaunRpmw0Unzx5oqVKldKrV6/q1atXo/0ot3v3br1161YCljBuHDt2TF1cXPSbb77Rmzdv6smTJ7V+/frq5+dn3HkTEBCgxYoV00KFChn7rMRm8ODB6uPjY5yzBwYGaqNGjTRjxoxarVo1Yzlz+adOnaolS5Y0bgm1VT/88INOmTJFp06dapz3PHr0SFetWqWenp7aokULY1lbPX5GZT4+/vLLL/rtt9/q559/rqdOndLQ0FC9d++edu7cWdOmTRtv4RrBWjz4/vvvNU+ePBocHKw7d+40mkh3795d8+fPr56envrpp58afRE8e/ZMmzdvrsOHD0+0O6w3dfLkSb19+7aGh4frP//8o3379tUpU6bojz/+qH379tXkyZOrq6urfvDBB/r06dOELm6cCQgIsLh1cO7cuers7Kxffvml0arr0aNH2rhxY50zZ45WrFjRuN0lsbtz544WL15cixYtarRgevTokX744YfasGFDixY/9+/f19atW+u3335r0YrEFnTr1k23bNliPP/iiy+0aNGiOmDAAL169aqq/t8BedKkSdqtWzdNmTKlmkwmnTZtWkIU+T+bNGmS5s6dWytWrBjt1vVVq1ZpiRIltFmzZja3Xzp58qR6eXkZFzJt2rRRe3t7/fDDDy2WGzJkiJYpU0Zv376dEMWMVwEBAVqnTh0tX758tB827ty5oz179ky0v0ZHPTFauXKlZsqUSfft26eqqr/++qsuWbJEc+bMqdWrV9eSJUuqyWTShQsXJlRx39j+/fs1W7ZsFuHCpUuXtGzZstq/f39jv6P64hf2Dz/8UMePH69//PFHQhQ3TplP8A8dOqRp0qTR7t27G+dEFy5c0AMHDqjq/637rl27aqNGjWzmvMFc7nv37mlERIRRt23btmm6dOm0WLFiFssPHTpUc+bMafNdC1y4cEFr1qypv/32m4aFhenq1avVzc1NmzdvbrHc8+fP9ZdffrHZH25UX9wW+c033+jSpUstpke9vfnZs2f6wQcfaMOGDW06MI2IiDDOA/bu3avZs2fXtm3bGoHiw4cP9dixYxav6dGjh9auXdtoXGBLIiIi9P79++rl5aVffvml5sqVS7t06WL8D65fv64ffvihcfFuy2bOnKllypSxaNH022+/aa1atbRBgwbGNHPAmBhFRkbq/PnztUKFClq3bl3jfPa3337Tjh07arp06fTrr7+2eM3y5cs1T548Nh14Dxw4UL29vbV8+fLq7++vHh4eeuHCBVV9cZ22evVq9fb21po1ayZwSePWunXr1MXFRVu0aKE+Pj5aokQJ7dmzpz5//lz/+usv/fjjjzVDhgxGyP8uEazFg3379qmfn59Wq1ZNTSaTbty4UVVftJwoW7asenp6Gq0pnj9/rkOGDFFPT0+9fPlyQhb7P3v69Klmy5ZNS5UqpVOnTtXQ0FBdt26dVqhQwfhVZ8mSJZo/f351dna26Z1ZVEOGDNFs2bIZ97SbT/wnT56sGTNm1Nq1a2v79u21XLlyxsl0x44dtXLlyon614PIyEijfLdv39Zy5cppkSJFjIvv9evXa4UKFbRevXq6efNmvXz5sn7++edauHDhaCFNYvfHH3/ogAEDonW8O3r0aC1evLgOGDAgWkf3YWFhevjwYa1Ro4Y2adIkPosbp6ZPn66lSpXSLl26GP0fmq1duzbRnki9yq+//qpFixbVFStWqOqLvpwqVaqkPj4+umXLFiPod3Z2jtYyKKm4efOmnj9/Xv/++2/jwubSpUtaq1YtrVq1arRwLTHvi8y2b9+uffr0ibEj/9DQUF2+fLl2795d7ezstEyZMnrt2rUEKOXbOXjwoGbOnNkiXPvqq680T5482qdPHz169Kjeu3dPBw0apH5+fsav8bbMHDD8+OOPOmLECOP2o7Zt20a7CA8ICND+/ftr2rRpbW6gp40bN2q5cuW0VKlSOmnSJKNLhYkTJ2qyZMm0SZMm2q1bN23Tpo2mTZtWT58+ncAl/u/279+v+fLlM1q/Pnz40Gg58XK4Zsti6iQ8augbEhKi3333ndaqVUuLFClinFvYwn42Jubv7Pr163XkyJGaN29eTZYsmdatWzfadnvu3Dnt27evpk2b1maOr+b6vbz/mTBhgqZMmTLabctDhw7VQoUK2cQxJjbmOs+ZM0cLFSpktCw0B2wHDx5Uk8lkMy36IyIidOXKlerr66u1atUyWs7+8ccf2q5dOy1VqpROnDhRQ0NDNSAgQKtXr641atSw2cB75syZ6uHhYXQfsGjRIjWZTJo+fXpj2qNHj3ThwoX64Ycf2uy+52UXL15ULy8vo8/Zmzdvqp2dnY4cOdJY5vr169qiRQv18vLSkJCQd7qOCdbekRUrVhgpsapq586d1c7OTsuXL2+ESk+fPtVFixZpsWLF1NvbW5s0aaK1a9fWjBkzJokTKtUXHZd+/vnnWqlSJS1TpowGBARo7dq1LS4aLl68mGRaiKxdu1YzZ86sa9as0e+++04LFiyoBQoUMFqprV+/XgcOHKi1a9fWnj17GidejRs31p49eybqHZ15R7R582adOXOm3rp1S4sWLapFihQxTiY2btyoTZs21WTJkmnOnDnVzc3N5rflJUuWWLR2iRqu3bx505huXnfHjh1TOzs7iw59E6tff/1VV65cqT/++KNevHjRmP7ll1+qr6+vdurUKdrty7YoPDxcGzVqZDH63KZNm7R169bq6OioRYoUUT8/P5s56X9b5tGnPTw8tHjx4jpkyBBjn/vHH39orVq1tEaNGjY1kMqRI0e0aNGimi5dOqPc5guAl/sOWbt2rebIkUN/+eWXeC/nm3j5JO/gwYOaJUsWi9tVpk6dqhUrVlR7e3vNnz+/pk2b1mYucN7E9u3bNWXKlDpjxgxdvXq1fvXVV5omTRqL20L37NmjTZs21SJFiujZs2cTuMRv5+zZs+rq6qpjx47Vtm3barly5bRJkyZGC62dO3dq7dq1tUGDBtq7d2+ba+FtZt6Wo/4oM2nSJE2ZMqVeunRJVf/vtqTs2bNrnTp1EqScce11nYQHBQXpkCFDtE2bNkYrJ1tr+f2yPXv2aIoUKfSbb77Rbdu26erVqzVdunTaqFEjo8+148ePa/fu3bV48eI28501b8NbtmzRJk2aaKNGjXT79u0aEhKiN2/e1Pbt26urq6t+8cUXOm3aNO3atas6OTklmf3xvn371GQyResX+uLFi1qgQAH97bffEqhkb868DiMiInTFihXRwrWLFy9qu3bt1M7OTr28vLRp06Zap04doy/TxHwtFpN79+5pjx49dNmyZar64kcqJycnnTRpktatW1czZMhgfP+ihsW2Vs+Y7NmzR0uVKqWqL7o58fLysrhF23xtc+3atXjJGgjW3oG//vpL8+XLZ7TsiIiI0AoVKmjr1q21YsWK2rZtW2NFh4WF6cWLF/Xzzz/Xzp0767hx42y6Kbzqi1/ujhw5otu2bTOmnTt3Tps0aaKZM2fWTp06GZ1MJyVr1qzRpUuXWhyMAgICtESJEhbhWlR37tzRIUOGaPr06S2CjcTq5MmTmiFDBuNC9s6dO8aoSOZw7dmzZ/r777/rqVOnYqyzLblz547WrFlTy5UrZ9GixxyuDRw40AjKIyIijFt8SpQooZs2bUqoYr+RdevWqbu7u5YoUUILFiyoVatW1R9//NGYP2XKFK1UqZI2bdrUOBmxBeYTqpcvWgICAjRDhgzRRmO7evWqPnz40OJ2naRk27Zt6uzsrFOnTtX79+/rgAEDNHPmzNqhQwej1eWlS5fU19dXGzRoYFP/h6lTp2r27Nm1QoUKGhgYqKqWJ4pRA6sPPvhAW7Vqleh+jTaX59dff9Vt27bpxo0b9e+//9YDBw5ozpw5tWrVqsay165d03379umWLVssuhpICnr06BHt1uxdu3Zp6tSptWPHjkar/l27dln8oJGYRd3WDhw4oH369DGeL1++XKtUqaKNGjUyjv3mfZatX+zs3r1b8+TJY9FioFmzZlqrVi0jcHv8+LEuWbJECxUqZDPr83Vi6yTcvD5DQ0ONbSIpdBzev3//aC23Dh06pC4uLlq/fn2jT7kzZ87Y3LngoUOHNFWqVNqzZ08tWbKkFixYUEePHq0hISEaGBiokyZN0pw5c6qvr682a9bM5lrPqlqO/rlv3z795ZdfjP3smDFj1N7eXr/99lu9ffu2Pn78WAcPHqw5c+ZM1HcXxbTvfP78ua5atUrLli1rEa5dunRJ27VrpyVKlLDoA9pWuhdQtTzGHDx4UAMCAvTChQuaM2dOnT17tqq+ONaYTCY1mUw2cZ35psx1X7NmjVaqVEnv37+v2bJl0y5duhjbwf79+/Xzzz+P1/0PwVoc++mnnyxaeJw5c8YiIZ03b56WK1dO27VrZxOp/9tat26dZs2aVcuWLavp0qXTOnXq6ObNm43533zzjdaqVUtNJpM2bNjQpnZgr3Lr1i1Nly6dmkymaJ2BBwQEaMmSJbVIkSIWtw8+ePBAu3Tpojly5LCJX7ouX76sX375pQ4cOFBV/+/E0ByuRb0t1FbFdFA+evSotmjRQitWrKgrV640po8ZM0ZLlSqlXbt2tfh1/uuvv1aTyZSo/xd79uzRjBkzGgfejRs3qpOTk+bOnVvXrFljLDdmzBitWbOmzbUo3b17t9aoUUMXLFhg7GPCwsK0U6dO2rZtWw0NDbXZkVvfRlBQkNasWVPHjx+vqi86Ec+WLZuWK1dOCxcurB06dDDW7Z9//plow5qXv5dRn8+cOdMY+dN87I063/x33bp1tVu3bonygnbt2rXq6uqqxYoVU5PJpBUqVNDp06cb4VrUlmtJUWRkpDZq1Mii3xdzyPTFF18Yo4Xa0vmCed9y8OBBnTlzpg4ePFj79u1rsYw5XGvSpInFOYCt75e+//57TZYsmbq6umqpUqX04MGD+s0332iDBg105cqVFkGTLQX5L3ubTsKj7ndsff2ay9+vXz+jFXjUfgMXLlyoKVOm1AYNGthsK/Bly5bpqFGjjOeDBg3S4sWL64gRI4zb7x89eqSqthXEmEUd/dPT01M9PT3Vy8tLc+TIYQSiX3zxhaZIkUJz5sypRYoU0UyZMiXqO1CiHve3b9+uq1at0pUrVxrrae3atVquXDmLcO3ChQvavn179fX1tYl+WF8WU6vXlStXqp+fn3Er77Zt2/Tjjz/WCRMm2HQr2djO2e/cuaPOzs5qMpmMPuzN+vbtq9WrV4/X7ogI1uJQYGCgenl5aYcOHfTXX3/VsLAw9fDwiHbS9M033xjhmrnTYfPGYssH3MOHD2v69OmN+5z37NmjJpNJ582bZ7HDu3z5sk12Zv86hw8f1mLFimnZsmU1LCxMVf9vfV69elWzZs2qbdq0sXjNrVu3ovXVldhERkbqvXv31NPTUx0cHCyGozav18DAQC1VqpRmy5bNJvvgUrU8KF+/fl3v379vTDty5Ig2bdo0WrjWv39/bd++vcX39saNG8aJSWL09OlT7d69u9F64saNG+rt7a2NGjXSRo0aaY4cOSxartla/3iqL/YxNWrUUB8fH82dO7d+//33GhQUpKdOnVI7Ozvdv39/QhcxXkRGRurq1av1woULGhQUpPnz59dPPvlEVV90/u7s7KyNGjVK1PugqN/LefPmaceOHbVt27YWI5ZOnz5dy5Urp507dzbCtai3gvzxxx9qMpkS5UXB6dOnNUOGDDp//ny9f/++3rlzR9u2bat+fn46a9YsPXDggHp5eamvr29CF/WdWrNmjWbIkCFa598LFizQ0qVLa7Zs2WyuZdOGDRs0ZcqUmj9/fnVxcdGMGTNGazGwcuVKLV68uLZp08Y4b7A1L5+33rp1Sz/++GOdPXu29uzZUz/66CP95JNP1MvLS5s0aZIow+239b52Eh7VDz/8oCaTSXfs2KGq/7evXr16tRYtWlSLFy9uM99Z8zZ86tQp3bp1qw4bNkxnzZplsczgwYO1ePHiOnLkSIsfG231uu3o0aOaJk0a/e677/TPP//U48ePa926dTVTpkxGw48jR47oqlWrdPny5TZzbj9w4EDNmjWr+vv7a5YsWbRy5cq6c+dOjYyM1BUrVmj58uW1bt26xrnCH3/8oZ06ddL8+fPb1J1Uc+bM0ZYtW2rjxo11yJAhxvSvv/5a7ezs9M6dO/rvv/9q/fr1tWfPnsZ8WwvXzCGo+bhx9OhRnT59um7evNnop3TJkiWaIUMG7datm965c0fPnDmjAwcOVBcXl3hvTUqwFsdOnTqlZcqU0c6dO+uDBw907969miNHDm3fvn20cK1ixYraqFEjm7/10+zrr7/Whg0bquqLC1vzqDlmL3eEnhRMmDBBZ86caZxQHD16VLNly6ZVq1Y1ppkPunfu3LG5Xy2jlnHv3r2aK1cuLVq0qB4+fNiYHnVAg4oVK9r8KGbDhg1Tb29vLVmypHbs2NG42DGHa5UqVbK4LTTqBbytXDD8/vvvevDgQQ0ODtaSJUtq586dVfVF/3n29vaaPn16Xbt2bQKX8s1F3U7NJw3Pnj3TP//8U7t06aKFChXSYsWK6ZIlS7R27dpap04d49e8pM58a8e0adO0du3aRlA6Z84cLVCggDZp0sS4nTkxGzhwoGbMmFHbtm1r9OPYokULo8XLV199pRUrVtSPPvpIHzx4EO31ibWT/xUrVmiBAgU0ODjY4ljRokULrVKlij5+/Fj37Nmj+fLlS7QtCt+GuY5XrlzRw4cPG9/DmzdvavPmzdXPz88I1yIjI3XgwIE6fvx4o++bxCzqfujBgwc6cuRIXbBggUZEROimTZu0WrVqWq5cOYv+d1VftPCylYvW2Bw4cEDr1Klj3Ca2du1azZs3r16/fl1Pnjyp48ePN1r1jx49OoFL+9+8b52Em7fr8+fP644dO/T8+fNGK63OnTtrmjRpdPv27cZyQ4YM0UmTJhkthWzF2rVrNU2aNJo1a1aj5fDLPywOHz5cs2fPruPGjbP59Tp//nz18/OzCFpCQkK0Vq1amj9/fpscvXXBggXq4eGhJ0+eVNUXP8YlT55ct27dqqovztNXr16tuXPn1s8++8zYZi9evKjdu3dP1HeaRDVw4EB1c3PTL774QqdMmaIpU6Y0rr8DAwO1YsWKmixZMs2bN68WLFgw2kBstmL58uXq7+9vHDPXrVunqVOn1kKFCmmWLFm0fv36euLECVVVXbx4sbq6uqqHh4fmy5dPixUrliB3gxGsvQOnT5/WYsWKaceOHfX+/ft66NAh9fT0jBauTZ8+XWvUqGETFzVv4tNPP9VevXqpqmqWLFn0448/NnZaa9eu1QULFtjslzs2/fr1U5PJZJw8q/5fuObv7x9jeGYL4cvL/YCY67Znzx719vbWli1bWmzL5vm2ULdXWbdunWbLlk1XrVqlQ4cO1VKlSmm5cuUswrXmzZtr/vz5defOncbrbCEk/e233/TAgQP6v//9z5i2a9cuLV26tHFRd/ToUa1WrZoOHDjQZgJS8/9+9+7d2rt3b23YsKHOnDnTovy//PKLTpw4UV1dXdVkMmm+fPmSbLB29uxZ3bNnj0X4rfriVpYSJUoY9e7fv79OnDjRJlokHjlyRD08PPTgwYMW01xcXIxQWPVF34ddu3aNsZ+1xPodXbVqlebMmdPoA8R8kRMQEKAmk0n37NmjqtFHp7NlP/zwg7q7u6u7u7t6e3sb5wanTp3S5s2ba9q0abV8+fJasWJFdXZ2TtQtgFXVuGgzO3XqlLq5uamPj48ePXrUmL5t2zatVauW+vj4JJm+bsyjhe/Zs0fz5Mmj+fPn12nTpmlYWJiOGTNGfX19NSQkRFVVd+zYoZUrV7bpblDe107C165dq5kyZdJMmTJpwYIFtV+/fvrkyRP9999/9eOPP1aTyaSlSpXSkiVLaurUqW1uoIK///5b27ZtqwsWLNC7d+/qhAkTtGTJktqlS5doAzh98cUXFudRtsp8TmRmPvb8/PPP6u3tnej3uzEZMGCAcR26evVqdXFx0Tlz5qjqi9AwODhYIyIidOfOncb1inkbsJXr0+PHj2u+fPmM86GNGzdqmjRpjK5dVF/8sLNo0SJdunRprIM62YL58+drxYoVtXHjxnrkyBHt3Lmz0Y/5+vXrtV69elqhQgU9duyYqr74Hu/atUvPnTuXYAOvEay9I1HDtQcPHliEa1EPODH9sm5L7t27Z7SI2Lx5szo5Oamzs7P26dPH4kSiS5cu2r59+yR1cWA2cuRItbOz0++++84iXMuePbsWKVIk0V7QxSZqUNGjRw9t1aqVjhs3zvgleufOnert7a2tWrWymZOn2Lx8svvDDz8Yzf/Dw8N1586dWqxYMfXx8TF+oT1w4IAOHz7cpg5SGzZs0NSpU2vOnDnVwcFB582bp+Hh4UbH9nv37lXVF7c6tG/f3mZCJ/O2un79enVwcNAmTZpo06ZNNW3atMZIXlFdvXpVp06daoxOl9Rs2LBBHR0dNU+ePMZw4+aTRfMtdfXr19eWLVtq6tSpE+3/4eXv1u7du9Xb29s4UTJfAOzcuVNTpkwZY8htKxeyV65cUQcHBx06dKjF9KtXr2qhQoVsYnTh14naN8rly5e1WLFiOmPGDP3tt9+0Q4cOmi9fPv3yyy81LCxM//nnH928ebN26dJFhw4dmugDqCNHjmjatGn1zp07Rh2PHz+u9erVU3t7e4swWPVF3z/16tXTvHnz2nR3GLGd1wwYMED9/f21ePHiumDBAm3RooV+9913xnc6Kdzu+r50Em6u861bt9Tf318XLFigV65c0dGjR6uPj4926NDBOP//8ccfdezYsTp27FijixtbceLECa1UqZLWqFHDouXo1KlTtVy5cjY/Onpsx8Lz589r/vz5ddy4cRb9xP3666/q5eWVKLtOiOrlfVBERITWr19fp0yZoqdOndI0adIYXUZERETojBkzovWjZkvn8WZ79uzRAgUKqOqLc740adIYg3IFBwfr+vXro73GFutptnz5cq1atap++OGHWq1aNeP2T9UX54DmcO3AgQMJWMr/Q7D2DsXUci1Hjhz60Ucf2eQvAS/bsGGDli9fXnPnzq0jRozQ7du3a+/evTVjxozGBe29e/d08ODBmilTJps+iYwqpl+qhg0bZoRr5ou+AwcOaMOGDW1yh2buG6Zz585avXp1LVWqlHp5eRkjf+7cuVNz585tMfKTrYl6UJ47d65+8cUX6ufnZzE6UHh4uO7atUuLFy+uvr6+0W5HSuzrNjIyUu/fv6/ly5fXb775Rv/8808dP368mkwmnTBhgh49elQ/+ugjY8CRNGnSJPrOhrds2WJRxps3b2rhwoV1xowZxrTjx49r+fLltXHjxsaJ8su/TiYlkZGRGhISYlz8XL58WZcuXar29vb66aefquqLE8tx48ZpkyZNtG7duon2exu1Bd2xY8c0PDxcz507p3Z2dsZI01Ev+LJnzx7ttmVbW8fLly9Xe3t7HTx4sP7555969+5dHTp0qHp6etp0i/aX++47fvy4fvnll/rJJ59YXOz16dNH8+fPr19++aWx/m0lGA0LCzPKHDWoPnXqlNaoUUPd3NyiBQ2bN2/WJk2a2MxtRy8zf78OHz6s48aN00mTJunq1auN+ceOHdO+ffuqyWRSJycn9fHxMX6ssbXvptn71El4VCdPntSOHTtqixYtjHqGh4frjBkztEyZMtquXTubHoBCVXXp0qVaokQJTZ8+fbQAberUqTY5OrqqRjtfPXv2rG7atEkPHTqkqi/62+3du7dWqlRJx4wZo+Hh4RocHKxDhw7VvHnzGiNtJ0ZRz73/+usv44f/FStWqKOjo5pMJov+kB89eqTVq1eP9gOWLVm4cKHOmDFDDx8+rDVq1NBZs2ZZhGqqL0L/li1b2uz1dtTjftR96KZNm9TX11ednJyi3d65c+dObdSokRYqVMiihXhCIVh7x15uubZ3714tVKiQTZ8sq744aXRxcdExY8Zo7969tWTJktq8eXMdP368du/eXVOkSKFFixZVHx8fzZYtW6L/5eNN/fTTT2oymaLd+qH64pfaVKlS6dKlS6M1KU7sAUxUQUFBWrRoUYvRTc+fP6/Vq1fX7NmzGyce27dv16JFi9rkthx15z1s2DB1dnbW8uXLq7e3t+bNm9fi4v758+e6e/du9fDwMPoMtJWLg9DQUH3y5IkOGTLEoo+p6dOna7JkyXTGjBm6detWnTt3rg4ZMiTR/9IcGBio2bNn1w4dOhi3E929e1dz5Mhh/EpnXrfHjx/XNGnS2FRntNZ69OiR/vvvvzpw4ECLTpU3btyo9vb22qNHD4vlE+soZnv27NFatWrprVu3tHfv3urp6alBQUEaGhqqbdq00QoVKlgMPPHvv/9qgQIF9Pvvv0/AUv93kZGRunLlSnVyctJs2bJpnjx5NGvWrHrq1KmELprVhg8frh9//LExAq+qaoMGDYxbxsy3B5r16dNHixYtqqNGjUr0tyfHFPoFBASonZ2d9uvXz5h26tQprV27tnp6ekbbt75cf1uzbt06TZMmjVarVk1LlCihDg4O2qFDB4tltm/fruXKldN06dLZ5HmC2fvSSfjLnj9/rgMGDNCsWbNq3rx5LeaFhYXp119/rRUqVNCGDRva9PYcHh6ua9as0Tx58qi/v3+0AG3cuHE2Nzr6uHHjtFevXkZdog6kYjKZ9NNPP9X79+/ro0ePtG/fvpo/f35NnTq1+vj4aMaMGRPtsWfOnDkWwcqgQYO0YMGC6urqqgMGDNAffvhBe/bsqR4eHvrzzz/rkydP9M8//9QPPvhAS5YsabPfyadPn2q9evW0UaNGev/+fc2bN6+aTCZjxHfVF7ee16pVS5s3b24z1ygxCQgIMPqe//7777Vr167G3yVKlNAPPvgg2oAEP/30k7Zs2TJR/FhFsBYPTp8+raVKldKmTZvqv//+a/O3Q165ckW/+OILHTt2rDFt8+bNWr16dW3atKnxi8iECRN05cqVRiunpCAyMlLbtm2r6dKli9Z64uzZs+rg4KAmk0k3bdqUkMW0Wnh4uD548EAzZsxocXvV8+fP9cyZM1qiRAmLwRrMtwHYqjt37mjr1q319OnTGhoaqqdOndIiRYpo0aJFNTg42FguPDxcT5w4YVMB6caNG7VmzZqaP39+zZcvX7SWaFOnTtWUKVPqyJEjbaZ1iOqLi9XSpUtr586d9fz58xocHKyZM2c2mvyHhYUZ9alRo4Z+/PHHCVncd27Dhg1aoUIFLV68uGbOnDnaL3YbN27U1KlTa4cOHRJtoGZmbgGSJ08eTZ8+vUU/eXv27NGGDRtqgQIFdNq0abps2TKtUaOGFitWzKa+l69y9epV3b59u27ZsiVRj9T6On369LEYjStqlxedOnVSNzc3/e6776JdjHfu3FnLlSuX6IM11RcjR5sD3VWrVmmrVq10xowZ6ujoaBG+nDx5UmvXrq05cuRIErcHqr5otZ81a1adOXOmqqo+fPhQt27dqunSpYu2v71+/brRmsQWvS+dhMfmwYMHOmrUKM2cObP269fPon5hYWE6ceJErV69us0Ep+bz9evXr+u1a9eMwDsyMlLXrFmj5cqV09q1a0cb7MYW9klRffPNN2oymXTIkCF66dIlrVSpks6fP1/v3bunmzZtUmdnZ+3QoYP+/fff+uzZM7127ZrOnTtX169fnyjCiZiY9ztdunTRP//8Uzdt2qRZsmTRDRs26OjRo7VcuXLarFkznThxovbu3Vvt7Ow0W7ZsWqRIEa1QoYKx7dra+YJ5mz19+rQ6OTnpsWPH9PTp0+rg4KBNmzbVmTNn6urVq7Vq1apauHBhIzy0pfN6s/DwcPX391dPT0/9+uuv1WQyWfw4bj5HbNiwYbTjaWK5HiVYiyfHjx/XSpUq2dQvHjEJDg7WUqVKaaZMmXTQoEEW8zZt2qR+fn7aqFGjRPtrR1xp27atOjk5GeGa6ovO4YcOHWpxO6gtOXnypH7yySd69+5d9fHxsbg4UH2xcy9TpozFL7K2/KvI/Pnz1cnJSUuWLGlxC8/58+e1SJEiWqxYsRhvcbCFg/KJEyfU2dlZu3Xrpu3bt9cUKVJo7969o408N2HCBE2bNq3Njdh7+vRpLVGihHbq1Elv3bqlU6dOVXt7+2h9LPj7++vIkSMTppDx4MSJE5oxY0bt0aOHfv755+rg4KAtW7bUmzdvWiy3Zs0adXNzS7S3dkT9TnXt2lVNJpP6+flFG0DjyJEj+vnnn6urq6v6+Pho/fr1bfZkOalasWKFZsqUybjV+Pjx49qhQweLvsYaN26sBQsW1KVLl0b7oTGxbqNRPXv2TJs3b66+vr7GLY+LFi1S1RfHFTs7O4vj5+nTp7VChQpaqFAhffbsmU0fNyMjI/Xs2bOaI0eOaN/PzZs3a6pUqWJs0W+L3qdOwlX/73zu2rVrGhAQYLQKf/LkiQ4fPlx9fHx00KBBFue3z549S7QjLr/MXL9169Zpnjx5NHv27Ori4qLdunUzGgCsXr1ay5Urp/Xr17e5Wz9fZu7zb8CAAdqmTRuL9bRt2zZNmzatdujQwaYGYjhz5oyWLFlS+/Tpo/369TM6sldVY+TlJk2a6M6dO/XChQv6/fff6969e42QyRavzcwePnyozZs3N67Bdu/erXXr1lVPT0+tXLmytmzZMsmcD3l7e2vKlCl10qRJqmoZEi5fvlz9/Py0SZMmibLrGoK1eGQLw8W/idOnT2uePHm0fPny0YaN37JlixYrVkxbtWqljx8/tukTSLOlS5fqoEGDdPjw4bphwwZjetu2bdXR0VGnT5+uW7du1Xr16mmTJk2M+ba2A585c6bRWXa/fv20dOnSum7dOotlGjZsqMOGDdPIyEibX7d3795Vf39/tbOzi9bB9IULF4wWQInlV5A3deXKFR0xYoROmDDBmDZnzhzNmjWrDho0KFq4ZisnxS8z32bfuXNn/fnnn/XTTz9VOzs7nTJlii5cuFD79++vzs7Oif72VmtdvnxZJ02apF988YUxbd++fZoiRQpt3759tHDt0aNH8V3ENxL1hGnNmjU6cuRInT9/vtaoUUPr168f44nTv//+a3F8sbV9bVI2efJkzZcvn6q+uHgrWrSoFilSRNu3b2/RmvKjjz7SggUL6vLly21uH6v6IlDx8fFRk8mk3bp1M6aHhobGGK6dPXtWr1+/nhBF/U+uX79u9GG4atUq7dKli16+fFlTpkxpcT6k+qIbiTx58uh3332XACWNe+9TJ+HmfemGDRs0f/78WrhwYXV2dtYePXpoQECAPn78WAcPHqw+Pj46dOhQm93n7tu3Tx0dHXXu3Lm6d+9eXb9+vWbIkEEbNmyot27d0oiICF25cqUWKFBAmzZtapOtfqKWecGCBWoymTRt2rQWrfNUX9yqnTFjRm3WrJnNjAKv+uKuhVKlSmm6dOl02rRpFvM2b95sdHT/8sA/tvbdnDp1qk6ZMsWi9fr8+fM1VapURmOAkJAQvXfvnkXrb1v9bqq+WEchISGaJk0a9fDw0MKFCxt1jbpdr1ixQosWLapt2rRJdAPiEKzBKr/++qsWK1ZMP/7442jh2o4dO6JdvNuq/v37q6urqzZt2lQLFSqk+fLl0/bt2xvzBwwYoG5ubpojRw719fW1qdsAzAfXqBc1lSpV0rp162p4eLh++OGHWrp0ae3Tp49+//332rNnT3V2drbJTjFjOzkKCgrSMmXKaP78+Y17+s3OnDmjbdu2tamDsblFaYYMGaK1OJw1a5ZmyZJFh/6/9u49Kqrz+hv4PkYiWkFw4Q2jXI2gBJVBKE4TIwq4xC5raoIUlKiD4q2oUYxIQSCsCgox2ChBgpGL2LIqt1i8VCwqRjCAmmVNDUqxWAWFiFwVmO/7B785YUBTheSdOeP+/DlDsvY4Z855zj772Xv7drUnlFJOkJaVlUEmk2HVqlU4c+YM/vSnP8HKygp2dnaQy+W9mpzqAqVSibq6OowbNw76+vpqN/XAD8k1hUKh9Tfy3Y+9rVu3wtraWpzKm56eDldX114DUk6cOKF2zpLy8auLSkpKMHHiRMyaNQsDBgzA6dOncfToUTg6OmLJkiVqyTUvLy+MGTMGf/7znzUYcd88efIErq6umDp1Ktzc3JCWlia+19LSgqSkJAwePBiBgYGaC7KfnlaZ99lnn6GzsxNeXl6YP38+ioqKxL/v7OyEi4uLuC1fql6GJuFPU1BQAAMDAyQkJKC1tRUHDx6EIAjiludHjx4hJCQEr7/+OsLDwzUcbd8EBwdj3rx5aq+Vl5fD2NgYGzZsANCVmMjMzNTaLZE/RnU9rKysFBMOmZmZEAQBH3zwQa8qvNzcXJibm0tuN9XVq1dhaWkJNze3XoOYjh07Bjs7O3FXlRTXCC0tLdi6dSuGDRsGV1dXLF++HHV1dWhra4OPjw8CAgKemlCS4md9mvr6erS1tUEmk2Hy5Mlicq375ztx4oRW/kY5scb6TLUdS6FQ6EzvkO5OnTqFsWPHihN0Hj16hKSkJNjY2GDNmjXi3924cQM3b96UZKlxfn4+vL29xSmu1dXVGD9+PPbu3YvW1lZs27YNv/zlLzFhwgS8+eabkkxUdE+MXb16FWVlZWrVPPfv3xdP3j2Ta0/7f2i7srIyTJgwAXK5vFeDz/3790NfXx/h4eGSOk5/TGlpKWQyGRQKBe7evYvHjx+jqalJrUeerui+qCgoKICVlRVmzJiBS5cuqf1dYWEhBEHA2rVrJXHsRkREwMTEBMXFxWr9uLKzszF37lx4eHggJycHc+fOxbRp03Rm8air1qxZA0EQ4OzsLL6Wlpb21OTa0qVLJVUt0V1bWxvu3r0LT09PzJo1C6mpqWrvx8XFYdSoUb0mDUrJsyrz8vLy8Pbbb2Pu3LlIT09HaWmp+CBSqt8n8PI0CX/aluugoCCxR15FRQVef/11cWCTSkNDAyIiIrTyhvZ/USqVWL58Odzd3QF0JYJVyYnU1FSMHDlS0kUBqmMxOzsbzs7O2LVrl3j9T0lJgSAI2LZtW69+cVIdPHH58mVMmzYN/v7+vQo8ioqKJLH2+V/+85//IDExEQ4ODrCxscGSJUvg6ekJT09PcReCVM9BANR2P/33v/9FdXW12vVSdX/WvXJt586dvQZyaRNOrLF+KSsrg5OTExYvXqxTT+6Arqc85ubmaluoGhoasGvXLjg6OqKioqLXfyOlsnGlUgl/f38IggBjY2OEhobi5s2biIqKwoIFC8Sy8c7OTtTW1kru4vvgwQO1C84f/vAHWFpawtLSEkOHDsXBgwfFbZAPHjyAo6Mj7O3tdeI4/rGK0qSkJNy4cUNDkf08ysrKMH36dHh5eelkkl9FtVBUnWdOnz4Nc3NzcQBHd0VFRWKPHG1WV1eHOXPmiBU/1dXVKCgogEKhwJEjR7B792688847MDMzw6xZs8SqYCkvJnVZS0sLXF1doVAoMGnSJCxevFh8Lz09HY6Ojr16rkndzZs34enpidmzZyMlJQUAEBoaCj8/P8k1Pe+pZ2We6vMBXZPYli5dCn19fdjY2MDGxkbSE+BflibhoaGh8PDw6DXMxtPTE5988gk6OjpgamqKVatWif8mycnJvQZ2aTOlUileL+vq6sQq56ysLAwaNAinTp0C8MN3p9oCK/Xfa15eHgYNGoRPP/201/X/0KFDEAQBISEhan11pfB9PouqwMPf3/+paz9dSK6pJCYmIjAwEIIgQBAEtQGCUqPqX6069nJycvDGG2/A1tYWJiYmSE1NxcOHDwF03Z85OTlh+PDhmDdvHvT19bX6OsOJNdZvJSUlmDlzpuRKiZ8lOTkZe/fuxenTp2FpaYkLFy6ovX/t2jW88soralMzpaLnBbS4uBje3t746KOP4OTkhNWrV0OhUMDW1ha7du3SUJT998Ybb6gN1wgLC8Po0aNx8uRJKJVK+Pr6wtDQEDExMWKFzIMHDzB+/Hj4+vpqKOqflq5XlPaka+ehnv7+979j7dq18PHxQVRUlDhp78SJEzA3N4ePjw8uX76s4ShfXH19PUxNTbF9+3YUFhbCy8sLTk5OcHR0xOjRo7F//358//33uHHjhiSrgl9GqpvYzz//HBMnToS3t7f4XkZGBqysrBAQEIDW1lZJ39R1d+vWLSxcuBB2dnZwdHTEsGHDek3olaqelXndk2tA17azyspKyTd7V9H1JuG1tbViNXv3B6ZRUVGYPHkyRo0ahXXr1qklDn19fbFp0yY8fvxYq3+zx44dU7sOHj16FHK5HNbW1ggNDUV+fj4CAwNha2urtob/8MMPIZPJJNtzFuh68O/u7o4dO3aovd69RY2qci0iIkJyCeFnUT1YXbRokaQGMTyvnr+3kpISvP/++/D09JTkzgx/f38sW7ZMPL/k5eXBwMAAsbGxuHXrFjZv3gwDAwPs3r1bbQfDtm3bEBwcrPX3M5xYYz8JXRnMoNoG8Nvf/hb19fViT7XuJ+vbt29jypQpkn3ifvr0aXGSTmdnJ9atW4f3338fDQ0NSEhIEKvYBEHolVSUgvDwcNjb24uLhsrKSnh6eiInJwdAV5m8sbExFixYAEEQEBMTI94QPHz4UJIL5WfR5YrSp9GV81BPWVlZ0NfXh0KhgJubGxwdHWFmZiZOMjt58iQmTJjQqx+ZVCQlJcHY2BiGhoYICgoSqwl8fHzg5+en9re6cjPwMmhsbERycjJsbGzUkmuZmZk6eQNUXV2Nzz//HOHh4To5NKV7Zd6hQ4cAdCUkAgICNBxZ/7xMTcK7J1n+8Y9/wNnZWRwQc+nSJcyYMQPW1tZiVXtbWxuCg4Px2muvqU1P10b37t2DhYUFli1bhoqKCly/fh1GRkaIjIxEYGAgZDIZFi9ejLi4OGzYsAF6enpwdnaGXC6HkZGRVlfBPI/a2lqMHz8eiYmJT31fdbymp6drfXLiRRUXF2PZsmU6vz5QJdmKi4uhr6+PwsJCDUf0YjIyMjBixAixrVBdXR0WLFggbrWvqqqCtbU1HBwcIAgCdu7cKT5EBqTxIIMTa4z9n6dtA7h48SKMjY3h5eWFhIQEnD17Fu7u7pDJZJL4gffU0dGBqKgoCIKApUuX4vz581AqlZg2bRrCwsIAdD2tXb9+PUxNTSW5ZXDTpk1wcHAA0NUQ/YMPPkBKSgoeP36Ms2fPwtTUFHv37gUAvPfeezAyMkJoaKhYmgxI4+T9vHS9kkvX1dbWYsqUKYiJiRFf++abb+Dm5gYLCwuxH8Xx48cxZcoU3LlzR1Oh9ktVVZXa+aazsxOzZ8/G9u3bNRgV66+mpiYkJyfDzs4Onp6emg6H9VP3yrzp06fD0NBQ0pV5L1OT8O79jCorK/Ho0SMYGRnh7bffFpNmaWlpePPNNzFmzBh4enpizpw5GDlypGSSTqqJkevWrUNkZKTa1Ozc3FzMmTMH7777LnJyclBYWIgPP/wQ0dHRklzrqr7L8vJy3L59Gw0NDZDJZE/dbVJaWoqdO3dKasDai1L9e7wsyTVHR0fxAYdUdJ8anpubi40bNyIpKQn37t1DTU0NbG1tsWLFCgDA6tWrYWxsjMjISLXKNW3HiTXGeui5DaCgoADz5s2Dqakp7O3tMWfOHElvAwC6enC5u7tDLpcjMDAQ+fn5+PWvf61WhSelExnww8Xm3LlzsLW1hb29PYYNG4bq6mqxT96qVauwbNky8ftbt24dpk2bBrlcLsmF8vPS1UouXdfe3o7vv/8eI0aMUNu20tHRgfLycjg4OGDv3r3iQrL7tEypamxsxLlz5zB//ny1PkZMupqamrBv3z44OTmpDY5h0qSLlXm63CS8+0NDoKufkYmJCW7fvo2amhqMHTsWM2bMEPsGX7lyBbGxsVi5ciXi4uKeOdRJW5WWlsLJyQlmZmbYunWr2nu5ubmYNWsW3nnnHUkO41JRHYtZWVkwNTVFSEgIACAgIAAmJia4cOGC2vEaHByMOXPmSHqr6/OQ6m/0RX322WcQBOGpvb61Wfep4YIgICcnR9wx9NFHH8Hd3V08Rnfs2IHXXnsNw4cPl1SbAU6ssZfe82wDaGhoQE1NDW7duiWeuKV+w3fv3j2kpqZi6tSpGDp0KCwsLNT6kkmZh4cHBEFQG6ve0tKC2bNniwlTAFi4cCEuX74sfqcvy0WZab+vv/4aAQEBqKmpgbOzM4KDg9XeVyqVcHJyUjuepX78KpVKnDlzBvPnz4eHh4fkH2CwHzQ3N4vNiBnTZrrUJFzVz0h1Lq2qqoK3tzcSEhLEBzL37t0Tk2vavt3zeV25cgUWFhaQy+W9BjgdO3YMU6dOhY+PD5qbmyV73fzyyy8xePBgHDhwQO3+ZdGiRRgxYgTCwsKwc+dO+Pv7w8DAQNzyy6SvoqJCstt5VVPDXVxc1F5XKBRYtGiReG+9adMmFBQUSK7IYwAx9hJrbW2lmpoaioyMJD8/P1qxYgXV19eTr68vLVy4kD7++GN68uQJGRoa0siRI8nCwoIEQSClUkkDBw7UdPj9MmrUKPL19aWvv/6aVq5cSXfv3qXk5GRqbGzUdGj9Ul9fT3p6ehQeHk7//ve/ydfXl4iIBg8eTHK5nBISEsjHx4ccHBzoX//6F02ePJkEQSAAJAiChqNnrMtXX31F58+fp1u3bpFcLqdTp07R0aNHxfcFQaCxY8eSkZERoeshmeSPX0EQyMXFhSIiIuhvf/sb6enpUUdHB73yyiuaDo3105AhQ2jYsGGaDoOxZwJARET+/v60Z88eKi4uJj8/P/rqq6/o0aNHGo7uxR05coSys7Pp97//Penp6VF5eTlFRkZSdXU1ubq60oABA+jJkyc0atQoKi0tpaqqKgoICKArV65oOvR+s7e3p+zsbGpubqb4+Hi6du2a+N68efMoOjqaoqKiaMiQIZK8bra1tdGhQ4do48aNpFAoaPjw4fTdd99RbGwsrVy5kmbOnEllZWWUlpZGDx48oKKiIrK3t9d02OwnYmVlRZMmTdJ0GC+stbWVvv32W1qxYgU1NDSI92dERNbW1pSXl0dBQUHk7e1NBw4coDFjxpCRkZHmAu4DAaorCWMvserqasrPz6eEhARqaWmh6dOnU319PRF1LU6GDh2qEzeuPXX/TAUFBWRlZUVmZmYajqr/Ojs7acCAAXTw4EHatWsXTZs2jQ4fPkxERJGRkXT9+nUaNmwYxcfHk56eHnV2dvLNO9MKLS0tNGTIECIimjlzJhkaGlJWVha9++67dOfOHZLL5TRjxgw6e/YspaSkUHFxMdnY2Gg46p+HUqmkAQP4+R9j7P8v1dqopKSEZs6cSSdOnKC33npL02G9kF27dlFycjJdv36djh8/TkFBQfTkyROqqqqi7Oxs8vDwICKiJ0+e0Kuvvkq1tbVkZmZGrq6ulJWVRa+++qqGP0H/lZeXk0KhIAcHB9q4caMkkxFP09raSm+99Ra5uLjQjh07KCwsjK5evUo3btygQYMG0fr162nNmjXU0dFBAwcOpMGDB2s6ZMaI6Ic1bnJyMsXExJCDg4N4f7Zt2zY6d+4cGRgYUHR0tCSTwZxYY6yHAwcO0LVr1yg+Pp6IuhIx27dv13BUPx9dTBiqNDc301/+8heKjo4mmUxG6enpRET0+PFjGjRoEBGRuPBgTNOOHz9OKSkp5OfnRx4eHnTnzh2aMWMGbdmyhRQKBUVERNCZM2eorq6ORo8eTfHx8TR16lRNh80YYzpHtTaaPn06rV+/npYuXarpkF7IpUuXaMmSJWRqakqFhYV08uRJam9vp82bN5OlpSWFhoaSo6MjERG1t7eTnp4e3b9/nx4+fEgTJkzQcPQ/nfLycgoICCBLS0sKCwvTmQdRKSkpFBAQQHp6ejR79mz6zW9+Q0uXLqXAwED65ptv6OTJk7y2ZVqrqamJMjMzKTo6Wi251tDQQPr6+uI9mtRwYo2x/9MzwXTp0iXat28f3b9/nw4fPkyGhoYajI71VXNzM2VmZtLu3btp3LhxlJ+fr+mQGOsFAK1atYqSkpLIyMiI1q9fT35+fnTkyBEqKSmh6OhomjhxIimVSqqrq6MhQ4bQL37xC02HzRhjOisxMZECAgLou+++IysrK02H88LWrl1L+/fvJycnJ7p48SIREWVkZFBcXBzZ2trShg0byMHBgYh+SK7pokuXLtGWLVsoIyODxowZo+lwfjL//Oc/6c6dO+Tm5iZWeK9bt44aGxspMTFRsskJ9nJQFT/ExcWRubk55eXlaTqkfuPEGmNPoQvbANgPmpub6YsvvqCioiJKS0vj7WVMK5WUlNCePXto8uTJlJubSzKZjNrb26moqIiWL19Omzdv1nSIjDH20rh58yY9fvxYklsIW1tbaf78+WRpaUkXLlwge3t7ysjIICKiw4cP08cff0x2dna0evVqcnJy0nC0P7+2tjbS19fXdBg/m2+//ZZSU1Pp008/pfPnz5OdnZ2mQ2Lsf2pubqaUlBT64osvKCsri0xNTTUdUr9wYo2xZ5D6NgCmrq2tjQYNGiQOn+DkGtMGBQUFVFlZSStWrCClUkmBgYHU1NREn3zyCWVkZFBpaSklJSUREVFRURG5uLhoOGLGGGNS8GP9jI4cOUIhISHk5uZGe/bs4eomCSstLaXY2Fi6fPkyZWRk0JQpUzQdEmPPraWlhdrb23ViwBFvvmbsGQRBoMTERCotLSW5XK7pcFg/qZ5UAuCkGtMKnZ2ddPHiRQoJCaGzZ8/SypUrKT4+nmQyGcXFxdGOHTuosbGR9PX16a9//SuZmJhoOmTGGGMSoRqE895775EgCBQTE0O/+93v6PDhw7R48WIaOHAgyWQyTqpJ3KRJk2j16tVkbm5O48aN03Q4jL0Q1XlKF3DFGmM/QsrbABhj0nD16lXasmULNTc3k6OjI82dO5f27dtHQUFB9Ktf/YqIiB4+fCi5seOMMca0Q/d+RmZmZvTll19qOiTGGNMpnFhjjDHGNKympoZOnTpFsbGxVFFRQSNGjCAvLy/64x//qOnQGGOM6YDu/YyOHj1KY8eO1XRIjDGmMzixxhhjjGmJzs5OCgoKon379pGhoSFVVFSQgYGBpsNijDGmA3SpnxFjjGkTTqwxxhhjWkA1MIWoa6iBlZUVmZmZaTgqxhhjjDHG2I/hxBpjjDGmJbon1xhjjDHGGGPaj0fjMcYYY1qCk2qMMcYYY4xJCyfWGGOMMcYYY4wxxhjrA06sMcYYY4wxxhhjjDHWB5xYY4wxxhhjjDHGGGOsDzixxhhjjDHGGGOMMcZYH3BijTHGGGOMMcYYY4yxPuDEGmOMMcYYY4wxxhhjfcCJNcYYY4wxxhhjjDHG+oATa4wxxhhjjDHGGGOM9QEn1hhjjDHGGGOMMcYY6wNOrDHGGGOMMcYYY4wx1gf/D45BXwHAcBVnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(\n",
    "    {\"counts\": TF_IDF_matrix.toarray().sum(axis=0)},\n",
    "    index=vectorizer.get_feature_names_out()\n",
    ").sort_values(\"counts\", ascending=False)\n",
    "\n",
    "word_counts.head(20).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "plt.title(\"Top 20 most frequently occurring words within Movie Description\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b3f7d-83ae-4e4b-8b71-8f89e0367fc2",
   "metadata": {},
   "source": [
    "Now that we have our first run at our TF IDF Vectorized data, lets calculate cosine similarity.\n",
    "\n",
    "We will look once again at Raiders of the Lost Arc and since we know (from extensive bakground research) that it is a Indiana Jones movie, let compare it to another Indy movie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f46daa46-903f-462b-a918-cf6984413f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5fc86a4c6758f6963478d502</td>\n",
       "      <td>[\"Adventure\",\"Action\"]</td>\n",
       "      <td>raiders-of-the-lost-ark</td>\n",
       "      <td>en</td>\n",
       "      <td>When Dr. Indiana Jones  the tweed-suited prof...</td>\n",
       "      <td>30.782</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>8.481832</td>\n",
       "      <td>3908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         _id                  genres                 movie_id  \\\n",
       "80  5fc86a4c6758f6963478d502  [\"Adventure\",\"Action\"]  raiders-of-the-lost-ark   \n",
       "\n",
       "   original_language                                           overview  \\\n",
       "80                en  When Dr. Indiana Jones  the tweed-suited prof...   \n",
       "\n",
       "    popularity  runtime  year_released  avg_rating  rating_count  \n",
       "80      30.782    115.0         1981.0    8.481832          3908  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Raiders of the Lost Arc\n",
    "df.loc[df['movie_id']=='raiders-of-the-lost-ark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a359d51c-df3b-483a-8c1a-a49ed3829243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>5fc8721c6758f696349b5400</td>\n",
       "      <td>[\"Adventure\",\"Action\"]</td>\n",
       "      <td>indiana-jones-and-the-temple-of-doom</td>\n",
       "      <td>en</td>\n",
       "      <td>After arriving in India, Indiana Jones is aske...</td>\n",
       "      <td>24.882</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>7.048237</td>\n",
       "      <td>3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>5fc877f76758f69634b57588</td>\n",
       "      <td>[\"Adventure\",\"Action\"]</td>\n",
       "      <td>indiana-jones-and-the-kingdom-of-the-crystal-s...</td>\n",
       "      <td>en</td>\n",
       "      <td>Set during the Cold War, the Sovietsled by sw...</td>\n",
       "      <td>23.291</td>\n",
       "      <td>122.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>4.994582</td>\n",
       "      <td>2584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>5fc883786758f69634f03a12</td>\n",
       "      <td>[\"Adventure\",\"Action\"]</td>\n",
       "      <td>indiana-jones-and-the-last-crusade</td>\n",
       "      <td>en</td>\n",
       "      <td>When Dr. Henry Jones Sr. suddenly goes missing...</td>\n",
       "      <td>24.824</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>8.033586</td>\n",
       "      <td>3037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id                  genres  \\\n",
       "1181  5fc8721c6758f696349b5400  [\"Adventure\",\"Action\"]   \n",
       "2307  5fc877f76758f69634b57588  [\"Adventure\",\"Action\"]   \n",
       "4406  5fc883786758f69634f03a12  [\"Adventure\",\"Action\"]   \n",
       "\n",
       "                                               movie_id original_language  \\\n",
       "1181               indiana-jones-and-the-temple-of-doom                en   \n",
       "2307  indiana-jones-and-the-kingdom-of-the-crystal-s...                en   \n",
       "4406                 indiana-jones-and-the-last-crusade                en   \n",
       "\n",
       "                                               overview  popularity  runtime  \\\n",
       "1181  After arriving in India, Indiana Jones is aske...      24.882    118.0   \n",
       "2307  Set during the Cold War, the Sovietsled by sw...      23.291    122.0   \n",
       "4406  When Dr. Henry Jones Sr. suddenly goes missing...      24.824    127.0   \n",
       "\n",
       "      year_released  avg_rating  rating_count  \n",
       "1181         1984.0    7.048237          3006  \n",
       "2307         2008.0    4.994582          2584  \n",
       "4406         1989.0    8.033586          3037  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking for another Indiana Jones movie\n",
    "df[df['movie_id'].str.contains('indiana-jones', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025c4af-2adc-4576-b21a-adb460c8c2f7",
   "metadata": {},
   "source": [
    "Lets check the similarity between two here.\n",
    "\n",
    "**Note** that a score of +1 indicates perfect similarity, -1 perfect dissimilarity, and 0 Orthoganility (no similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d5c3831-8c53-473e-8ed3-a9d967559710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: [[0.12076394]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "movie_1 = TF_IDF_matrix[(df['movie_id'] == 'raiders-of-the-lost-ark').values,]\n",
    "movie_2 = TF_IDF_matrix[(df['movie_id'] == 'indiana-jones-and-the-last-crusade').values,]\n",
    "\n",
    "print(\"Similarity:\", cosine_similarity(movie_1, movie_2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd23eb-8da9-4607-8f11-f4c781520434",
   "metadata": {},
   "source": [
    "It is unclear how strong of a score this is without comparing it to more movies in our dataset, but there is certainly some positive similarity there. It can be noted that we only did a first pass at vectorization. We can revisit this later and potentially improve this.\n",
    "\n",
    "Now lets compute the similarity between each column and every other column, giving back a square matrix, aka like a correlation matrix for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d501072-ef0e-4aa8-a284-5dbdc0eacc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "\n",
    "#Creating our square matrix for similarity\n",
    "similarities = cosine_similarity(TF_IDF_matrix, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7008be17-e0c0-496e-8dcf-969bdc5fe79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5061, 5061)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape\n",
    "# rows and columns should be equal, and the number of movies we started with (rows)\n",
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a76b15b0-9ee9-48af-ab82-42bce2df2cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5061"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of movies we started with\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fdfd10-ea91-4a9b-a6da-1b6fd57a4aa2",
   "metadata": {},
   "source": [
    "Perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c849ece3-d0c4-40b1-913c-7d07e8f93b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5061x5061 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5750667 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d7e59-8e8e-432c-9b44-a0491842a52f",
   "metadata": {},
   "source": [
    "Wow our similarities Sparse matrix contains 5,750,667 elements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52e279-ac85-4bf6-b1bf-e75dd1769ca7",
   "metadata": {},
   "source": [
    "Lets work with Raiders of the Lost Ark again and take its column in the similarity matrix, and then finding those rows where the similarities are highest, return the 10 most similar movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5fd40069-e20e-4534-8272-39736019e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column based upon the index\n",
    "movie_index = df[df['movie_id'] == 'raiders-of-the-lost-ark'].index\n",
    "\n",
    "# Create a dataframe with the movie titles\n",
    "sim_df = pd.DataFrame({'movie':df['movie_id'], \n",
    "                       'similarity': np.array(similarities[movie_index, :].todense()).squeeze()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2e370dc2-c45a-4756-882d-87d495c714e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>raiders-of-the-lost-ark</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>a-serious-man</td>\n",
       "      <td>0.434499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>pawn-sacrifice</td>\n",
       "      <td>0.323655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>flubber</td>\n",
       "      <td>0.312888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>luxo-jr</td>\n",
       "      <td>0.302468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>good-will-hunting</td>\n",
       "      <td>0.290531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>horror-express</td>\n",
       "      <td>0.287779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>the-stanford-prison-experiment</td>\n",
       "      <td>0.286782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>the-cider-house-rules</td>\n",
       "      <td>0.284619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>the-nutty-professor-1996</td>\n",
       "      <td>0.276434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movie  similarity\n",
       "80           raiders-of-the-lost-ark    1.000000\n",
       "4330                   a-serious-man    0.434499\n",
       "696                   pawn-sacrifice    0.323655\n",
       "4221                         flubber    0.312888\n",
       "2128                         luxo-jr    0.302468\n",
       "1655               good-will-hunting    0.290531\n",
       "847                   horror-express    0.287779\n",
       "1304  the-stanford-prison-experiment    0.286782\n",
       "115            the-cider-house-rules    0.284619\n",
       "2930        the-nutty-professor-1996    0.276434"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the top 10 most similar movies\n",
    "sim_df.sort_values(by='similarity', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a937ee-55df-4127-bca8-3367567e16ce",
   "metadata": {},
   "source": [
    "This is doing an okay job at suggesting movies, we don't see other Indiana Jones movies which is probably not the greatest sign. However, we are **only** using description column. I think using the genre coumn would be greatly beneficial as well.\n",
    "\n",
    "In order to use more columns we will turn our sparse matrix into a dataframe and merge it onto our existing dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18f16cbb-2b4f-49bc-bd64-0e9b95105ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the TF-IDF matrix\n",
    "tfidf_df = pd.DataFrame(TF_IDF_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Reset the index of the movie_df for concatenation\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate the original dataset (movie_df) and the TF-IDF matrix DataFrame (tfidf_df)\n",
    "merged_df = pd.concat([df, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "602fb139-7ac0-4072-bee4-14a227bcddf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>...</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fc85ff26758f696344ad07f</td>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>en</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17549</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fc85ff26758f696344aceeb</td>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>en</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fc85ff26758f696344acf29</td>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>en</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5fc85ff26758f696344ad019</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>en</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fc85ff26758f696344ad100</td>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>en</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>61b645960109cc2a5dcd8d76</td>\n",
       "      <td>[\"Action\",\"Adventure\",\"Thriller\"]</td>\n",
       "      <td>the-kings-man</td>\n",
       "      <td>en</td>\n",
       "      <td>As a collection of history's worst tyrants and...</td>\n",
       "      <td>56.179</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.307355</td>\n",
       "      <td>911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>61ccb7590109cc2a5d628e1d</td>\n",
       "      <td>[\"Drama\",\"Science Fiction\"]</td>\n",
       "      <td>ex-machina-2015</td>\n",
       "      <td>en</td>\n",
       "      <td>Caleb, a coder at the world's largest internet...</td>\n",
       "      <td>26.475</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>7.990072</td>\n",
       "      <td>3324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>61d1aad90109cc2a5d83d806</td>\n",
       "      <td>[\"Documentary\"]</td>\n",
       "      <td>harry-potter-20th-anniversary-return-to-hogwarts</td>\n",
       "      <td>en</td>\n",
       "      <td>An enchanting making-of story told through all...</td>\n",
       "      <td>583.354</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>7.605364</td>\n",
       "      <td>522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>61dd43eb0109cc2a5d12ee62</td>\n",
       "      <td>[\"Comedy\",\"Horror\"]</td>\n",
       "      <td>house-1985</td>\n",
       "      <td>en</td>\n",
       "      <td>Roger Cobb is an author who has just separated...</td>\n",
       "      <td>12.058</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>6.154905</td>\n",
       "      <td>581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>61e320bc0109cc2a5d9e7875</td>\n",
       "      <td>[\"Horror\",\"Mystery\",\"Thriller\"]</td>\n",
       "      <td>scream-2022</td>\n",
       "      <td>en</td>\n",
       "      <td>Twenty-five years after a streak of brutal mur...</td>\n",
       "      <td>588.452</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>6.696850</td>\n",
       "      <td>1778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5061 rows  510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id  \\\n",
       "0     5fc85ff26758f696344ad07f   \n",
       "1     5fc85ff26758f696344aceeb   \n",
       "2     5fc85ff26758f696344acf29   \n",
       "3     5fc85ff26758f696344ad019   \n",
       "4     5fc85ff26758f696344ad100   \n",
       "...                        ...   \n",
       "5056  61b645960109cc2a5dcd8d76   \n",
       "5057  61ccb7590109cc2a5d628e1d   \n",
       "5058  61d1aad90109cc2a5d83d806   \n",
       "5059  61dd43eb0109cc2a5d12ee62   \n",
       "5060  61e320bc0109cc2a5d9e7875   \n",
       "\n",
       "                                                 genres  \\\n",
       "0                                 [\"Horror\",\"Thriller\"]   \n",
       "1                                     [\"Crime\",\"Drama\"]   \n",
       "2                           [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3     [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                   [\"Romance\",\"Drama\"]   \n",
       "...                                                 ...   \n",
       "5056                  [\"Action\",\"Adventure\",\"Thriller\"]   \n",
       "5057                        [\"Drama\",\"Science Fiction\"]   \n",
       "5058                                    [\"Documentary\"]   \n",
       "5059                                [\"Comedy\",\"Horror\"]   \n",
       "5060                    [\"Horror\",\"Mystery\",\"Thriller\"]   \n",
       "\n",
       "                                              movie_id original_language  \\\n",
       "0                       house-at-the-end-of-the-street                en   \n",
       "1                               green-street-hooligans                en   \n",
       "2                                beverly-hills-cop-iii                en   \n",
       "3                                          bad-boys-ii                en   \n",
       "4                                         a-single-man                en   \n",
       "...                                                ...               ...   \n",
       "5056                                     the-kings-man                en   \n",
       "5057                                   ex-machina-2015                en   \n",
       "5058  harry-potter-20th-anniversary-return-to-hogwarts                en   \n",
       "5059                                        house-1985                en   \n",
       "5060                                       scream-2022                en   \n",
       "\n",
       "                                               overview  popularity  runtime  \\\n",
       "0     A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1     After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2     Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3     Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4     The life of George Falconer, a British college...      11.640     97.0   \n",
       "...                                                 ...         ...      ...   \n",
       "5056  As a collection of history's worst tyrants and...      56.179    131.0   \n",
       "5057  Caleb, a coder at the world's largest internet...      26.475    108.0   \n",
       "5058  An enchanting making-of story told through all...     583.354    103.0   \n",
       "5059  Roger Cobb is an author who has just separated...      12.058     93.0   \n",
       "5060  Twenty-five years after a streak of brutal mur...     588.452    114.0   \n",
       "\n",
       "      year_released  avg_rating  rating_count  ...  working  works     world  \\\n",
       "0            2012.0    3.880987           689  ...      0.0    0.0  0.000000   \n",
       "1            2005.0    5.953771           411  ...      0.0    0.0  0.168197   \n",
       "2            1994.0    4.492424           528  ...      0.0    0.0  0.000000   \n",
       "3            2003.0    6.021593          1343  ...      0.0    0.0  0.000000   \n",
       "4            2009.0    7.660256          1404  ...      0.0    0.0  0.000000   \n",
       "...             ...         ...           ...  ...      ...    ...       ...   \n",
       "5056         2021.0    5.307355           911  ...      0.0    0.0  0.000000   \n",
       "5057         2015.0    7.990072          3324  ...      0.0    0.0  0.332734   \n",
       "5058         2022.0    7.605364           522  ...      0.0    0.0  0.000000   \n",
       "5059         1985.0    6.154905           581  ...      0.0    0.0  0.000000   \n",
       "5060         2022.0    6.696850          1778  ...      0.0    0.0  0.000000   \n",
       "\n",
       "      writer  wrong  year     years  york    young  younger  \n",
       "0        0.0    0.0   0.0  0.000000   0.0  0.17549      0.0  \n",
       "1        0.0    0.0   0.0  0.000000   0.0  0.00000      0.0  \n",
       "2        0.0    0.0   0.0  0.000000   0.0  0.00000      0.0  \n",
       "3        0.0    0.0   0.0  0.000000   0.0  0.00000      0.0  \n",
       "4        0.0    0.0   0.0  0.000000   0.0  0.00000      0.0  \n",
       "...      ...    ...   ...       ...   ...      ...      ...  \n",
       "5056     0.0    0.0   0.0  0.000000   0.0  0.00000      0.0  \n",
       "5057     0.0    0.0   0.0  0.000000   0.0  0.00000      0.0  \n",
       "5058     0.0    0.0   0.0  0.000000   0.0  0.00000      0.0  \n",
       "5059     0.0    0.0   0.0  0.000000   0.0  0.00000      0.0  \n",
       "5060     0.0    0.0   0.0  0.253042   0.0  0.00000      0.0  \n",
       "\n",
       "[5061 rows x 510 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf267fb5-d9f9-4979-b815-ded6fefe5a63",
   "metadata": {},
   "source": [
    "Cool! Now that we have that done lets take a look at genres.\n",
    "\n",
    "## Genres - MultiLabel Binarizer\n",
    "We will use Sk Learn's MultiLabelBinarizer to transform the genres into a multi-binary representation of our genre column. With this approach we can account for a movie falling under several genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5de0b0f5-b6b7-41dc-957e-320459f2e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new version of our df to save our progress\n",
    "movie_df = merged_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c355b90-5aca-4db9-9502-0453f256dc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>...</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fc85ff26758f696344ad07f</td>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>en</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17549</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fc85ff26758f696344aceeb</td>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>en</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fc85ff26758f696344acf29</td>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>en</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5fc85ff26758f696344ad019</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>en</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fc85ff26758f696344ad100</td>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>en</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5fc85ff26758f696344ad07f   \n",
       "1  5fc85ff26758f696344aceeb   \n",
       "2  5fc85ff26758f696344acf29   \n",
       "3  5fc85ff26758f696344ad019   \n",
       "4  5fc85ff26758f696344ad100   \n",
       "\n",
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id original_language  \\\n",
       "0  house-at-the-end-of-the-street                en   \n",
       "1          green-street-hooligans                en   \n",
       "2           beverly-hills-cop-iii                en   \n",
       "3                     bad-boys-ii                en   \n",
       "4                    a-single-man                en   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  ...  working  works     world  \\\n",
       "0         2012.0    3.880987           689  ...      0.0    0.0  0.000000   \n",
       "1         2005.0    5.953771           411  ...      0.0    0.0  0.168197   \n",
       "2         1994.0    4.492424           528  ...      0.0    0.0  0.000000   \n",
       "3         2003.0    6.021593          1343  ...      0.0    0.0  0.000000   \n",
       "4         2009.0    7.660256          1404  ...      0.0    0.0  0.000000   \n",
       "\n",
       "   writer  wrong  year  years  york    young  younger  \n",
       "0     0.0    0.0   0.0    0.0   0.0  0.17549      0.0  \n",
       "1     0.0    0.0   0.0    0.0   0.0  0.00000      0.0  \n",
       "2     0.0    0.0   0.0    0.0   0.0  0.00000      0.0  \n",
       "3     0.0    0.0   0.0    0.0   0.0  0.00000      0.0  \n",
       "4     0.0    0.0   0.0    0.0   0.0  0.00000      0.0  \n",
       "\n",
       "[5 rows x 510 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc604f1f-dbc7-417f-959c-34b307469715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1388"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df['genres'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97366848-db88-47fa-abcc-a9db45cce119",
   "metadata": {},
   "source": [
    "We can see we have 1388 unique combinations of movie genres. Our multi label binarizer is an excellent way to account for all of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df943594-4b55-414e-b8bc-dd1b341e2883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5061 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Action  Adventure  Animation  Comedy  Crime  Documentary  Drama  Family  \\\n",
       "0          0          0          0       0      0            0      0       0   \n",
       "1          0          0          0       0      1            0      1       0   \n",
       "2          1          0          0       1      1            0      0       0   \n",
       "3          1          1          0       1      1            0      0       0   \n",
       "4          0          0          0       0      0            0      1       0   \n",
       "...      ...        ...        ...     ...    ...          ...    ...     ...   \n",
       "5056       1          1          0       0      0            0      0       0   \n",
       "5057       0          0          0       0      0            0      1       0   \n",
       "5058       0          0          0       0      0            1      0       0   \n",
       "5059       0          0          0       1      0            0      0       0   \n",
       "5060       0          0          0       0      0            0      0       0   \n",
       "\n",
       "      Fantasy  History  Horror  Music  Mystery  Romance  Science Fiction  \\\n",
       "0           0        0       1      0        0        0                0   \n",
       "1           0        0       0      0        0        0                0   \n",
       "2           0        0       0      0        0        0                0   \n",
       "3           0        0       0      0        0        0                0   \n",
       "4           0        0       0      0        0        1                0   \n",
       "...       ...      ...     ...    ...      ...      ...              ...   \n",
       "5056        0        0       0      0        0        0                0   \n",
       "5057        0        0       0      0        0        0                1   \n",
       "5058        0        0       0      0        0        0                0   \n",
       "5059        0        0       1      0        0        0                0   \n",
       "5060        0        0       1      0        1        0                0   \n",
       "\n",
       "      TV Movie  Thriller  War  Western  \n",
       "0            0         1    0        0  \n",
       "1            0         0    0        0  \n",
       "2            0         0    0        0  \n",
       "3            0         1    0        0  \n",
       "4            0         0    0        0  \n",
       "...        ...       ...  ...      ...  \n",
       "5056         0         1    0        0  \n",
       "5057         0         0    0        0  \n",
       "5058         0         0    0        0  \n",
       "5059         0         0    0        0  \n",
       "5060         0         1    0        0  \n",
       "\n",
       "[5061 rows x 19 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Convert the genres column from string representation to a list of genres\n",
    "movie_df['genres'] = movie_df['genres'].apply(eval)  \n",
    "\n",
    "# Initialize the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Transform and add new encoded genre columns\n",
    "encoded_genres = mlb.fit_transform(movie_df['genres'])\n",
    "encoded_genres_df = pd.DataFrame(encoded_genres, columns=mlb.classes_)\n",
    "\n",
    "#Sanity Check\n",
    "encoded_genres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59f59e3e-1afa-4a5e-b247-8bf84dd06ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the encoded genres with our dataset\n",
    "merged_df = pd.concat([merged_df, encoded_genres_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a3ce466-fb90-4e32-8dc0-5e5da88cadd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>000</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>agent</th>\n",
       "      <th>alex</th>\n",
       "      <th>alice</th>\n",
       "      <th>alien</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>ancient</th>\n",
       "      <th>angeles</th>\n",
       "      <th>apart</th>\n",
       "      <th>army</th>\n",
       "      <th>arrives</th>\n",
       "      <th>art</th>\n",
       "      <th>artist</th>\n",
       "      <th>attack</th>\n",
       "      <th>attempt</th>\n",
       "      <th>attempts</th>\n",
       "      <th>away</th>\n",
       "      <th>baby</th>\n",
       "      <th>bad</th>\n",
       "      <th>band</th>\n",
       "      <th>based</th>\n",
       "      <th>battle</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>begin</th>\n",
       "      <th>begins</th>\n",
       "      <th>best</th>\n",
       "      <th>big</th>\n",
       "      <th>black</th>\n",
       "      <th>body</th>\n",
       "      <th>bond</th>\n",
       "      <th>book</th>\n",
       "      <th>born</th>\n",
       "      <th>boss</th>\n",
       "      <th>boy</th>\n",
       "      <th>boyfriend</th>\n",
       "      <th>break</th>\n",
       "      <th>bring</th>\n",
       "      <th>brings</th>\n",
       "      <th>british</th>\n",
       "      <th>brother</th>\n",
       "      <th>brothers</th>\n",
       "      <th>business</th>\n",
       "      <th>california</th>\n",
       "      <th>called</th>\n",
       "      <th>camp</th>\n",
       "      <th>captain</th>\n",
       "      <th>car</th>\n",
       "      <th>career</th>\n",
       "      <th>case</th>\n",
       "      <th>caught</th>\n",
       "      <th>century</th>\n",
       "      <th>chance</th>\n",
       "      <th>change</th>\n",
       "      <th>charlie</th>\n",
       "      <th>child</th>\n",
       "      <th>childhood</th>\n",
       "      <th>children</th>\n",
       "      <th>christmas</th>\n",
       "      <th>cia</th>\n",
       "      <th>city</th>\n",
       "      <th>class</th>\n",
       "      <th>classic</th>\n",
       "      <th>college</th>\n",
       "      <th>come</th>\n",
       "      <th>comedy</th>\n",
       "      <th>comes</th>\n",
       "      <th>community</th>\n",
       "      <th>company</th>\n",
       "      <th>confront</th>\n",
       "      <th>control</th>\n",
       "      <th>cop</th>\n",
       "      <th>country</th>\n",
       "      <th>couple</th>\n",
       "      <th>course</th>\n",
       "      <th>creatures</th>\n",
       "      <th>crew</th>\n",
       "      <th>crime</th>\n",
       "      <th>criminal</th>\n",
       "      <th>cross</th>\n",
       "      <th>dangerous</th>\n",
       "      <th>dark</th>\n",
       "      <th>daughter</th>\n",
       "      <th>david</th>\n",
       "      <th>day</th>\n",
       "      <th>days</th>\n",
       "      <th>dead</th>\n",
       "      <th>deadly</th>\n",
       "      <th>deal</th>\n",
       "      <th>death</th>\n",
       "      <th>decide</th>\n",
       "      <th>decides</th>\n",
       "      <th>deep</th>\n",
       "      <th>desperate</th>\n",
       "      <th>despite</th>\n",
       "      <th>destroy</th>\n",
       "      <th>detective</th>\n",
       "      <th>determined</th>\n",
       "      <th>different</th>\n",
       "      <th>director</th>\n",
       "      <th>discover</th>\n",
       "      <th>discovers</th>\n",
       "      <th>doctor</th>\n",
       "      <th>documentary</th>\n",
       "      <th>does</th>\n",
       "      <th>doesn</th>\n",
       "      <th>dog</th>\n",
       "      <th>don</th>\n",
       "      <th>dr</th>\n",
       "      <th>dream</th>\n",
       "      <th>dreams</th>\n",
       "      <th>driver</th>\n",
       "      <th>drug</th>\n",
       "      <th>earth</th>\n",
       "      <th>eccentric</th>\n",
       "      <th>embark</th>\n",
       "      <th>embarks</th>\n",
       "      <th>encounter</th>\n",
       "      <th>end</th>\n",
       "      <th>ends</th>\n",
       "      <th>enemy</th>\n",
       "      <th>england</th>\n",
       "      <th>english</th>\n",
       "      <th>entire</th>\n",
       "      <th>epic</th>\n",
       "      <th>escape</th>\n",
       "      <th>estranged</th>\n",
       "      <th>eve</th>\n",
       "      <th>events</th>\n",
       "      <th>eventually</th>\n",
       "      <th>evil</th>\n",
       "      <th>ex</th>\n",
       "      <th>existence</th>\n",
       "      <th>experience</th>\n",
       "      <th>eye</th>\n",
       "      <th>face</th>\n",
       "      <th>faces</th>\n",
       "      <th>fall</th>\n",
       "      <th>falls</th>\n",
       "      <th>family</th>\n",
       "      <th>famous</th>\n",
       "      <th>far</th>\n",
       "      <th>fate</th>\n",
       "      <th>father</th>\n",
       "      <th>fbi</th>\n",
       "      <th>fear</th>\n",
       "      <th>fellow</th>\n",
       "      <th>fight</th>\n",
       "      <th>fighting</th>\n",
       "      <th>film</th>\n",
       "      <th>final</th>\n",
       "      <th>finally</th>\n",
       "      <th>finds</th>\n",
       "      <th>following</th>\n",
       "      <th>follows</th>\n",
       "      <th>force</th>\n",
       "      <th>forced</th>\n",
       "      <th>forces</th>\n",
       "      <th>forever</th>\n",
       "      <th>form</th>\n",
       "      <th>frank</th>\n",
       "      <th>free</th>\n",
       "      <th>friend</th>\n",
       "      <th>friends</th>\n",
       "      <th>friendship</th>\n",
       "      <th>future</th>\n",
       "      <th>game</th>\n",
       "      <th>gang</th>\n",
       "      <th>george</th>\n",
       "      <th>gets</th>\n",
       "      <th>getting</th>\n",
       "      <th>girl</th>\n",
       "      <th>girlfriend</th>\n",
       "      <th>girls</th>\n",
       "      <th>global</th>\n",
       "      <th>goes</th>\n",
       "      <th>going</th>\n",
       "      <th>good</th>\n",
       "      <th>government</th>\n",
       "      <th>great</th>\n",
       "      <th>group</th>\n",
       "      <th>guy</th>\n",
       "      <th>hands</th>\n",
       "      <th>hard</th>\n",
       "      <th>harry</th>\n",
       "      <th>having</th>\n",
       "      <th>head</th>\n",
       "      <th>heart</th>\n",
       "      <th>heist</th>\n",
       "      <th>hell</th>\n",
       "      <th>help</th>\n",
       "      <th>henry</th>\n",
       "      <th>hero</th>\n",
       "      <th>high</th>\n",
       "      <th>history</th>\n",
       "      <th>hit</th>\n",
       "      <th>holiday</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>home</th>\n",
       "      <th>hope</th>\n",
       "      <th>horror</th>\n",
       "      <th>hospital</th>\n",
       "      <th>hotel</th>\n",
       "      <th>house</th>\n",
       "      <th>human</th>\n",
       "      <th>humanity</th>\n",
       "      <th>humans</th>\n",
       "      <th>hunt</th>\n",
       "      <th>husband</th>\n",
       "      <th>identity</th>\n",
       "      <th>ii</th>\n",
       "      <th>including</th>\n",
       "      <th>increasingly</th>\n",
       "      <th>inside</th>\n",
       "      <th>international</th>\n",
       "      <th>investigate</th>\n",
       "      <th>involved</th>\n",
       "      <th>island</th>\n",
       "      <th>jack</th>\n",
       "      <th>james</th>\n",
       "      <th>job</th>\n",
       "      <th>john</th>\n",
       "      <th>johnny</th>\n",
       "      <th>join</th>\n",
       "      <th>joins</th>\n",
       "      <th>journey</th>\n",
       "      <th>just</th>\n",
       "      <th>kidnapped</th>\n",
       "      <th>kids</th>\n",
       "      <th>kill</th>\n",
       "      <th>killed</th>\n",
       "      <th>killer</th>\n",
       "      <th>killing</th>\n",
       "      <th>king</th>\n",
       "      <th>know</th>\n",
       "      <th>known</th>\n",
       "      <th>land</th>\n",
       "      <th>late</th>\n",
       "      <th>later</th>\n",
       "      <th>law</th>\n",
       "      <th>lawyer</th>\n",
       "      <th>lead</th>\n",
       "      <th>leader</th>\n",
       "      <th>leading</th>\n",
       "      <th>leads</th>\n",
       "      <th>learn</th>\n",
       "      <th>learns</th>\n",
       "      <th>leave</th>\n",
       "      <th>leaves</th>\n",
       "      <th>led</th>\n",
       "      <th>left</th>\n",
       "      <th>legendary</th>\n",
       "      <th>life</th>\n",
       "      <th>like</th>\n",
       "      <th>little</th>\n",
       "      <th>live</th>\n",
       "      <th>lives</th>\n",
       "      <th>living</th>\n",
       "      <th>local</th>\n",
       "      <th>london</th>\n",
       "      <th>long</th>\n",
       "      <th>look</th>\n",
       "      <th>looking</th>\n",
       "      <th>lord</th>\n",
       "      <th>los</th>\n",
       "      <th>lost</th>\n",
       "      <th>love</th>\n",
       "      <th>magical</th>\n",
       "      <th>make</th>\n",
       "      <th>makes</th>\n",
       "      <th>making</th>\n",
       "      <th>man</th>\n",
       "      <th>marriage</th>\n",
       "      <th>married</th>\n",
       "      <th>master</th>\n",
       "      <th>max</th>\n",
       "      <th>means</th>\n",
       "      <th>meet</th>\n",
       "      <th>meets</th>\n",
       "      <th>members</th>\n",
       "      <th>men</th>\n",
       "      <th>michael</th>\n",
       "      <th>middle</th>\n",
       "      <th>mike</th>\n",
       "      <th>military</th>\n",
       "      <th>mind</th>\n",
       "      <th>missing</th>\n",
       "      <th>mission</th>\n",
       "      <th>money</th>\n",
       "      <th>monster</th>\n",
       "      <th>mother</th>\n",
       "      <th>moves</th>\n",
       "      <th>movie</th>\n",
       "      <th>mr</th>\n",
       "      <th>murder</th>\n",
       "      <th>murdered</th>\n",
       "      <th>music</th>\n",
       "      <th>mysterious</th>\n",
       "      <th>mystery</th>\n",
       "      <th>named</th>\n",
       "      <th>new</th>\n",
       "      <th>night</th>\n",
       "      <th>notorious</th>\n",
       "      <th>obsessed</th>\n",
       "      <th>officer</th>\n",
       "      <th>old</th>\n",
       "      <th>older</th>\n",
       "      <th>order</th>\n",
       "      <th>owner</th>\n",
       "      <th>pair</th>\n",
       "      <th>parents</th>\n",
       "      <th>paris</th>\n",
       "      <th>park</th>\n",
       "      <th>partner</th>\n",
       "      <th>party</th>\n",
       "      <th>past</th>\n",
       "      <th>path</th>\n",
       "      <th>paul</th>\n",
       "      <th>people</th>\n",
       "      <th>perfect</th>\n",
       "      <th>person</th>\n",
       "      <th>personal</th>\n",
       "      <th>peter</th>\n",
       "      <th>place</th>\n",
       "      <th>plan</th>\n",
       "      <th>planet</th>\n",
       "      <th>plans</th>\n",
       "      <th>play</th>\n",
       "      <th>plot</th>\n",
       "      <th>police</th>\n",
       "      <th>popular</th>\n",
       "      <th>power</th>\n",
       "      <th>powerful</th>\n",
       "      <th>powers</th>\n",
       "      <th>president</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>prison</th>\n",
       "      <th>private</th>\n",
       "      <th>professor</th>\n",
       "      <th>protect</th>\n",
       "      <th>prove</th>\n",
       "      <th>puts</th>\n",
       "      <th>queen</th>\n",
       "      <th>quest</th>\n",
       "      <th>quickly</th>\n",
       "      <th>race</th>\n",
       "      <th>real</th>\n",
       "      <th>reality</th>\n",
       "      <th>realizes</th>\n",
       "      <th>really</th>\n",
       "      <th>relationship</th>\n",
       "      <th>remote</th>\n",
       "      <th>rescue</th>\n",
       "      <th>rest</th>\n",
       "      <th>return</th>\n",
       "      <th>returns</th>\n",
       "      <th>revenge</th>\n",
       "      <th>rich</th>\n",
       "      <th>right</th>\n",
       "      <th>road</th>\n",
       "      <th>rock</th>\n",
       "      <th>romance</th>\n",
       "      <th>romantic</th>\n",
       "      <th>run</th>\n",
       "      <th>runs</th>\n",
       "      <th>ruthless</th>\n",
       "      <th>sam</th>\n",
       "      <th>san</th>\n",
       "      <th>save</th>\n",
       "      <th>school</th>\n",
       "      <th>scientist</th>\n",
       "      <th>search</th>\n",
       "      <th>secret</th>\n",
       "      <th>secrets</th>\n",
       "      <th>security</th>\n",
       "      <th>seek</th>\n",
       "      <th>seeks</th>\n",
       "      <th>seemingly</th>\n",
       "      <th>self</th>\n",
       "      <th>sent</th>\n",
       "      <th>serial</th>\n",
       "      <th>series</th>\n",
       "      <th>set</th>\n",
       "      <th>sets</th>\n",
       "      <th>sex</th>\n",
       "      <th>ship</th>\n",
       "      <th>short</th>\n",
       "      <th>singer</th>\n",
       "      <th>single</th>\n",
       "      <th>sinister</th>\n",
       "      <th>sister</th>\n",
       "      <th>small</th>\n",
       "      <th>social</th>\n",
       "      <th>society</th>\n",
       "      <th>son</th>\n",
       "      <th>soon</th>\n",
       "      <th>south</th>\n",
       "      <th>space</th>\n",
       "      <th>special</th>\n",
       "      <th>spirit</th>\n",
       "      <th>star</th>\n",
       "      <th>start</th>\n",
       "      <th>starts</th>\n",
       "      <th>state</th>\n",
       "      <th>states</th>\n",
       "      <th>stay</th>\n",
       "      <th>stop</th>\n",
       "      <th>story</th>\n",
       "      <th>strange</th>\n",
       "      <th>street</th>\n",
       "      <th>struggle</th>\n",
       "      <th>struggles</th>\n",
       "      <th>struggling</th>\n",
       "      <th>student</th>\n",
       "      <th>students</th>\n",
       "      <th>suburban</th>\n",
       "      <th>successful</th>\n",
       "      <th>suddenly</th>\n",
       "      <th>summer</th>\n",
       "      <th>supernatural</th>\n",
       "      <th>survival</th>\n",
       "      <th>survive</th>\n",
       "      <th>taken</th>\n",
       "      <th>takes</th>\n",
       "      <th>taking</th>\n",
       "      <th>tale</th>\n",
       "      <th>target</th>\n",
       "      <th>teacher</th>\n",
       "      <th>team</th>\n",
       "      <th>teams</th>\n",
       "      <th>teen</th>\n",
       "      <th>teenage</th>\n",
       "      <th>teenager</th>\n",
       "      <th>tells</th>\n",
       "      <th>terrifying</th>\n",
       "      <th>test</th>\n",
       "      <th>texas</th>\n",
       "      <th>thing</th>\n",
       "      <th>things</th>\n",
       "      <th>thought</th>\n",
       "      <th>threatens</th>\n",
       "      <th>time</th>\n",
       "      <th>town</th>\n",
       "      <th>train</th>\n",
       "      <th>trapped</th>\n",
       "      <th>travel</th>\n",
       "      <th>travels</th>\n",
       "      <th>tries</th>\n",
       "      <th>trip</th>\n",
       "      <th>true</th>\n",
       "      <th>truth</th>\n",
       "      <th>try</th>\n",
       "      <th>trying</th>\n",
       "      <th>turn</th>\n",
       "      <th>turned</th>\n",
       "      <th>turns</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>ultimately</th>\n",
       "      <th>uncover</th>\n",
       "      <th>unexpected</th>\n",
       "      <th>united</th>\n",
       "      <th>unlikely</th>\n",
       "      <th>use</th>\n",
       "      <th>uses</th>\n",
       "      <th>using</th>\n",
       "      <th>vacation</th>\n",
       "      <th>vampire</th>\n",
       "      <th>veteran</th>\n",
       "      <th>village</th>\n",
       "      <th>violent</th>\n",
       "      <th>want</th>\n",
       "      <th>wants</th>\n",
       "      <th>war</th>\n",
       "      <th>way</th>\n",
       "      <th>ways</th>\n",
       "      <th>wealthy</th>\n",
       "      <th>wedding</th>\n",
       "      <th>white</th>\n",
       "      <th>wife</th>\n",
       "      <th>wild</th>\n",
       "      <th>win</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fc85ff26758f696344ad07f</td>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>en</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fc85ff26758f696344aceeb</td>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>en</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280571</td>\n",
       "      <td>0.242753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fc85ff26758f696344acf29</td>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>en</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.336685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.373179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5fc85ff26758f696344ad019</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>en</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.240268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fc85ff26758f696344ad100</td>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>en</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5fc85ff26758f696344ad07f   \n",
       "1  5fc85ff26758f696344aceeb   \n",
       "2  5fc85ff26758f696344acf29   \n",
       "3  5fc85ff26758f696344ad019   \n",
       "4  5fc85ff26758f696344ad100   \n",
       "\n",
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id original_language  \\\n",
       "0  house-at-the-end-of-the-street                en   \n",
       "1          green-street-hooligans                en   \n",
       "2           beverly-hills-cop-iii                en   \n",
       "3                     bad-boys-ii                en   \n",
       "4                    a-single-man                en   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  000  accident  accidentally  act  \\\n",
       "0         2012.0    3.880987           689  0.0       0.0           0.0  0.0   \n",
       "1         2005.0    5.953771           411  0.0       0.0           0.0  0.0   \n",
       "2         1994.0    4.492424           528  0.0       0.0           0.0  0.0   \n",
       "3         2003.0    6.021593          1343  0.0       0.0           0.0  0.0   \n",
       "4         2009.0    7.660256          1404  0.0       0.0           0.0  0.0   \n",
       "\n",
       "   action  adventure  agent  alex  alice  alien  america  american  ancient  \\\n",
       "0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000      0.0   \n",
       "1     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.223725      0.0   \n",
       "2     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000      0.0   \n",
       "3     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000      0.0   \n",
       "4     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000      0.0   \n",
       "\n",
       "   angeles  apart  army  arrives  art  artist  attack  attempt  attempts  \\\n",
       "0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   \n",
       "1      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   \n",
       "2      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   \n",
       "3      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   \n",
       "4      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   \n",
       "\n",
       "   away  baby  bad  band  based  battle  beautiful  begin  begins  best  big  \\\n",
       "0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0   \n",
       "1   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0   \n",
       "2   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0   \n",
       "3   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0   \n",
       "4   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0   \n",
       "\n",
       "   black  body  bond  book  born      boss  boy  boyfriend  break  bring  \\\n",
       "0    0.0   0.0   0.0   0.0   0.0  0.000000  0.0        0.0    0.0    0.0   \n",
       "1    0.0   0.0   0.0   0.0   0.0  0.000000  0.0        0.0    0.0    0.0   \n",
       "2    0.0   0.0   0.0   0.0   0.0  0.356986  0.0        0.0    0.0    0.0   \n",
       "3    0.0   0.0   0.0   0.0   0.0  0.000000  0.0        0.0    0.0    0.0   \n",
       "4    0.0   0.0   0.0   0.0   0.0  0.000000  0.0        0.0    0.0    0.0   \n",
       "\n",
       "   brings   british   brother  brothers  business  california  called  camp  \\\n",
       "0     0.0  0.000000  0.000000       0.0       0.0    0.000000     0.0   0.0   \n",
       "1     0.0  0.280571  0.242753       0.0       0.0    0.000000     0.0   0.0   \n",
       "2     0.0  0.000000  0.000000       0.0       0.0    0.365932     0.0   0.0   \n",
       "3     0.0  0.000000  0.000000       0.0       0.0    0.000000     0.0   0.0   \n",
       "4     0.0  0.257771  0.000000       0.0       0.0    0.000000     0.0   0.0   \n",
       "\n",
       "   captain  car  career  case  caught  century  chance  change  charlie  \\\n",
       "0      0.0  0.0     0.0   0.0     0.0      0.0     0.0     0.0      0.0   \n",
       "1      0.0  0.0     0.0   0.0     0.0      0.0     0.0     0.0      0.0   \n",
       "2      0.0  0.0     0.0   0.0     0.0      0.0     0.0     0.0      0.0   \n",
       "3      0.0  0.0     0.0   0.0     0.0      0.0     0.0     0.0      0.0   \n",
       "4      0.0  0.0     0.0   0.0     0.0      0.0     0.0     0.0      0.0   \n",
       "\n",
       "   child  childhood  children  christmas  cia  city  class  classic   college  \\\n",
       "0    0.0        0.0       0.0        0.0  0.0   0.0    0.0      0.0  0.000000   \n",
       "1    0.0        0.0       0.0        0.0  0.0   0.0    0.0      0.0  0.000000   \n",
       "2    0.0        0.0       0.0        0.0  0.0   0.0    0.0      0.0  0.000000   \n",
       "3    0.0        0.0       0.0        0.0  0.0   0.0    0.0      0.0  0.000000   \n",
       "4    0.0        0.0       0.0        0.0  0.0   0.0    0.0      0.0  0.234468   \n",
       "\n",
       "   come  comedy  comes  community  company  confront  control       cop  \\\n",
       "0   0.0     0.0    0.0        0.0      0.0       0.0  0.00000  0.000000   \n",
       "1   0.0     0.0    0.0        0.0      0.0       0.0  0.00000  0.000000   \n",
       "2   0.0     0.0    0.0        0.0      0.0       0.0  0.00000  0.336685   \n",
       "3   0.0     0.0    0.0        0.0      0.0       0.0  0.28055  0.000000   \n",
       "4   0.0     0.0    0.0        0.0      0.0       0.0  0.00000  0.000000   \n",
       "\n",
       "   country  couple  course  creatures  crew  crime  criminal  cross  \\\n",
       "0      0.0     0.0     0.0        0.0   0.0    0.0       0.0    0.0   \n",
       "1      0.0     0.0     0.0        0.0   0.0    0.0       0.0    0.0   \n",
       "2      0.0     0.0     0.0        0.0   0.0    0.0       0.0    0.0   \n",
       "3      0.0     0.0     0.0        0.0   0.0    0.0       0.0    0.0   \n",
       "4      0.0     0.0     0.0        0.0   0.0    0.0       0.0    0.0   \n",
       "\n",
       "   dangerous  dark  daughter  david  day  days  dead  deadly  deal  death  \\\n",
       "0    0.00000   0.0   0.47792    0.0  0.0   0.0   0.0     0.0   0.0    0.0   \n",
       "1    0.24861   0.0   0.00000    0.0  0.0   0.0   0.0     0.0   0.0    0.0   \n",
       "2    0.00000   0.0   0.00000    0.0  0.0   0.0   0.0     0.0   0.0    0.0   \n",
       "3    0.00000   0.0   0.00000    0.0  0.0   0.0   0.0     0.0   0.0    0.0   \n",
       "4    0.00000   0.0   0.00000    0.0  0.0   0.0   0.0     0.0   0.0    0.0   \n",
       "\n",
       "   decide  decides  deep  desperate  despite  destroy  detective  determined  \\\n",
       "0     0.0      0.0   0.0        0.0      0.0      0.0        0.0         0.0   \n",
       "1     0.0      0.0   0.0        0.0      0.0      0.0        0.0         0.0   \n",
       "2     0.0      0.0   0.0        0.0      0.0      0.0        0.0         0.0   \n",
       "3     0.0      0.0   0.0        0.0      0.0      0.0        0.0         0.0   \n",
       "4     0.0      0.0   0.0        0.0      0.0      0.0        0.0         0.0   \n",
       "\n",
       "   different  director  discover  discovers  doctor  documentary  does  doesn  \\\n",
       "0        0.0       0.0   0.00000   0.000000     0.0          0.0   0.0    0.0   \n",
       "1        0.0       0.0   0.00000   0.000000     0.0          0.0   0.0    0.0   \n",
       "2        0.0       0.0   0.29159   0.000000     0.0          0.0   0.0    0.0   \n",
       "3        0.0       0.0   0.00000   0.240268     0.0          0.0   0.0    0.0   \n",
       "4        0.0       0.0   0.00000   0.000000     0.0          0.0   0.0    0.0   \n",
       "\n",
       "   dog  don   dr  dream  dreams  driver      drug  earth  eccentric  embark  \\\n",
       "0  0.0  0.0  0.0    0.0     0.0     0.0  0.000000    0.0        0.0     0.0   \n",
       "1  0.0  0.0  0.0    0.0     0.0     0.0  0.000000    0.0        0.0     0.0   \n",
       "2  0.0  0.0  0.0    0.0     0.0     0.0  0.000000    0.0        0.0     0.0   \n",
       "3  0.0  0.0  0.0    0.0     0.0     0.0  0.275676    0.0        0.0     0.0   \n",
       "4  0.0  0.0  0.0    0.0     0.0     0.0  0.000000    0.0        0.0     0.0   \n",
       "\n",
       "   embarks  encounter  end  ends  enemy   england  english  entire  epic  \\\n",
       "0      0.0        0.0  0.0   0.0    0.0  0.000000      0.0     0.0   0.0   \n",
       "1      0.0        0.0  0.0   0.0    0.0  0.283943      0.0     0.0   0.0   \n",
       "2      0.0        0.0  0.0   0.0    0.0  0.000000      0.0     0.0   0.0   \n",
       "3      0.0        0.0  0.0   0.0    0.0  0.000000      0.0     0.0   0.0   \n",
       "4      0.0        0.0  0.0   0.0    0.0  0.000000      0.0     0.0   0.0   \n",
       "\n",
       "   escape  estranged  eve  events  eventually  evil   ex  existence  \\\n",
       "0     0.0        0.0  0.0     0.0         0.0   0.0  0.0        0.0   \n",
       "1     0.0        0.0  0.0     0.0         0.0   0.0  0.0        0.0   \n",
       "2     0.0        0.0  0.0     0.0         0.0   0.0  0.0        0.0   \n",
       "3     0.0        0.0  0.0     0.0         0.0   0.0  0.0        0.0   \n",
       "4     0.0        0.0  0.0     0.0         0.0   0.0  0.0        0.0   \n",
       "\n",
       "   experience  eye  face  faces  fall  falls  family  famous       far  fate  \\\n",
       "0         0.0  0.0   0.0    0.0   0.0    0.0     0.0     0.0  0.290858   0.0   \n",
       "1         0.0  0.0   0.0    0.0   0.0    0.0     0.0     0.0  0.000000   0.0   \n",
       "2         0.0  0.0   0.0    0.0   0.0    0.0     0.0     0.0  0.000000   0.0   \n",
       "3         0.0  0.0   0.0    0.0   0.0    0.0     0.0     0.0  0.000000   0.0   \n",
       "4         0.0  0.0   0.0    0.0   0.0    0.0     0.0     0.0  0.000000   0.0   \n",
       "\n",
       "   father  fbi  fear  fellow  fight  fighting  film  final  finally  finds  \\\n",
       "0     0.0  0.0   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0   \n",
       "1     0.0  0.0   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0   \n",
       "2     0.0  0.0   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0   \n",
       "3     0.0  0.0   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0   \n",
       "4     0.0  0.0   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0   \n",
       "\n",
       "   following  follows    force  forced  forces  forever  form  frank  free  \\\n",
       "0        0.0      0.0  0.00000     0.0     0.0      0.0   0.0    0.0   0.0   \n",
       "1        0.0      0.0  0.00000     0.0     0.0      0.0   0.0    0.0   0.0   \n",
       "2        0.0      0.0  0.00000     0.0     0.0      0.0   0.0    0.0   0.0   \n",
       "3        0.0      0.0  0.27806     0.0     0.0      0.0   0.0    0.0   0.0   \n",
       "4        0.0      0.0  0.00000     0.0     0.0      0.0   0.0    0.0   0.0   \n",
       "\n",
       "     friend  friends  friendship  future  game      gang    george  gets  \\\n",
       "0  0.000000      0.0    0.000000     0.0   0.0  0.000000  0.000000   0.0   \n",
       "1  0.000000      0.0    0.278964     0.0   0.0  0.000000  0.000000   0.0   \n",
       "2  0.000000      0.0    0.000000     0.0   0.0  0.327756  0.000000   0.0   \n",
       "3  0.000000      0.0    0.000000     0.0   0.0  0.000000  0.000000   0.0   \n",
       "4  0.203322      0.0    0.000000     0.0   0.0  0.000000  0.555974   0.0   \n",
       "\n",
       "   getting      girl  girlfriend  girls  global  goes  going  good  \\\n",
       "0      0.0  0.234962         0.0    0.0     0.0   0.0    0.0   0.0   \n",
       "1      0.0  0.000000         0.0    0.0     0.0   0.0    0.0   0.0   \n",
       "2      0.0  0.000000         0.0    0.0     0.0   0.0    0.0   0.0   \n",
       "3      0.0  0.000000         0.0    0.0     0.0   0.0    0.0   0.0   \n",
       "4      0.0  0.202604         0.0    0.0     0.0   0.0    0.0   0.0   \n",
       "\n",
       "   government  great  group  guy  hands  hard  harry  having  head  heart  \\\n",
       "0         0.0    0.0    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0   \n",
       "1         0.0    0.0    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0   \n",
       "2         0.0    0.0    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0   \n",
       "3         0.0    0.0    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0   \n",
       "4         0.0    0.0    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0   \n",
       "\n",
       "   heist  hell  help  henry  hero  high  history  hit  holiday  hollywood  \\\n",
       "0    0.0   0.0   0.0    0.0   0.0   0.0      0.0  0.0      0.0        0.0   \n",
       "1    0.0   0.0   0.0    0.0   0.0   0.0      0.0  0.0      0.0        0.0   \n",
       "2    0.0   0.0   0.0    0.0   0.0   0.0      0.0  0.0      0.0        0.0   \n",
       "3    0.0   0.0   0.0    0.0   0.0   0.0      0.0  0.0      0.0        0.0   \n",
       "4    0.0   0.0   0.0    0.0   0.0   0.0      0.0  0.0      0.0        0.0   \n",
       "\n",
       "       home  hope  horror  hospital  hotel     house  human  humanity  humans  \\\n",
       "0  0.000000   0.0     0.0       0.0    0.0  0.246224    0.0       0.0     0.0   \n",
       "1  0.201096   0.0     0.0       0.0    0.0  0.000000    0.0       0.0     0.0   \n",
       "2  0.000000   0.0     0.0       0.0    0.0  0.000000    0.0       0.0     0.0   \n",
       "3  0.000000   0.0     0.0       0.0    0.0  0.000000    0.0       0.0     0.0   \n",
       "4  0.000000   0.0     0.0       0.0    0.0  0.000000    0.0       0.0     0.0   \n",
       "\n",
       "   hunt  husband  identity   ii  including  increasingly  inside  \\\n",
       "0   0.0      0.0       0.0  0.0        0.0           0.0     0.0   \n",
       "1   0.0      0.0       0.0  0.0        0.0           0.0     0.0   \n",
       "2   0.0      0.0       0.0  0.0        0.0           0.0     0.0   \n",
       "3   0.0      0.0       0.0  0.0        0.0           0.0     0.0   \n",
       "4   0.0      0.0       0.0  0.0        0.0           0.0     0.0   \n",
       "\n",
       "   international  investigate  involved  island  jack  james  job  john  \\\n",
       "0            0.0          0.0       0.0     0.0   0.0    0.0  0.0   0.0   \n",
       "1            0.0          0.0       0.0     0.0   0.0    0.0  0.0   0.0   \n",
       "2            0.0          0.0       0.0     0.0   0.0    0.0  0.0   0.0   \n",
       "3            0.0          0.0       0.0     0.0   0.0    0.0  0.0   0.0   \n",
       "4            0.0          0.0       0.0     0.0   0.0    0.0  0.0   0.0   \n",
       "\n",
       "   johnny  join  joins  journey  just  kidnapped  kids  kill  killed  killer  \\\n",
       "0     0.0   0.0    0.0      0.0   0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "1     0.0   0.0    0.0      0.0   0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "2     0.0   0.0    0.0      0.0   0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "3     0.0   0.0    0.0      0.0   0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "4     0.0   0.0    0.0      0.0   0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "\n",
       "   killing  king  know  known  land  late  later       law  lawyer  lead  \\\n",
       "0      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.000000     0.0   0.0   \n",
       "1      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.285714     0.0   0.0   \n",
       "2      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.000000     0.0   0.0   \n",
       "3      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.000000     0.0   0.0   \n",
       "4      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.000000     0.0   0.0   \n",
       "\n",
       "   leader  leading  leads  learn    learns  leave  leaves  led  left  \\\n",
       "0     0.0      0.0    0.0    0.0  0.287218    0.0     0.0  0.0   0.0   \n",
       "1     0.0      0.0    0.0    0.0  0.269571    0.0     0.0  0.0   0.0   \n",
       "2     0.0      0.0    0.0    0.0  0.000000    0.0     0.0  0.0   0.0   \n",
       "3     0.0      0.0    0.0    0.0  0.000000    0.0     0.0  0.0   0.0   \n",
       "4     0.0      0.0    0.0    0.0  0.000000    0.0     0.0  0.0   0.0   \n",
       "\n",
       "   legendary      life  like  little      live  lives    living  local  \\\n",
       "0        0.0  0.000000   0.0     0.0  0.000000    0.0  0.254973    0.0   \n",
       "1        0.0  0.000000   0.0     0.0  0.000000    0.0  0.239307    0.0   \n",
       "2        0.0  0.000000   0.0     0.0  0.000000    0.0  0.000000    0.0   \n",
       "3        0.0  0.000000   0.0     0.0  0.000000    0.0  0.000000    0.0   \n",
       "4        0.0  0.288127   0.0     0.0  0.227201    0.0  0.000000    0.0   \n",
       "\n",
       "   london  long  look  looking      lord  los  lost  love  magical  make  \\\n",
       "0     0.0   0.0   0.0      0.0  0.000000  0.0   0.0   0.0      0.0   0.0   \n",
       "1     0.0   0.0   0.0      0.0  0.000000  0.0   0.0   0.0      0.0   0.0   \n",
       "2     0.0   0.0   0.0      0.0  0.000000  0.0   0.0   0.0      0.0   0.0   \n",
       "3     0.0   0.0   0.0      0.0  0.318321  0.0   0.0   0.0      0.0   0.0   \n",
       "4     0.0   0.0   0.0      0.0  0.000000  0.0   0.0   0.0      0.0   0.0   \n",
       "\n",
       "     makes  making  man  marriage  married  master  max  means  meet  meets  \\\n",
       "0  0.00000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0    0.0   \n",
       "1  0.00000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0    0.0   \n",
       "2  0.00000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0    0.0   \n",
       "3  0.00000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0    0.0   \n",
       "4  0.23831     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0    0.0   \n",
       "\n",
       "   members  men  michael  middle      mike  military  mind  missing  mission  \\\n",
       "0      0.0  0.0      0.0     0.0  0.000000       0.0   0.0      0.0      0.0   \n",
       "1      0.0  0.0      0.0     0.0  0.000000       0.0   0.0      0.0      0.0   \n",
       "2      0.0  0.0      0.0     0.0  0.000000       0.0   0.0      0.0      0.0   \n",
       "3      0.0  0.0      0.0     0.0  0.679081       0.0   0.0      0.0      0.0   \n",
       "4      0.0  0.0      0.0     0.0  0.000000       0.0   0.0      0.0      0.0   \n",
       "\n",
       "   money  monster    mother  moves  movie   mr  murder  murdered  music  \\\n",
       "0    0.0      0.0  0.238665    0.0    0.0  0.0     0.0  0.296389    0.0   \n",
       "1    0.0      0.0  0.000000    0.0    0.0  0.0     0.0  0.000000    0.0   \n",
       "2    0.0      0.0  0.000000    0.0    0.0  0.0     0.0  0.000000    0.0   \n",
       "3    0.0      0.0  0.000000    0.0    0.0  0.0     0.0  0.000000    0.0   \n",
       "4    0.0      0.0  0.000000    0.0    0.0  0.0     0.0  0.000000    0.0   \n",
       "\n",
       "   mysterious  mystery  named      new  night  notorious  obsessed  officer  \\\n",
       "0         0.0      0.0    0.0  0.16748    0.0        0.0       0.0      0.0   \n",
       "1         0.0      0.0    0.0  0.00000    0.0        0.0       0.0      0.0   \n",
       "2         0.0      0.0    0.0  0.00000    0.0        0.0       0.0      0.0   \n",
       "3         0.0      0.0    0.0  0.00000    0.0        0.0       0.0      0.0   \n",
       "4         0.0      0.0    0.0  0.00000    0.0        0.0       0.0      0.0   \n",
       "\n",
       "   old  older  order  owner  pair   parents  paris      park   partner  party  \\\n",
       "0  0.0    0.0    0.0    0.0   0.0  0.265358    0.0  0.000000  0.000000    0.0   \n",
       "1  0.0    0.0    0.0    0.0   0.0  0.000000    0.0  0.000000  0.000000    0.0   \n",
       "2  0.0    0.0    0.0    0.0   0.0  0.000000    0.0  0.363247  0.000000    0.0   \n",
       "3  0.0    0.0    0.0    0.0   0.0  0.000000    0.0  0.000000  0.000000    0.0   \n",
       "4  0.0    0.0    0.0    0.0   0.0  0.000000    0.0  0.000000  0.261675    0.0   \n",
       "\n",
       "   past  path  paul  people  perfect  person  personal  peter  place  plan  \\\n",
       "0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0    0.0   0.0   \n",
       "1   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0    0.0   0.0   \n",
       "2   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0    0.0   0.0   \n",
       "3   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0    0.0   0.0   \n",
       "4   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0    0.0   0.0   \n",
       "\n",
       "   planet  plans  play  plot  police  popular  power  powerful  powers  \\\n",
       "0     0.0    0.0   0.0   0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1     0.0    0.0   0.0   0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2     0.0    0.0   0.0   0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3     0.0    0.0   0.0   0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4     0.0    0.0   0.0   0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   president  prince  princess  prison  private  professor  protect  prove  \\\n",
       "0        0.0     0.0       0.0     0.0      0.0   0.000000      0.0    0.0   \n",
       "1        0.0     0.0       0.0     0.0      0.0   0.000000      0.0    0.0   \n",
       "2        0.0     0.0       0.0     0.0      0.0   0.000000      0.0    0.0   \n",
       "3        0.0     0.0       0.0     0.0      0.0   0.000000      0.0    0.0   \n",
       "4        0.0     0.0       0.0     0.0      0.0   0.279144      0.0    0.0   \n",
       "\n",
       "   puts  queen  quest  quickly  race      real  reality  realizes  really  \\\n",
       "0   0.0    0.0    0.0      0.0   0.0  0.000000      0.0       0.0     0.0   \n",
       "1   0.0    0.0    0.0      0.0   0.0  0.000000      0.0       0.0     0.0   \n",
       "2   0.0    0.0    0.0      0.0   0.0  0.000000      0.0       0.0     0.0   \n",
       "3   0.0    0.0    0.0      0.0   0.0  0.274522      0.0       0.0     0.0   \n",
       "4   0.0    0.0    0.0      0.0   0.0  0.000000      0.0       0.0     0.0   \n",
       "\n",
       "   relationship  remote  rescue  rest  return  returns  revenge  rich  right  \\\n",
       "0           0.0     0.0     0.0   0.0     0.0      0.0      0.0   0.0    0.0   \n",
       "1           0.0     0.0     0.0   0.0     0.0      0.0      0.0   0.0    0.0   \n",
       "2           0.0     0.0     0.0   0.0     0.0      0.0      0.0   0.0    0.0   \n",
       "3           0.0     0.0     0.0   0.0     0.0      0.0      0.0   0.0    0.0   \n",
       "4           0.0     0.0     0.0   0.0     0.0      0.0      0.0   0.0    0.0   \n",
       "\n",
       "   road  rock  romance  romantic      run  runs  ruthless  sam  san  save  \\\n",
       "0   0.0   0.0      0.0       0.0  0.00000   0.0       0.0  0.0  0.0   0.0   \n",
       "1   0.0   0.0      0.0       0.0  0.00000   0.0       0.0  0.0  0.0   0.0   \n",
       "2   0.0   0.0      0.0       0.0  0.30941   0.0       0.0  0.0  0.0   0.0   \n",
       "3   0.0   0.0      0.0       0.0  0.00000   0.0       0.0  0.0  0.0   0.0   \n",
       "4   0.0   0.0      0.0       0.0  0.00000   0.0       0.0  0.0  0.0   0.0   \n",
       "\n",
       "   school  scientist  search    secret  secrets  security  seek     seeks  \\\n",
       "0     0.0        0.0     0.0  0.000000      0.0       0.0   0.0  0.000000   \n",
       "1     0.0        0.0     0.0  0.222101      0.0       0.0   0.0  0.000000   \n",
       "2     0.0        0.0     0.0  0.000000      0.0       0.0   0.0  0.000000   \n",
       "3     0.0        0.0     0.0  0.000000      0.0       0.0   0.0  0.000000   \n",
       "4     0.0        0.0     0.0  0.000000      0.0       0.0   0.0  0.275754   \n",
       "\n",
       "   seemingly  self  sent  serial  series  set  sets  sex  ship  short  singer  \\\n",
       "0        0.0   0.0   0.0     0.0     0.0  0.0   0.0  0.0   0.0    0.0     0.0   \n",
       "1        0.0   0.0   0.0     0.0     0.0  0.0   0.0  0.0   0.0    0.0     0.0   \n",
       "2        0.0   0.0   0.0     0.0     0.0  0.0   0.0  0.0   0.0    0.0     0.0   \n",
       "3        0.0   0.0   0.0     0.0     0.0  0.0   0.0  0.0   0.0    0.0     0.0   \n",
       "4        0.0   0.0   0.0     0.0     0.0  0.0   0.0  0.0   0.0    0.0     0.0   \n",
       "\n",
       "   single  sinister    sister  small  social  society       son      soon  \\\n",
       "0     0.0       0.0  0.000000    0.0     0.0      0.0  0.235795  0.000000   \n",
       "1     0.0       0.0  0.253722    0.0     0.0      0.0  0.000000  0.000000   \n",
       "2     0.0       0.0  0.000000    0.0     0.0      0.0  0.000000  0.256718   \n",
       "3     0.0       0.0  0.269086    0.0     0.0      0.0  0.000000  0.000000   \n",
       "4     0.0       0.0  0.000000    0.0     0.0      0.0  0.000000  0.000000   \n",
       "\n",
       "   south  space  special  spirit  star  start  starts  state  states  stay  \\\n",
       "0    0.0    0.0      0.0     0.0   0.0    0.0     0.0    0.0     0.0   0.0   \n",
       "1    0.0    0.0      0.0     0.0   0.0    0.0     0.0    0.0     0.0   0.0   \n",
       "2    0.0    0.0      0.0     0.0   0.0    0.0     0.0    0.0     0.0   0.0   \n",
       "3    0.0    0.0      0.0     0.0   0.0    0.0     0.0    0.0     0.0   0.0   \n",
       "4    0.0    0.0      0.0     0.0   0.0    0.0     0.0    0.0     0.0   0.0   \n",
       "\n",
       "   stop     story  strange    street  struggle  struggles  struggling  \\\n",
       "0   0.0  0.213882      0.0  0.000000       0.0        0.0    0.000000   \n",
       "1   0.0  0.200741      0.0  0.288489       0.0        0.0    0.000000   \n",
       "2   0.0  0.000000      0.0  0.000000       0.0        0.0    0.000000   \n",
       "3   0.0  0.000000      0.0  0.000000       0.0        0.0    0.000000   \n",
       "4   0.0  0.000000      0.0  0.000000       0.0        0.0    0.270589   \n",
       "\n",
       "   student  students  suburban  successful  suddenly  summer  supernatural  \\\n",
       "0      0.0       0.0       0.0         0.0       0.0     0.0           0.0   \n",
       "1      0.0       0.0       0.0         0.0       0.0     0.0           0.0   \n",
       "2      0.0       0.0       0.0         0.0       0.0     0.0           0.0   \n",
       "3      0.0       0.0       0.0         0.0       0.0     0.0           0.0   \n",
       "4      0.0       0.0       0.0         0.0       0.0     0.0           0.0   \n",
       "\n",
       "   survival  survive  taken  takes  taking  tale  target  teacher  team  \\\n",
       "0       0.0      0.0    0.0    0.0     0.0   0.0     0.0      0.0   0.0   \n",
       "1       0.0      0.0    0.0    0.0     0.0   0.0     0.0      0.0   0.0   \n",
       "2       0.0      0.0    0.0    0.0     0.0   0.0     0.0      0.0   0.0   \n",
       "3       0.0      0.0    0.0    0.0     0.0   0.0     0.0      0.0   0.0   \n",
       "4       0.0      0.0    0.0    0.0     0.0   0.0     0.0      0.0   0.0   \n",
       "\n",
       "      teams  teen  teenage  teenager  tells  terrifying  test  texas  thing  \\\n",
       "0  0.000000   0.0      0.0       0.0    0.0         0.0   0.0    0.0    0.0   \n",
       "1  0.000000   0.0      0.0       0.0    0.0         0.0   0.0    0.0    0.0   \n",
       "2  0.373179   0.0      0.0       0.0    0.0         0.0   0.0    0.0    0.0   \n",
       "3  0.000000   0.0      0.0       0.0    0.0         0.0   0.0    0.0    0.0   \n",
       "4  0.000000   0.0      0.0       0.0    0.0         0.0   0.0    0.0    0.0   \n",
       "\n",
       "   things  thought  threatens  time      town  train  trapped  travel  \\\n",
       "0     0.0      0.0        0.0   0.0  0.219642    0.0      0.0     0.0   \n",
       "1     0.0      0.0        0.0   0.0  0.000000    0.0      0.0     0.0   \n",
       "2     0.0      0.0        0.0   0.0  0.000000    0.0      0.0     0.0   \n",
       "3     0.0      0.0        0.0   0.0  0.000000    0.0      0.0     0.0   \n",
       "4     0.0      0.0        0.0   0.0  0.000000    0.0      0.0     0.0   \n",
       "\n",
       "   travels  tries  trip  true  truth  try  trying  turn  turned  turns  \\\n",
       "0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0     0.0    0.0   \n",
       "1      0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0     0.0    0.0   \n",
       "2      0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0     0.0    0.0   \n",
       "3      0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0     0.0    0.0   \n",
       "4      0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0     0.0    0.0   \n",
       "\n",
       "   ultimate  ultimately  uncover  unexpected  united  unlikely  use  uses  \\\n",
       "0       0.0         0.0      0.0         0.0     0.0       0.0  0.0   0.0   \n",
       "1       0.0         0.0      0.0         0.0     0.0       0.0  0.0   0.0   \n",
       "2       0.0         0.0      0.0         0.0     0.0       0.0  0.0   0.0   \n",
       "3       0.0         0.0      0.0         0.0     0.0       0.0  0.0   0.0   \n",
       "4       0.0         0.0      0.0         0.0     0.0       0.0  0.0   0.0   \n",
       "\n",
       "   using  vacation  vampire  veteran  village   violent  want  wants  war  \\\n",
       "0    0.0       0.0      0.0      0.0      0.0  0.000000   0.0    0.0  0.0   \n",
       "1    0.0       0.0      0.0      0.0      0.0  0.272987   0.0    0.0  0.0   \n",
       "2    0.0       0.0      0.0      0.0      0.0  0.000000   0.0    0.0  0.0   \n",
       "3    0.0       0.0      0.0      0.0      0.0  0.000000   0.0    0.0  0.0   \n",
       "4    0.0       0.0      0.0      0.0      0.0  0.000000   0.0    0.0  0.0   \n",
       "\n",
       "   way  ways  wealthy  wedding  white  wife  wild  win  woman  women  work  \\\n",
       "0  0.0   0.0      0.0      0.0    0.0   0.0   0.0  0.0    0.0    0.0   0.0   \n",
       "1  0.0   0.0      0.0      0.0    0.0   0.0   0.0  0.0    0.0    0.0   0.0   \n",
       "2  0.0   0.0      0.0      0.0    0.0   0.0   0.0  0.0    0.0    0.0   0.0   \n",
       "3  0.0   0.0      0.0      0.0    0.0   0.0   0.0  0.0    0.0    0.0   0.0   \n",
       "4  0.0   0.0      0.0      0.0    0.0   0.0   0.0  0.0    0.0    0.0   0.0   \n",
       "\n",
       "   working  works     world  writer  wrong  year  years  york    young  \\\n",
       "0      0.0    0.0  0.000000     0.0    0.0   0.0    0.0   0.0  0.17549   \n",
       "1      0.0    0.0  0.168197     0.0    0.0   0.0    0.0   0.0  0.00000   \n",
       "2      0.0    0.0  0.000000     0.0    0.0   0.0    0.0   0.0  0.00000   \n",
       "3      0.0    0.0  0.000000     0.0    0.0   0.0    0.0   0.0  0.00000   \n",
       "4      0.0    0.0  0.000000     0.0    0.0   0.0    0.0   0.0  0.00000   \n",
       "\n",
       "   younger  Action  Adventure  Animation  Comedy  Crime  Documentary  Drama  \\\n",
       "0      0.0       0          0          0       0      0            0      0   \n",
       "1      0.0       0          0          0       0      1            0      1   \n",
       "2      0.0       1          0          0       1      1            0      0   \n",
       "3      0.0       1          1          0       1      1            0      0   \n",
       "4      0.0       0          0          0       0      0            0      1   \n",
       "\n",
       "   Family  Fantasy  History  Horror  Music  Mystery  Romance  Science Fiction  \\\n",
       "0       0        0        0       1      0        0        0                0   \n",
       "1       0        0        0       0      0        0        0                0   \n",
       "2       0        0        0       0      0        0        0                0   \n",
       "3       0        0        0       0      0        0        0                0   \n",
       "4       0        0        0       0      0        0        1                0   \n",
       "\n",
       "   TV Movie  Thriller  War  Western  \n",
       "0         0         1    0        0  \n",
       "1         0         0    0        0  \n",
       "2         0         0    0        0  \n",
       "3         0         1    0        0  \n",
       "4         0         0    0        0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking all columns\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "#Sanity Check\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca8f89-54a5-4cc5-a121-f30403cf35f9",
   "metadata": {},
   "source": [
    "We can see now that we have one dataframe containing our original data, TF_IDF columns, and our binary Genre columns.\n",
    "\n",
    "Lets drop the original columns we will no longer need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d99d2047-16e2-4878-8965-8bcbc97a0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns that we will not include in ML\n",
    "columns_to_drop = ['_id', 'genres', 'original_language','overview']\n",
    "movies_ML = merged_df.drop(columns = columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58788db7-52ba-4763-8300-07da237aaa69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>000</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>agent</th>\n",
       "      <th>alex</th>\n",
       "      <th>alice</th>\n",
       "      <th>alien</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>ancient</th>\n",
       "      <th>angeles</th>\n",
       "      <th>apart</th>\n",
       "      <th>army</th>\n",
       "      <th>arrives</th>\n",
       "      <th>art</th>\n",
       "      <th>artist</th>\n",
       "      <th>attack</th>\n",
       "      <th>attempt</th>\n",
       "      <th>attempts</th>\n",
       "      <th>away</th>\n",
       "      <th>baby</th>\n",
       "      <th>bad</th>\n",
       "      <th>band</th>\n",
       "      <th>based</th>\n",
       "      <th>battle</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>begin</th>\n",
       "      <th>begins</th>\n",
       "      <th>best</th>\n",
       "      <th>big</th>\n",
       "      <th>black</th>\n",
       "      <th>body</th>\n",
       "      <th>bond</th>\n",
       "      <th>book</th>\n",
       "      <th>born</th>\n",
       "      <th>boss</th>\n",
       "      <th>boy</th>\n",
       "      <th>boyfriend</th>\n",
       "      <th>break</th>\n",
       "      <th>bring</th>\n",
       "      <th>brings</th>\n",
       "      <th>british</th>\n",
       "      <th>brother</th>\n",
       "      <th>brothers</th>\n",
       "      <th>business</th>\n",
       "      <th>california</th>\n",
       "      <th>called</th>\n",
       "      <th>camp</th>\n",
       "      <th>captain</th>\n",
       "      <th>car</th>\n",
       "      <th>career</th>\n",
       "      <th>case</th>\n",
       "      <th>caught</th>\n",
       "      <th>century</th>\n",
       "      <th>chance</th>\n",
       "      <th>change</th>\n",
       "      <th>charlie</th>\n",
       "      <th>child</th>\n",
       "      <th>childhood</th>\n",
       "      <th>children</th>\n",
       "      <th>christmas</th>\n",
       "      <th>cia</th>\n",
       "      <th>city</th>\n",
       "      <th>class</th>\n",
       "      <th>classic</th>\n",
       "      <th>college</th>\n",
       "      <th>come</th>\n",
       "      <th>comedy</th>\n",
       "      <th>comes</th>\n",
       "      <th>community</th>\n",
       "      <th>company</th>\n",
       "      <th>confront</th>\n",
       "      <th>control</th>\n",
       "      <th>cop</th>\n",
       "      <th>country</th>\n",
       "      <th>couple</th>\n",
       "      <th>course</th>\n",
       "      <th>creatures</th>\n",
       "      <th>crew</th>\n",
       "      <th>crime</th>\n",
       "      <th>criminal</th>\n",
       "      <th>cross</th>\n",
       "      <th>dangerous</th>\n",
       "      <th>dark</th>\n",
       "      <th>daughter</th>\n",
       "      <th>david</th>\n",
       "      <th>day</th>\n",
       "      <th>days</th>\n",
       "      <th>dead</th>\n",
       "      <th>deadly</th>\n",
       "      <th>deal</th>\n",
       "      <th>death</th>\n",
       "      <th>decide</th>\n",
       "      <th>decides</th>\n",
       "      <th>deep</th>\n",
       "      <th>desperate</th>\n",
       "      <th>despite</th>\n",
       "      <th>destroy</th>\n",
       "      <th>detective</th>\n",
       "      <th>determined</th>\n",
       "      <th>different</th>\n",
       "      <th>director</th>\n",
       "      <th>discover</th>\n",
       "      <th>discovers</th>\n",
       "      <th>doctor</th>\n",
       "      <th>documentary</th>\n",
       "      <th>does</th>\n",
       "      <th>doesn</th>\n",
       "      <th>dog</th>\n",
       "      <th>don</th>\n",
       "      <th>dr</th>\n",
       "      <th>dream</th>\n",
       "      <th>dreams</th>\n",
       "      <th>driver</th>\n",
       "      <th>drug</th>\n",
       "      <th>earth</th>\n",
       "      <th>eccentric</th>\n",
       "      <th>embark</th>\n",
       "      <th>embarks</th>\n",
       "      <th>encounter</th>\n",
       "      <th>end</th>\n",
       "      <th>ends</th>\n",
       "      <th>enemy</th>\n",
       "      <th>england</th>\n",
       "      <th>english</th>\n",
       "      <th>entire</th>\n",
       "      <th>epic</th>\n",
       "      <th>escape</th>\n",
       "      <th>estranged</th>\n",
       "      <th>eve</th>\n",
       "      <th>events</th>\n",
       "      <th>eventually</th>\n",
       "      <th>evil</th>\n",
       "      <th>ex</th>\n",
       "      <th>existence</th>\n",
       "      <th>experience</th>\n",
       "      <th>eye</th>\n",
       "      <th>face</th>\n",
       "      <th>faces</th>\n",
       "      <th>fall</th>\n",
       "      <th>falls</th>\n",
       "      <th>family</th>\n",
       "      <th>famous</th>\n",
       "      <th>far</th>\n",
       "      <th>fate</th>\n",
       "      <th>father</th>\n",
       "      <th>fbi</th>\n",
       "      <th>fear</th>\n",
       "      <th>fellow</th>\n",
       "      <th>fight</th>\n",
       "      <th>fighting</th>\n",
       "      <th>film</th>\n",
       "      <th>final</th>\n",
       "      <th>finally</th>\n",
       "      <th>finds</th>\n",
       "      <th>following</th>\n",
       "      <th>follows</th>\n",
       "      <th>force</th>\n",
       "      <th>forced</th>\n",
       "      <th>forces</th>\n",
       "      <th>forever</th>\n",
       "      <th>form</th>\n",
       "      <th>frank</th>\n",
       "      <th>free</th>\n",
       "      <th>friend</th>\n",
       "      <th>friends</th>\n",
       "      <th>friendship</th>\n",
       "      <th>future</th>\n",
       "      <th>game</th>\n",
       "      <th>gang</th>\n",
       "      <th>george</th>\n",
       "      <th>gets</th>\n",
       "      <th>getting</th>\n",
       "      <th>girl</th>\n",
       "      <th>girlfriend</th>\n",
       "      <th>girls</th>\n",
       "      <th>global</th>\n",
       "      <th>goes</th>\n",
       "      <th>going</th>\n",
       "      <th>good</th>\n",
       "      <th>government</th>\n",
       "      <th>great</th>\n",
       "      <th>group</th>\n",
       "      <th>guy</th>\n",
       "      <th>hands</th>\n",
       "      <th>hard</th>\n",
       "      <th>harry</th>\n",
       "      <th>having</th>\n",
       "      <th>head</th>\n",
       "      <th>heart</th>\n",
       "      <th>heist</th>\n",
       "      <th>hell</th>\n",
       "      <th>help</th>\n",
       "      <th>henry</th>\n",
       "      <th>hero</th>\n",
       "      <th>high</th>\n",
       "      <th>history</th>\n",
       "      <th>hit</th>\n",
       "      <th>holiday</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>home</th>\n",
       "      <th>hope</th>\n",
       "      <th>horror</th>\n",
       "      <th>hospital</th>\n",
       "      <th>hotel</th>\n",
       "      <th>house</th>\n",
       "      <th>human</th>\n",
       "      <th>humanity</th>\n",
       "      <th>humans</th>\n",
       "      <th>hunt</th>\n",
       "      <th>husband</th>\n",
       "      <th>identity</th>\n",
       "      <th>ii</th>\n",
       "      <th>including</th>\n",
       "      <th>increasingly</th>\n",
       "      <th>inside</th>\n",
       "      <th>international</th>\n",
       "      <th>investigate</th>\n",
       "      <th>involved</th>\n",
       "      <th>island</th>\n",
       "      <th>jack</th>\n",
       "      <th>james</th>\n",
       "      <th>job</th>\n",
       "      <th>john</th>\n",
       "      <th>johnny</th>\n",
       "      <th>join</th>\n",
       "      <th>joins</th>\n",
       "      <th>journey</th>\n",
       "      <th>just</th>\n",
       "      <th>kidnapped</th>\n",
       "      <th>kids</th>\n",
       "      <th>kill</th>\n",
       "      <th>killed</th>\n",
       "      <th>killer</th>\n",
       "      <th>killing</th>\n",
       "      <th>king</th>\n",
       "      <th>know</th>\n",
       "      <th>known</th>\n",
       "      <th>land</th>\n",
       "      <th>late</th>\n",
       "      <th>later</th>\n",
       "      <th>law</th>\n",
       "      <th>lawyer</th>\n",
       "      <th>lead</th>\n",
       "      <th>leader</th>\n",
       "      <th>leading</th>\n",
       "      <th>leads</th>\n",
       "      <th>learn</th>\n",
       "      <th>learns</th>\n",
       "      <th>leave</th>\n",
       "      <th>leaves</th>\n",
       "      <th>led</th>\n",
       "      <th>left</th>\n",
       "      <th>legendary</th>\n",
       "      <th>life</th>\n",
       "      <th>like</th>\n",
       "      <th>little</th>\n",
       "      <th>live</th>\n",
       "      <th>lives</th>\n",
       "      <th>living</th>\n",
       "      <th>local</th>\n",
       "      <th>london</th>\n",
       "      <th>long</th>\n",
       "      <th>look</th>\n",
       "      <th>looking</th>\n",
       "      <th>lord</th>\n",
       "      <th>los</th>\n",
       "      <th>lost</th>\n",
       "      <th>love</th>\n",
       "      <th>magical</th>\n",
       "      <th>make</th>\n",
       "      <th>makes</th>\n",
       "      <th>making</th>\n",
       "      <th>man</th>\n",
       "      <th>marriage</th>\n",
       "      <th>married</th>\n",
       "      <th>master</th>\n",
       "      <th>max</th>\n",
       "      <th>means</th>\n",
       "      <th>meet</th>\n",
       "      <th>meets</th>\n",
       "      <th>members</th>\n",
       "      <th>men</th>\n",
       "      <th>michael</th>\n",
       "      <th>middle</th>\n",
       "      <th>mike</th>\n",
       "      <th>military</th>\n",
       "      <th>mind</th>\n",
       "      <th>missing</th>\n",
       "      <th>mission</th>\n",
       "      <th>money</th>\n",
       "      <th>monster</th>\n",
       "      <th>mother</th>\n",
       "      <th>moves</th>\n",
       "      <th>movie</th>\n",
       "      <th>mr</th>\n",
       "      <th>murder</th>\n",
       "      <th>murdered</th>\n",
       "      <th>music</th>\n",
       "      <th>mysterious</th>\n",
       "      <th>mystery</th>\n",
       "      <th>named</th>\n",
       "      <th>new</th>\n",
       "      <th>night</th>\n",
       "      <th>notorious</th>\n",
       "      <th>obsessed</th>\n",
       "      <th>officer</th>\n",
       "      <th>old</th>\n",
       "      <th>older</th>\n",
       "      <th>order</th>\n",
       "      <th>owner</th>\n",
       "      <th>pair</th>\n",
       "      <th>parents</th>\n",
       "      <th>paris</th>\n",
       "      <th>park</th>\n",
       "      <th>partner</th>\n",
       "      <th>party</th>\n",
       "      <th>past</th>\n",
       "      <th>path</th>\n",
       "      <th>paul</th>\n",
       "      <th>people</th>\n",
       "      <th>perfect</th>\n",
       "      <th>person</th>\n",
       "      <th>personal</th>\n",
       "      <th>peter</th>\n",
       "      <th>place</th>\n",
       "      <th>plan</th>\n",
       "      <th>planet</th>\n",
       "      <th>plans</th>\n",
       "      <th>play</th>\n",
       "      <th>plot</th>\n",
       "      <th>police</th>\n",
       "      <th>popular</th>\n",
       "      <th>power</th>\n",
       "      <th>powerful</th>\n",
       "      <th>powers</th>\n",
       "      <th>president</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>prison</th>\n",
       "      <th>private</th>\n",
       "      <th>professor</th>\n",
       "      <th>protect</th>\n",
       "      <th>prove</th>\n",
       "      <th>puts</th>\n",
       "      <th>queen</th>\n",
       "      <th>quest</th>\n",
       "      <th>quickly</th>\n",
       "      <th>race</th>\n",
       "      <th>real</th>\n",
       "      <th>reality</th>\n",
       "      <th>realizes</th>\n",
       "      <th>really</th>\n",
       "      <th>relationship</th>\n",
       "      <th>remote</th>\n",
       "      <th>rescue</th>\n",
       "      <th>rest</th>\n",
       "      <th>return</th>\n",
       "      <th>returns</th>\n",
       "      <th>revenge</th>\n",
       "      <th>rich</th>\n",
       "      <th>right</th>\n",
       "      <th>road</th>\n",
       "      <th>rock</th>\n",
       "      <th>romance</th>\n",
       "      <th>romantic</th>\n",
       "      <th>run</th>\n",
       "      <th>runs</th>\n",
       "      <th>ruthless</th>\n",
       "      <th>sam</th>\n",
       "      <th>san</th>\n",
       "      <th>save</th>\n",
       "      <th>school</th>\n",
       "      <th>scientist</th>\n",
       "      <th>search</th>\n",
       "      <th>secret</th>\n",
       "      <th>secrets</th>\n",
       "      <th>security</th>\n",
       "      <th>seek</th>\n",
       "      <th>seeks</th>\n",
       "      <th>seemingly</th>\n",
       "      <th>self</th>\n",
       "      <th>sent</th>\n",
       "      <th>serial</th>\n",
       "      <th>series</th>\n",
       "      <th>set</th>\n",
       "      <th>sets</th>\n",
       "      <th>sex</th>\n",
       "      <th>ship</th>\n",
       "      <th>short</th>\n",
       "      <th>singer</th>\n",
       "      <th>single</th>\n",
       "      <th>sinister</th>\n",
       "      <th>sister</th>\n",
       "      <th>small</th>\n",
       "      <th>social</th>\n",
       "      <th>society</th>\n",
       "      <th>son</th>\n",
       "      <th>soon</th>\n",
       "      <th>south</th>\n",
       "      <th>space</th>\n",
       "      <th>special</th>\n",
       "      <th>spirit</th>\n",
       "      <th>star</th>\n",
       "      <th>start</th>\n",
       "      <th>starts</th>\n",
       "      <th>state</th>\n",
       "      <th>states</th>\n",
       "      <th>stay</th>\n",
       "      <th>stop</th>\n",
       "      <th>story</th>\n",
       "      <th>strange</th>\n",
       "      <th>street</th>\n",
       "      <th>struggle</th>\n",
       "      <th>struggles</th>\n",
       "      <th>struggling</th>\n",
       "      <th>student</th>\n",
       "      <th>students</th>\n",
       "      <th>suburban</th>\n",
       "      <th>successful</th>\n",
       "      <th>suddenly</th>\n",
       "      <th>summer</th>\n",
       "      <th>supernatural</th>\n",
       "      <th>survival</th>\n",
       "      <th>survive</th>\n",
       "      <th>taken</th>\n",
       "      <th>takes</th>\n",
       "      <th>taking</th>\n",
       "      <th>tale</th>\n",
       "      <th>target</th>\n",
       "      <th>teacher</th>\n",
       "      <th>team</th>\n",
       "      <th>teams</th>\n",
       "      <th>teen</th>\n",
       "      <th>teenage</th>\n",
       "      <th>teenager</th>\n",
       "      <th>tells</th>\n",
       "      <th>terrifying</th>\n",
       "      <th>test</th>\n",
       "      <th>texas</th>\n",
       "      <th>thing</th>\n",
       "      <th>things</th>\n",
       "      <th>thought</th>\n",
       "      <th>threatens</th>\n",
       "      <th>time</th>\n",
       "      <th>town</th>\n",
       "      <th>train</th>\n",
       "      <th>trapped</th>\n",
       "      <th>travel</th>\n",
       "      <th>travels</th>\n",
       "      <th>tries</th>\n",
       "      <th>trip</th>\n",
       "      <th>true</th>\n",
       "      <th>truth</th>\n",
       "      <th>try</th>\n",
       "      <th>trying</th>\n",
       "      <th>turn</th>\n",
       "      <th>turned</th>\n",
       "      <th>turns</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>ultimately</th>\n",
       "      <th>uncover</th>\n",
       "      <th>unexpected</th>\n",
       "      <th>united</th>\n",
       "      <th>unlikely</th>\n",
       "      <th>use</th>\n",
       "      <th>uses</th>\n",
       "      <th>using</th>\n",
       "      <th>vacation</th>\n",
       "      <th>vampire</th>\n",
       "      <th>veteran</th>\n",
       "      <th>village</th>\n",
       "      <th>violent</th>\n",
       "      <th>want</th>\n",
       "      <th>wants</th>\n",
       "      <th>war</th>\n",
       "      <th>way</th>\n",
       "      <th>ways</th>\n",
       "      <th>wealthy</th>\n",
       "      <th>wedding</th>\n",
       "      <th>white</th>\n",
       "      <th>wife</th>\n",
       "      <th>wild</th>\n",
       "      <th>win</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280571</td>\n",
       "      <td>0.242753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.336685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.373179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.240268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a-single-man</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.227201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         movie_id  popularity  runtime  year_released  \\\n",
       "0  house-at-the-end-of-the-street      11.088    101.0         2012.0   \n",
       "1          green-street-hooligans      14.690    109.0         2005.0   \n",
       "2           beverly-hills-cop-iii      13.890    105.0         1994.0   \n",
       "3                     bad-boys-ii      32.121    147.0         2003.0   \n",
       "4                    a-single-man      11.640     97.0         2009.0   \n",
       "\n",
       "   avg_rating  rating_count  000  accident  accidentally  act  action  \\\n",
       "0    3.880987           689  0.0       0.0           0.0  0.0     0.0   \n",
       "1    5.953771           411  0.0       0.0           0.0  0.0     0.0   \n",
       "2    4.492424           528  0.0       0.0           0.0  0.0     0.0   \n",
       "3    6.021593          1343  0.0       0.0           0.0  0.0     0.0   \n",
       "4    7.660256          1404  0.0       0.0           0.0  0.0     0.0   \n",
       "\n",
       "   adventure  agent  alex  alice  alien  america  american  ancient  angeles  \\\n",
       "0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000      0.0      0.0   \n",
       "1        0.0    0.0   0.0    0.0    0.0      0.0  0.223725      0.0      0.0   \n",
       "2        0.0    0.0   0.0    0.0    0.0      0.0  0.000000      0.0      0.0   \n",
       "3        0.0    0.0   0.0    0.0    0.0      0.0  0.000000      0.0      0.0   \n",
       "4        0.0    0.0   0.0    0.0    0.0      0.0  0.000000      0.0      0.0   \n",
       "\n",
       "   apart  army  arrives  art  artist  attack  attempt  attempts  away  baby  \\\n",
       "0    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   0.0   0.0   \n",
       "1    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   0.0   0.0   \n",
       "2    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   0.0   0.0   \n",
       "3    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   0.0   0.0   \n",
       "4    0.0   0.0      0.0  0.0     0.0     0.0      0.0       0.0   0.0   0.0   \n",
       "\n",
       "   bad  band  based  battle  beautiful  begin  begins  best  big  black  body  \\\n",
       "0  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0    0.0   0.0   \n",
       "1  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0    0.0   0.0   \n",
       "2  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0    0.0   0.0   \n",
       "3  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0    0.0   0.0   \n",
       "4  0.0   0.0    0.0     0.0        0.0    0.0     0.0   0.0  0.0    0.0   0.0   \n",
       "\n",
       "   bond  book  born      boss  boy  boyfriend  break  bring  brings   british  \\\n",
       "0   0.0   0.0   0.0  0.000000  0.0        0.0    0.0    0.0     0.0  0.000000   \n",
       "1   0.0   0.0   0.0  0.000000  0.0        0.0    0.0    0.0     0.0  0.280571   \n",
       "2   0.0   0.0   0.0  0.356986  0.0        0.0    0.0    0.0     0.0  0.000000   \n",
       "3   0.0   0.0   0.0  0.000000  0.0        0.0    0.0    0.0     0.0  0.000000   \n",
       "4   0.0   0.0   0.0  0.000000  0.0        0.0    0.0    0.0     0.0  0.257771   \n",
       "\n",
       "    brother  brothers  business  california  called  camp  captain  car  \\\n",
       "0  0.000000       0.0       0.0    0.000000     0.0   0.0      0.0  0.0   \n",
       "1  0.242753       0.0       0.0    0.000000     0.0   0.0      0.0  0.0   \n",
       "2  0.000000       0.0       0.0    0.365932     0.0   0.0      0.0  0.0   \n",
       "3  0.000000       0.0       0.0    0.000000     0.0   0.0      0.0  0.0   \n",
       "4  0.000000       0.0       0.0    0.000000     0.0   0.0      0.0  0.0   \n",
       "\n",
       "   career  case  caught  century  chance  change  charlie  child  childhood  \\\n",
       "0     0.0   0.0     0.0      0.0     0.0     0.0      0.0    0.0        0.0   \n",
       "1     0.0   0.0     0.0      0.0     0.0     0.0      0.0    0.0        0.0   \n",
       "2     0.0   0.0     0.0      0.0     0.0     0.0      0.0    0.0        0.0   \n",
       "3     0.0   0.0     0.0      0.0     0.0     0.0      0.0    0.0        0.0   \n",
       "4     0.0   0.0     0.0      0.0     0.0     0.0      0.0    0.0        0.0   \n",
       "\n",
       "   children  christmas  cia  city  class  classic   college  come  comedy  \\\n",
       "0       0.0        0.0  0.0   0.0    0.0      0.0  0.000000   0.0     0.0   \n",
       "1       0.0        0.0  0.0   0.0    0.0      0.0  0.000000   0.0     0.0   \n",
       "2       0.0        0.0  0.0   0.0    0.0      0.0  0.000000   0.0     0.0   \n",
       "3       0.0        0.0  0.0   0.0    0.0      0.0  0.000000   0.0     0.0   \n",
       "4       0.0        0.0  0.0   0.0    0.0      0.0  0.234468   0.0     0.0   \n",
       "\n",
       "   comes  community  company  confront  control       cop  country  couple  \\\n",
       "0    0.0        0.0      0.0       0.0  0.00000  0.000000      0.0     0.0   \n",
       "1    0.0        0.0      0.0       0.0  0.00000  0.000000      0.0     0.0   \n",
       "2    0.0        0.0      0.0       0.0  0.00000  0.336685      0.0     0.0   \n",
       "3    0.0        0.0      0.0       0.0  0.28055  0.000000      0.0     0.0   \n",
       "4    0.0        0.0      0.0       0.0  0.00000  0.000000      0.0     0.0   \n",
       "\n",
       "   course  creatures  crew  crime  criminal  cross  dangerous  dark  daughter  \\\n",
       "0     0.0        0.0   0.0    0.0       0.0    0.0    0.00000   0.0   0.47792   \n",
       "1     0.0        0.0   0.0    0.0       0.0    0.0    0.24861   0.0   0.00000   \n",
       "2     0.0        0.0   0.0    0.0       0.0    0.0    0.00000   0.0   0.00000   \n",
       "3     0.0        0.0   0.0    0.0       0.0    0.0    0.00000   0.0   0.00000   \n",
       "4     0.0        0.0   0.0    0.0       0.0    0.0    0.00000   0.0   0.00000   \n",
       "\n",
       "   david  day  days  dead  deadly  deal  death  decide  decides  deep  \\\n",
       "0    0.0  0.0   0.0   0.0     0.0   0.0    0.0     0.0      0.0   0.0   \n",
       "1    0.0  0.0   0.0   0.0     0.0   0.0    0.0     0.0      0.0   0.0   \n",
       "2    0.0  0.0   0.0   0.0     0.0   0.0    0.0     0.0      0.0   0.0   \n",
       "3    0.0  0.0   0.0   0.0     0.0   0.0    0.0     0.0      0.0   0.0   \n",
       "4    0.0  0.0   0.0   0.0     0.0   0.0    0.0     0.0      0.0   0.0   \n",
       "\n",
       "   desperate  despite  destroy  detective  determined  different  director  \\\n",
       "0        0.0      0.0      0.0        0.0         0.0        0.0       0.0   \n",
       "1        0.0      0.0      0.0        0.0         0.0        0.0       0.0   \n",
       "2        0.0      0.0      0.0        0.0         0.0        0.0       0.0   \n",
       "3        0.0      0.0      0.0        0.0         0.0        0.0       0.0   \n",
       "4        0.0      0.0      0.0        0.0         0.0        0.0       0.0   \n",
       "\n",
       "   discover  discovers  doctor  documentary  does  doesn  dog  don   dr  \\\n",
       "0   0.00000   0.000000     0.0          0.0   0.0    0.0  0.0  0.0  0.0   \n",
       "1   0.00000   0.000000     0.0          0.0   0.0    0.0  0.0  0.0  0.0   \n",
       "2   0.29159   0.000000     0.0          0.0   0.0    0.0  0.0  0.0  0.0   \n",
       "3   0.00000   0.240268     0.0          0.0   0.0    0.0  0.0  0.0  0.0   \n",
       "4   0.00000   0.000000     0.0          0.0   0.0    0.0  0.0  0.0  0.0   \n",
       "\n",
       "   dream  dreams  driver      drug  earth  eccentric  embark  embarks  \\\n",
       "0    0.0     0.0     0.0  0.000000    0.0        0.0     0.0      0.0   \n",
       "1    0.0     0.0     0.0  0.000000    0.0        0.0     0.0      0.0   \n",
       "2    0.0     0.0     0.0  0.000000    0.0        0.0     0.0      0.0   \n",
       "3    0.0     0.0     0.0  0.275676    0.0        0.0     0.0      0.0   \n",
       "4    0.0     0.0     0.0  0.000000    0.0        0.0     0.0      0.0   \n",
       "\n",
       "   encounter  end  ends  enemy   england  english  entire  epic  escape  \\\n",
       "0        0.0  0.0   0.0    0.0  0.000000      0.0     0.0   0.0     0.0   \n",
       "1        0.0  0.0   0.0    0.0  0.283943      0.0     0.0   0.0     0.0   \n",
       "2        0.0  0.0   0.0    0.0  0.000000      0.0     0.0   0.0     0.0   \n",
       "3        0.0  0.0   0.0    0.0  0.000000      0.0     0.0   0.0     0.0   \n",
       "4        0.0  0.0   0.0    0.0  0.000000      0.0     0.0   0.0     0.0   \n",
       "\n",
       "   estranged  eve  events  eventually  evil   ex  existence  experience  eye  \\\n",
       "0        0.0  0.0     0.0         0.0   0.0  0.0        0.0         0.0  0.0   \n",
       "1        0.0  0.0     0.0         0.0   0.0  0.0        0.0         0.0  0.0   \n",
       "2        0.0  0.0     0.0         0.0   0.0  0.0        0.0         0.0  0.0   \n",
       "3        0.0  0.0     0.0         0.0   0.0  0.0        0.0         0.0  0.0   \n",
       "4        0.0  0.0     0.0         0.0   0.0  0.0        0.0         0.0  0.0   \n",
       "\n",
       "   face  faces  fall  falls  family  famous       far  fate  father  fbi  \\\n",
       "0   0.0    0.0   0.0    0.0     0.0     0.0  0.290858   0.0     0.0  0.0   \n",
       "1   0.0    0.0   0.0    0.0     0.0     0.0  0.000000   0.0     0.0  0.0   \n",
       "2   0.0    0.0   0.0    0.0     0.0     0.0  0.000000   0.0     0.0  0.0   \n",
       "3   0.0    0.0   0.0    0.0     0.0     0.0  0.000000   0.0     0.0  0.0   \n",
       "4   0.0    0.0   0.0    0.0     0.0     0.0  0.000000   0.0     0.0  0.0   \n",
       "\n",
       "   fear  fellow  fight  fighting  film  final  finally  finds  following  \\\n",
       "0   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0        0.0   \n",
       "1   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0        0.0   \n",
       "2   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0        0.0   \n",
       "3   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0        0.0   \n",
       "4   0.0     0.0    0.0       0.0   0.0    0.0      0.0    0.0        0.0   \n",
       "\n",
       "   follows    force  forced  forces  forever  form  frank  free    friend  \\\n",
       "0      0.0  0.00000     0.0     0.0      0.0   0.0    0.0   0.0  0.000000   \n",
       "1      0.0  0.00000     0.0     0.0      0.0   0.0    0.0   0.0  0.000000   \n",
       "2      0.0  0.00000     0.0     0.0      0.0   0.0    0.0   0.0  0.000000   \n",
       "3      0.0  0.27806     0.0     0.0      0.0   0.0    0.0   0.0  0.000000   \n",
       "4      0.0  0.00000     0.0     0.0      0.0   0.0    0.0   0.0  0.203322   \n",
       "\n",
       "   friends  friendship  future  game      gang    george  gets  getting  \\\n",
       "0      0.0    0.000000     0.0   0.0  0.000000  0.000000   0.0      0.0   \n",
       "1      0.0    0.278964     0.0   0.0  0.000000  0.000000   0.0      0.0   \n",
       "2      0.0    0.000000     0.0   0.0  0.327756  0.000000   0.0      0.0   \n",
       "3      0.0    0.000000     0.0   0.0  0.000000  0.000000   0.0      0.0   \n",
       "4      0.0    0.000000     0.0   0.0  0.000000  0.555974   0.0      0.0   \n",
       "\n",
       "       girl  girlfriend  girls  global  goes  going  good  government  great  \\\n",
       "0  0.234962         0.0    0.0     0.0   0.0    0.0   0.0         0.0    0.0   \n",
       "1  0.000000         0.0    0.0     0.0   0.0    0.0   0.0         0.0    0.0   \n",
       "2  0.000000         0.0    0.0     0.0   0.0    0.0   0.0         0.0    0.0   \n",
       "3  0.000000         0.0    0.0     0.0   0.0    0.0   0.0         0.0    0.0   \n",
       "4  0.202604         0.0    0.0     0.0   0.0    0.0   0.0         0.0    0.0   \n",
       "\n",
       "   group  guy  hands  hard  harry  having  head  heart  heist  hell  help  \\\n",
       "0    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "1    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "2    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "3    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "4    0.0  0.0    0.0   0.0    0.0     0.0   0.0    0.0    0.0   0.0   0.0   \n",
       "\n",
       "   henry  hero  high  history  hit  holiday  hollywood      home  hope  \\\n",
       "0    0.0   0.0   0.0      0.0  0.0      0.0        0.0  0.000000   0.0   \n",
       "1    0.0   0.0   0.0      0.0  0.0      0.0        0.0  0.201096   0.0   \n",
       "2    0.0   0.0   0.0      0.0  0.0      0.0        0.0  0.000000   0.0   \n",
       "3    0.0   0.0   0.0      0.0  0.0      0.0        0.0  0.000000   0.0   \n",
       "4    0.0   0.0   0.0      0.0  0.0      0.0        0.0  0.000000   0.0   \n",
       "\n",
       "   horror  hospital  hotel     house  human  humanity  humans  hunt  husband  \\\n",
       "0     0.0       0.0    0.0  0.246224    0.0       0.0     0.0   0.0      0.0   \n",
       "1     0.0       0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "2     0.0       0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "3     0.0       0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "4     0.0       0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "\n",
       "   identity   ii  including  increasingly  inside  international  investigate  \\\n",
       "0       0.0  0.0        0.0           0.0     0.0            0.0          0.0   \n",
       "1       0.0  0.0        0.0           0.0     0.0            0.0          0.0   \n",
       "2       0.0  0.0        0.0           0.0     0.0            0.0          0.0   \n",
       "3       0.0  0.0        0.0           0.0     0.0            0.0          0.0   \n",
       "4       0.0  0.0        0.0           0.0     0.0            0.0          0.0   \n",
       "\n",
       "   involved  island  jack  james  job  john  johnny  join  joins  journey  \\\n",
       "0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0   \n",
       "1       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0   \n",
       "2       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0   \n",
       "3       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0   \n",
       "4       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0   \n",
       "\n",
       "   just  kidnapped  kids  kill  killed  killer  killing  king  know  known  \\\n",
       "0   0.0        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   \n",
       "1   0.0        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   \n",
       "2   0.0        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   \n",
       "3   0.0        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   \n",
       "4   0.0        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   \n",
       "\n",
       "   land  late  later       law  lawyer  lead  leader  leading  leads  learn  \\\n",
       "0   0.0   0.0    0.0  0.000000     0.0   0.0     0.0      0.0    0.0    0.0   \n",
       "1   0.0   0.0    0.0  0.285714     0.0   0.0     0.0      0.0    0.0    0.0   \n",
       "2   0.0   0.0    0.0  0.000000     0.0   0.0     0.0      0.0    0.0    0.0   \n",
       "3   0.0   0.0    0.0  0.000000     0.0   0.0     0.0      0.0    0.0    0.0   \n",
       "4   0.0   0.0    0.0  0.000000     0.0   0.0     0.0      0.0    0.0    0.0   \n",
       "\n",
       "     learns  leave  leaves  led  left  legendary      life  like  little  \\\n",
       "0  0.287218    0.0     0.0  0.0   0.0        0.0  0.000000   0.0     0.0   \n",
       "1  0.269571    0.0     0.0  0.0   0.0        0.0  0.000000   0.0     0.0   \n",
       "2  0.000000    0.0     0.0  0.0   0.0        0.0  0.000000   0.0     0.0   \n",
       "3  0.000000    0.0     0.0  0.0   0.0        0.0  0.000000   0.0     0.0   \n",
       "4  0.000000    0.0     0.0  0.0   0.0        0.0  0.288127   0.0     0.0   \n",
       "\n",
       "       live  lives    living  local  london  long  look  looking      lord  \\\n",
       "0  0.000000    0.0  0.254973    0.0     0.0   0.0   0.0      0.0  0.000000   \n",
       "1  0.000000    0.0  0.239307    0.0     0.0   0.0   0.0      0.0  0.000000   \n",
       "2  0.000000    0.0  0.000000    0.0     0.0   0.0   0.0      0.0  0.000000   \n",
       "3  0.000000    0.0  0.000000    0.0     0.0   0.0   0.0      0.0  0.318321   \n",
       "4  0.227201    0.0  0.000000    0.0     0.0   0.0   0.0      0.0  0.000000   \n",
       "\n",
       "   los  lost  love  magical  make    makes  making  man  marriage  married  \\\n",
       "0  0.0   0.0   0.0      0.0   0.0  0.00000     0.0  0.0       0.0      0.0   \n",
       "1  0.0   0.0   0.0      0.0   0.0  0.00000     0.0  0.0       0.0      0.0   \n",
       "2  0.0   0.0   0.0      0.0   0.0  0.00000     0.0  0.0       0.0      0.0   \n",
       "3  0.0   0.0   0.0      0.0   0.0  0.00000     0.0  0.0       0.0      0.0   \n",
       "4  0.0   0.0   0.0      0.0   0.0  0.23831     0.0  0.0       0.0      0.0   \n",
       "\n",
       "   master  max  means  meet  meets  members  men  michael  middle      mike  \\\n",
       "0     0.0  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0  0.000000   \n",
       "1     0.0  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0  0.000000   \n",
       "2     0.0  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0  0.000000   \n",
       "3     0.0  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0  0.679081   \n",
       "4     0.0  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0  0.000000   \n",
       "\n",
       "   military  mind  missing  mission  money  monster    mother  moves  movie  \\\n",
       "0       0.0   0.0      0.0      0.0    0.0      0.0  0.238665    0.0    0.0   \n",
       "1       0.0   0.0      0.0      0.0    0.0      0.0  0.000000    0.0    0.0   \n",
       "2       0.0   0.0      0.0      0.0    0.0      0.0  0.000000    0.0    0.0   \n",
       "3       0.0   0.0      0.0      0.0    0.0      0.0  0.000000    0.0    0.0   \n",
       "4       0.0   0.0      0.0      0.0    0.0      0.0  0.000000    0.0    0.0   \n",
       "\n",
       "    mr  murder  murdered  music  mysterious  mystery  named      new  night  \\\n",
       "0  0.0     0.0  0.296389    0.0         0.0      0.0    0.0  0.16748    0.0   \n",
       "1  0.0     0.0  0.000000    0.0         0.0      0.0    0.0  0.00000    0.0   \n",
       "2  0.0     0.0  0.000000    0.0         0.0      0.0    0.0  0.00000    0.0   \n",
       "3  0.0     0.0  0.000000    0.0         0.0      0.0    0.0  0.00000    0.0   \n",
       "4  0.0     0.0  0.000000    0.0         0.0      0.0    0.0  0.00000    0.0   \n",
       "\n",
       "   notorious  obsessed  officer  old  older  order  owner  pair   parents  \\\n",
       "0        0.0       0.0      0.0  0.0    0.0    0.0    0.0   0.0  0.265358   \n",
       "1        0.0       0.0      0.0  0.0    0.0    0.0    0.0   0.0  0.000000   \n",
       "2        0.0       0.0      0.0  0.0    0.0    0.0    0.0   0.0  0.000000   \n",
       "3        0.0       0.0      0.0  0.0    0.0    0.0    0.0   0.0  0.000000   \n",
       "4        0.0       0.0      0.0  0.0    0.0    0.0    0.0   0.0  0.000000   \n",
       "\n",
       "   paris      park   partner  party  past  path  paul  people  perfect  \\\n",
       "0    0.0  0.000000  0.000000    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "1    0.0  0.000000  0.000000    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "2    0.0  0.363247  0.000000    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "3    0.0  0.000000  0.000000    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "4    0.0  0.000000  0.261675    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "\n",
       "   person  personal  peter  place  plan  planet  plans  play  plot  police  \\\n",
       "0     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "1     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "2     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "3     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "4     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "\n",
       "   popular  power  powerful  powers  president  prince  princess  prison  \\\n",
       "0      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "1      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "2      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "3      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "4      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "\n",
       "   private  professor  protect  prove  puts  queen  quest  quickly  race  \\\n",
       "0      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "1      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "2      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "3      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "4      0.0   0.279144      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "\n",
       "       real  reality  realizes  really  relationship  remote  rescue  rest  \\\n",
       "0  0.000000      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "1  0.000000      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "2  0.000000      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "3  0.274522      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "4  0.000000      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "\n",
       "   return  returns  revenge  rich  right  road  rock  romance  romantic  \\\n",
       "0     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "1     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "2     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "3     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "4     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "\n",
       "       run  runs  ruthless  sam  san  save  school  scientist  search  \\\n",
       "0  0.00000   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0   \n",
       "1  0.00000   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0   \n",
       "2  0.30941   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0   \n",
       "3  0.00000   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0   \n",
       "4  0.00000   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0   \n",
       "\n",
       "     secret  secrets  security  seek     seeks  seemingly  self  sent  serial  \\\n",
       "0  0.000000      0.0       0.0   0.0  0.000000        0.0   0.0   0.0     0.0   \n",
       "1  0.222101      0.0       0.0   0.0  0.000000        0.0   0.0   0.0     0.0   \n",
       "2  0.000000      0.0       0.0   0.0  0.000000        0.0   0.0   0.0     0.0   \n",
       "3  0.000000      0.0       0.0   0.0  0.000000        0.0   0.0   0.0     0.0   \n",
       "4  0.000000      0.0       0.0   0.0  0.275754        0.0   0.0   0.0     0.0   \n",
       "\n",
       "   series  set  sets  sex  ship  short  singer  single  sinister    sister  \\\n",
       "0     0.0  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0  0.000000   \n",
       "1     0.0  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0  0.253722   \n",
       "2     0.0  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0  0.000000   \n",
       "3     0.0  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0  0.269086   \n",
       "4     0.0  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0  0.000000   \n",
       "\n",
       "   small  social  society       son      soon  south  space  special  spirit  \\\n",
       "0    0.0     0.0      0.0  0.235795  0.000000    0.0    0.0      0.0     0.0   \n",
       "1    0.0     0.0      0.0  0.000000  0.000000    0.0    0.0      0.0     0.0   \n",
       "2    0.0     0.0      0.0  0.000000  0.256718    0.0    0.0      0.0     0.0   \n",
       "3    0.0     0.0      0.0  0.000000  0.000000    0.0    0.0      0.0     0.0   \n",
       "4    0.0     0.0      0.0  0.000000  0.000000    0.0    0.0      0.0     0.0   \n",
       "\n",
       "   star  start  starts  state  states  stay  stop     story  strange  \\\n",
       "0   0.0    0.0     0.0    0.0     0.0   0.0   0.0  0.213882      0.0   \n",
       "1   0.0    0.0     0.0    0.0     0.0   0.0   0.0  0.200741      0.0   \n",
       "2   0.0    0.0     0.0    0.0     0.0   0.0   0.0  0.000000      0.0   \n",
       "3   0.0    0.0     0.0    0.0     0.0   0.0   0.0  0.000000      0.0   \n",
       "4   0.0    0.0     0.0    0.0     0.0   0.0   0.0  0.000000      0.0   \n",
       "\n",
       "     street  struggle  struggles  struggling  student  students  suburban  \\\n",
       "0  0.000000       0.0        0.0    0.000000      0.0       0.0       0.0   \n",
       "1  0.288489       0.0        0.0    0.000000      0.0       0.0       0.0   \n",
       "2  0.000000       0.0        0.0    0.000000      0.0       0.0       0.0   \n",
       "3  0.000000       0.0        0.0    0.000000      0.0       0.0       0.0   \n",
       "4  0.000000       0.0        0.0    0.270589      0.0       0.0       0.0   \n",
       "\n",
       "   successful  suddenly  summer  supernatural  survival  survive  taken  \\\n",
       "0         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "1         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "2         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "3         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "4         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "\n",
       "   takes  taking  tale  target  teacher  team     teams  teen  teenage  \\\n",
       "0    0.0     0.0   0.0     0.0      0.0   0.0  0.000000   0.0      0.0   \n",
       "1    0.0     0.0   0.0     0.0      0.0   0.0  0.000000   0.0      0.0   \n",
       "2    0.0     0.0   0.0     0.0      0.0   0.0  0.373179   0.0      0.0   \n",
       "3    0.0     0.0   0.0     0.0      0.0   0.0  0.000000   0.0      0.0   \n",
       "4    0.0     0.0   0.0     0.0      0.0   0.0  0.000000   0.0      0.0   \n",
       "\n",
       "   teenager  tells  terrifying  test  texas  thing  things  thought  \\\n",
       "0       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "1       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "2       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "3       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "4       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "\n",
       "   threatens  time      town  train  trapped  travel  travels  tries  trip  \\\n",
       "0        0.0   0.0  0.219642    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "1        0.0   0.0  0.000000    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "2        0.0   0.0  0.000000    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "3        0.0   0.0  0.000000    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "4        0.0   0.0  0.000000    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "\n",
       "   true  truth  try  trying  turn  turned  turns  ultimate  ultimately  \\\n",
       "0   0.0    0.0  0.0     0.0   0.0     0.0    0.0       0.0         0.0   \n",
       "1   0.0    0.0  0.0     0.0   0.0     0.0    0.0       0.0         0.0   \n",
       "2   0.0    0.0  0.0     0.0   0.0     0.0    0.0       0.0         0.0   \n",
       "3   0.0    0.0  0.0     0.0   0.0     0.0    0.0       0.0         0.0   \n",
       "4   0.0    0.0  0.0     0.0   0.0     0.0    0.0       0.0         0.0   \n",
       "\n",
       "   uncover  unexpected  united  unlikely  use  uses  using  vacation  vampire  \\\n",
       "0      0.0         0.0     0.0       0.0  0.0   0.0    0.0       0.0      0.0   \n",
       "1      0.0         0.0     0.0       0.0  0.0   0.0    0.0       0.0      0.0   \n",
       "2      0.0         0.0     0.0       0.0  0.0   0.0    0.0       0.0      0.0   \n",
       "3      0.0         0.0     0.0       0.0  0.0   0.0    0.0       0.0      0.0   \n",
       "4      0.0         0.0     0.0       0.0  0.0   0.0    0.0       0.0      0.0   \n",
       "\n",
       "   veteran  village   violent  want  wants  war  way  ways  wealthy  wedding  \\\n",
       "0      0.0      0.0  0.000000   0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "1      0.0      0.0  0.272987   0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "2      0.0      0.0  0.000000   0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "3      0.0      0.0  0.000000   0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "4      0.0      0.0  0.000000   0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "\n",
       "   white  wife  wild  win  woman  women  work  working  works     world  \\\n",
       "0    0.0   0.0   0.0  0.0    0.0    0.0   0.0      0.0    0.0  0.000000   \n",
       "1    0.0   0.0   0.0  0.0    0.0    0.0   0.0      0.0    0.0  0.168197   \n",
       "2    0.0   0.0   0.0  0.0    0.0    0.0   0.0      0.0    0.0  0.000000   \n",
       "3    0.0   0.0   0.0  0.0    0.0    0.0   0.0      0.0    0.0  0.000000   \n",
       "4    0.0   0.0   0.0  0.0    0.0    0.0   0.0      0.0    0.0  0.000000   \n",
       "\n",
       "   writer  wrong  year  years  york    young  younger  Action  Adventure  \\\n",
       "0     0.0    0.0   0.0    0.0   0.0  0.17549      0.0       0          0   \n",
       "1     0.0    0.0   0.0    0.0   0.0  0.00000      0.0       0          0   \n",
       "2     0.0    0.0   0.0    0.0   0.0  0.00000      0.0       1          0   \n",
       "3     0.0    0.0   0.0    0.0   0.0  0.00000      0.0       1          1   \n",
       "4     0.0    0.0   0.0    0.0   0.0  0.00000      0.0       0          0   \n",
       "\n",
       "   Animation  Comedy  Crime  Documentary  Drama  Family  Fantasy  History  \\\n",
       "0          0       0      0            0      0       0        0        0   \n",
       "1          0       0      1            0      1       0        0        0   \n",
       "2          0       1      1            0      0       0        0        0   \n",
       "3          0       1      1            0      0       0        0        0   \n",
       "4          0       0      0            0      1       0        0        0   \n",
       "\n",
       "   Horror  Music  Mystery  Romance  Science Fiction  TV Movie  Thriller  War  \\\n",
       "0       1      0        0        0                0         0         1    0   \n",
       "1       0      0        0        0                0         0         0    0   \n",
       "2       0      0        0        0                0         0         0    0   \n",
       "3       0      0        0        0                0         0         1    0   \n",
       "4       0      0        0        1                0         0         0    0   \n",
       "\n",
       "   Western  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "movies_ML.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d256dc18-18b8-4251-9439-ddf55be2a903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7a97ffa-dd0b-4b97-be87-daffc59c39f9",
   "metadata": {},
   "source": [
    "### Pre-Processing Summary\n",
    "* We applied TF_IDF to our Overview column, finding the top 500 tokens to create binary columns\n",
    "* Created genre columns creating binary values for each genre, and allowing for multiple genres associated with each movie\n",
    "* Dropped our old columns from before pre-processing in a datafame that is now ready for our ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483df0f-b2dc-460a-8b7b-edd5b003d97f",
   "metadata": {},
   "source": [
    "# Initial Modelling\n",
    "We are going to use the Nearest Neighbours model (not KNN) which will allow us to simply identify the k most similar movies (neighbours) in the vector space. This model is an unsupervised model.\n",
    "\n",
    "We may evaluate quantitatively but the most powerful evalation right now will be qualitative as there is no target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f1d4dbf-8741-4c5c-a70b-9d46f8d82ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(n_neighbors=10)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "X = movies_ML.drop(['movie_id'], axis=1)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the NearestNeighbors model\n",
    "#Using euclidian distance as distance metric by default\n",
    "nn = NearestNeighbors(n_neighbors=10, algorithm='auto')\n",
    "\n",
    "# Fit the model to your data\n",
    "nn.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7237948-4883-460b-b4e6-1c7e6f8238b5",
   "metadata": {},
   "source": [
    "We have our model, now lets see if its working. We need a query index for a movie. We will keep things consistent and go with Raiders Of the Lost Ark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89c41f21-7876-427c-9bc0-9e22fa0051ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indy_index = movies_ML.loc[movies_ML['movie_id']=='raiders-of-the-lost-ark'].index[0]\n",
    "\n",
    "indy_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e10cc-1d58-4979-ac85-0c63a2c458d7",
   "metadata": {},
   "source": [
    "Lets use the index of our movie to see what the model provides us for nearest neighbours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "07a6248d-37b4-4bf2-b366-a9fb4830a0ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors Indices: [[  80 4330 4651 3056  722 2000 4097 2462  845 1871]]\n",
      "Euclidian Distance to Neighbors: [[4.76837158e-07 2.40022630e+01 2.49713292e+01 2.51455512e+01\n",
      "  2.52060884e+01 2.56604858e+01 2.57354721e+01 2.58172811e+01\n",
      "  2.63741874e+01 2.64813013e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Get the features of Raiders of the Lost Ark movie \n",
    "input_movie_features = X_scaled[[indy_index]]  \n",
    "\n",
    "# Find the nearest neighbors\n",
    "distances, indices = nn.kneighbors(input_movie_features, n_neighbors=10)\n",
    "\n",
    "# The 'indices' variable contains the indices of the nearest neighbors\n",
    "# The 'distances' variable contains the distances to these neighbors\n",
    "\n",
    "# Print the indices and distances of the nearest neighbors\n",
    "print(\"Nearest Neighbors Indices:\", indices)\n",
    "print(\"Euclidian Distance to Neighbors:\", distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82783b07-79ad-46b7-96a4-4dc7dba4142f",
   "metadata": {},
   "source": [
    "We can use the indices we found to apply them to our original df (with overview and genres etc.) to see how it performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4256caf6-72e3-4508-84a2-efc3e68a3a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>000</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>agent</th>\n",
       "      <th>alex</th>\n",
       "      <th>alice</th>\n",
       "      <th>alien</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>ancient</th>\n",
       "      <th>angeles</th>\n",
       "      <th>apart</th>\n",
       "      <th>army</th>\n",
       "      <th>arrives</th>\n",
       "      <th>art</th>\n",
       "      <th>artist</th>\n",
       "      <th>attack</th>\n",
       "      <th>attempt</th>\n",
       "      <th>attempts</th>\n",
       "      <th>away</th>\n",
       "      <th>baby</th>\n",
       "      <th>bad</th>\n",
       "      <th>band</th>\n",
       "      <th>based</th>\n",
       "      <th>battle</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>begin</th>\n",
       "      <th>begins</th>\n",
       "      <th>best</th>\n",
       "      <th>big</th>\n",
       "      <th>black</th>\n",
       "      <th>body</th>\n",
       "      <th>bond</th>\n",
       "      <th>book</th>\n",
       "      <th>born</th>\n",
       "      <th>boss</th>\n",
       "      <th>boy</th>\n",
       "      <th>boyfriend</th>\n",
       "      <th>break</th>\n",
       "      <th>bring</th>\n",
       "      <th>brings</th>\n",
       "      <th>british</th>\n",
       "      <th>brother</th>\n",
       "      <th>brothers</th>\n",
       "      <th>business</th>\n",
       "      <th>california</th>\n",
       "      <th>called</th>\n",
       "      <th>camp</th>\n",
       "      <th>captain</th>\n",
       "      <th>car</th>\n",
       "      <th>career</th>\n",
       "      <th>case</th>\n",
       "      <th>caught</th>\n",
       "      <th>century</th>\n",
       "      <th>chance</th>\n",
       "      <th>change</th>\n",
       "      <th>charlie</th>\n",
       "      <th>child</th>\n",
       "      <th>childhood</th>\n",
       "      <th>children</th>\n",
       "      <th>christmas</th>\n",
       "      <th>cia</th>\n",
       "      <th>city</th>\n",
       "      <th>class</th>\n",
       "      <th>classic</th>\n",
       "      <th>college</th>\n",
       "      <th>come</th>\n",
       "      <th>comedy</th>\n",
       "      <th>comes</th>\n",
       "      <th>community</th>\n",
       "      <th>company</th>\n",
       "      <th>confront</th>\n",
       "      <th>control</th>\n",
       "      <th>cop</th>\n",
       "      <th>country</th>\n",
       "      <th>couple</th>\n",
       "      <th>course</th>\n",
       "      <th>creatures</th>\n",
       "      <th>crew</th>\n",
       "      <th>crime</th>\n",
       "      <th>criminal</th>\n",
       "      <th>cross</th>\n",
       "      <th>dangerous</th>\n",
       "      <th>dark</th>\n",
       "      <th>daughter</th>\n",
       "      <th>david</th>\n",
       "      <th>day</th>\n",
       "      <th>days</th>\n",
       "      <th>dead</th>\n",
       "      <th>deadly</th>\n",
       "      <th>deal</th>\n",
       "      <th>death</th>\n",
       "      <th>decide</th>\n",
       "      <th>decides</th>\n",
       "      <th>deep</th>\n",
       "      <th>desperate</th>\n",
       "      <th>despite</th>\n",
       "      <th>destroy</th>\n",
       "      <th>detective</th>\n",
       "      <th>determined</th>\n",
       "      <th>different</th>\n",
       "      <th>director</th>\n",
       "      <th>discover</th>\n",
       "      <th>discovers</th>\n",
       "      <th>doctor</th>\n",
       "      <th>documentary</th>\n",
       "      <th>does</th>\n",
       "      <th>doesn</th>\n",
       "      <th>dog</th>\n",
       "      <th>don</th>\n",
       "      <th>dr</th>\n",
       "      <th>dream</th>\n",
       "      <th>dreams</th>\n",
       "      <th>driver</th>\n",
       "      <th>drug</th>\n",
       "      <th>earth</th>\n",
       "      <th>eccentric</th>\n",
       "      <th>embark</th>\n",
       "      <th>embarks</th>\n",
       "      <th>encounter</th>\n",
       "      <th>end</th>\n",
       "      <th>ends</th>\n",
       "      <th>enemy</th>\n",
       "      <th>england</th>\n",
       "      <th>english</th>\n",
       "      <th>entire</th>\n",
       "      <th>epic</th>\n",
       "      <th>escape</th>\n",
       "      <th>estranged</th>\n",
       "      <th>eve</th>\n",
       "      <th>events</th>\n",
       "      <th>eventually</th>\n",
       "      <th>evil</th>\n",
       "      <th>ex</th>\n",
       "      <th>existence</th>\n",
       "      <th>experience</th>\n",
       "      <th>eye</th>\n",
       "      <th>face</th>\n",
       "      <th>faces</th>\n",
       "      <th>fall</th>\n",
       "      <th>falls</th>\n",
       "      <th>family</th>\n",
       "      <th>famous</th>\n",
       "      <th>far</th>\n",
       "      <th>fate</th>\n",
       "      <th>father</th>\n",
       "      <th>fbi</th>\n",
       "      <th>fear</th>\n",
       "      <th>fellow</th>\n",
       "      <th>fight</th>\n",
       "      <th>fighting</th>\n",
       "      <th>film</th>\n",
       "      <th>final</th>\n",
       "      <th>finally</th>\n",
       "      <th>finds</th>\n",
       "      <th>following</th>\n",
       "      <th>follows</th>\n",
       "      <th>force</th>\n",
       "      <th>forced</th>\n",
       "      <th>forces</th>\n",
       "      <th>forever</th>\n",
       "      <th>form</th>\n",
       "      <th>frank</th>\n",
       "      <th>free</th>\n",
       "      <th>friend</th>\n",
       "      <th>friends</th>\n",
       "      <th>friendship</th>\n",
       "      <th>future</th>\n",
       "      <th>game</th>\n",
       "      <th>gang</th>\n",
       "      <th>george</th>\n",
       "      <th>gets</th>\n",
       "      <th>getting</th>\n",
       "      <th>girl</th>\n",
       "      <th>girlfriend</th>\n",
       "      <th>girls</th>\n",
       "      <th>global</th>\n",
       "      <th>goes</th>\n",
       "      <th>going</th>\n",
       "      <th>good</th>\n",
       "      <th>government</th>\n",
       "      <th>great</th>\n",
       "      <th>group</th>\n",
       "      <th>guy</th>\n",
       "      <th>hands</th>\n",
       "      <th>hard</th>\n",
       "      <th>harry</th>\n",
       "      <th>having</th>\n",
       "      <th>head</th>\n",
       "      <th>heart</th>\n",
       "      <th>heist</th>\n",
       "      <th>hell</th>\n",
       "      <th>help</th>\n",
       "      <th>henry</th>\n",
       "      <th>hero</th>\n",
       "      <th>high</th>\n",
       "      <th>history</th>\n",
       "      <th>hit</th>\n",
       "      <th>holiday</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>home</th>\n",
       "      <th>hope</th>\n",
       "      <th>horror</th>\n",
       "      <th>hospital</th>\n",
       "      <th>hotel</th>\n",
       "      <th>house</th>\n",
       "      <th>human</th>\n",
       "      <th>humanity</th>\n",
       "      <th>humans</th>\n",
       "      <th>hunt</th>\n",
       "      <th>husband</th>\n",
       "      <th>identity</th>\n",
       "      <th>ii</th>\n",
       "      <th>including</th>\n",
       "      <th>increasingly</th>\n",
       "      <th>inside</th>\n",
       "      <th>international</th>\n",
       "      <th>investigate</th>\n",
       "      <th>involved</th>\n",
       "      <th>island</th>\n",
       "      <th>jack</th>\n",
       "      <th>james</th>\n",
       "      <th>job</th>\n",
       "      <th>john</th>\n",
       "      <th>johnny</th>\n",
       "      <th>join</th>\n",
       "      <th>joins</th>\n",
       "      <th>journey</th>\n",
       "      <th>just</th>\n",
       "      <th>kidnapped</th>\n",
       "      <th>kids</th>\n",
       "      <th>kill</th>\n",
       "      <th>killed</th>\n",
       "      <th>killer</th>\n",
       "      <th>killing</th>\n",
       "      <th>king</th>\n",
       "      <th>know</th>\n",
       "      <th>known</th>\n",
       "      <th>land</th>\n",
       "      <th>late</th>\n",
       "      <th>later</th>\n",
       "      <th>law</th>\n",
       "      <th>lawyer</th>\n",
       "      <th>lead</th>\n",
       "      <th>leader</th>\n",
       "      <th>leading</th>\n",
       "      <th>leads</th>\n",
       "      <th>learn</th>\n",
       "      <th>learns</th>\n",
       "      <th>leave</th>\n",
       "      <th>leaves</th>\n",
       "      <th>led</th>\n",
       "      <th>left</th>\n",
       "      <th>legendary</th>\n",
       "      <th>life</th>\n",
       "      <th>like</th>\n",
       "      <th>little</th>\n",
       "      <th>live</th>\n",
       "      <th>lives</th>\n",
       "      <th>living</th>\n",
       "      <th>local</th>\n",
       "      <th>london</th>\n",
       "      <th>long</th>\n",
       "      <th>look</th>\n",
       "      <th>looking</th>\n",
       "      <th>lord</th>\n",
       "      <th>los</th>\n",
       "      <th>lost</th>\n",
       "      <th>love</th>\n",
       "      <th>magical</th>\n",
       "      <th>make</th>\n",
       "      <th>makes</th>\n",
       "      <th>making</th>\n",
       "      <th>man</th>\n",
       "      <th>marriage</th>\n",
       "      <th>married</th>\n",
       "      <th>master</th>\n",
       "      <th>max</th>\n",
       "      <th>means</th>\n",
       "      <th>meet</th>\n",
       "      <th>meets</th>\n",
       "      <th>members</th>\n",
       "      <th>men</th>\n",
       "      <th>michael</th>\n",
       "      <th>middle</th>\n",
       "      <th>mike</th>\n",
       "      <th>military</th>\n",
       "      <th>mind</th>\n",
       "      <th>missing</th>\n",
       "      <th>mission</th>\n",
       "      <th>money</th>\n",
       "      <th>monster</th>\n",
       "      <th>mother</th>\n",
       "      <th>moves</th>\n",
       "      <th>movie</th>\n",
       "      <th>mr</th>\n",
       "      <th>murder</th>\n",
       "      <th>murdered</th>\n",
       "      <th>music</th>\n",
       "      <th>mysterious</th>\n",
       "      <th>mystery</th>\n",
       "      <th>named</th>\n",
       "      <th>new</th>\n",
       "      <th>night</th>\n",
       "      <th>notorious</th>\n",
       "      <th>obsessed</th>\n",
       "      <th>officer</th>\n",
       "      <th>old</th>\n",
       "      <th>older</th>\n",
       "      <th>order</th>\n",
       "      <th>owner</th>\n",
       "      <th>pair</th>\n",
       "      <th>parents</th>\n",
       "      <th>paris</th>\n",
       "      <th>park</th>\n",
       "      <th>partner</th>\n",
       "      <th>party</th>\n",
       "      <th>past</th>\n",
       "      <th>path</th>\n",
       "      <th>paul</th>\n",
       "      <th>people</th>\n",
       "      <th>perfect</th>\n",
       "      <th>person</th>\n",
       "      <th>personal</th>\n",
       "      <th>peter</th>\n",
       "      <th>place</th>\n",
       "      <th>plan</th>\n",
       "      <th>planet</th>\n",
       "      <th>plans</th>\n",
       "      <th>play</th>\n",
       "      <th>plot</th>\n",
       "      <th>police</th>\n",
       "      <th>popular</th>\n",
       "      <th>power</th>\n",
       "      <th>powerful</th>\n",
       "      <th>powers</th>\n",
       "      <th>president</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>prison</th>\n",
       "      <th>private</th>\n",
       "      <th>professor</th>\n",
       "      <th>protect</th>\n",
       "      <th>prove</th>\n",
       "      <th>puts</th>\n",
       "      <th>queen</th>\n",
       "      <th>quest</th>\n",
       "      <th>quickly</th>\n",
       "      <th>race</th>\n",
       "      <th>real</th>\n",
       "      <th>reality</th>\n",
       "      <th>realizes</th>\n",
       "      <th>really</th>\n",
       "      <th>relationship</th>\n",
       "      <th>remote</th>\n",
       "      <th>rescue</th>\n",
       "      <th>rest</th>\n",
       "      <th>return</th>\n",
       "      <th>returns</th>\n",
       "      <th>revenge</th>\n",
       "      <th>rich</th>\n",
       "      <th>right</th>\n",
       "      <th>road</th>\n",
       "      <th>rock</th>\n",
       "      <th>romance</th>\n",
       "      <th>romantic</th>\n",
       "      <th>run</th>\n",
       "      <th>runs</th>\n",
       "      <th>ruthless</th>\n",
       "      <th>sam</th>\n",
       "      <th>san</th>\n",
       "      <th>save</th>\n",
       "      <th>school</th>\n",
       "      <th>scientist</th>\n",
       "      <th>search</th>\n",
       "      <th>secret</th>\n",
       "      <th>secrets</th>\n",
       "      <th>security</th>\n",
       "      <th>seek</th>\n",
       "      <th>seeks</th>\n",
       "      <th>seemingly</th>\n",
       "      <th>self</th>\n",
       "      <th>sent</th>\n",
       "      <th>serial</th>\n",
       "      <th>series</th>\n",
       "      <th>set</th>\n",
       "      <th>sets</th>\n",
       "      <th>sex</th>\n",
       "      <th>ship</th>\n",
       "      <th>short</th>\n",
       "      <th>singer</th>\n",
       "      <th>single</th>\n",
       "      <th>sinister</th>\n",
       "      <th>sister</th>\n",
       "      <th>small</th>\n",
       "      <th>social</th>\n",
       "      <th>society</th>\n",
       "      <th>son</th>\n",
       "      <th>soon</th>\n",
       "      <th>south</th>\n",
       "      <th>space</th>\n",
       "      <th>special</th>\n",
       "      <th>spirit</th>\n",
       "      <th>star</th>\n",
       "      <th>start</th>\n",
       "      <th>starts</th>\n",
       "      <th>state</th>\n",
       "      <th>states</th>\n",
       "      <th>stay</th>\n",
       "      <th>stop</th>\n",
       "      <th>story</th>\n",
       "      <th>strange</th>\n",
       "      <th>street</th>\n",
       "      <th>struggle</th>\n",
       "      <th>struggles</th>\n",
       "      <th>struggling</th>\n",
       "      <th>student</th>\n",
       "      <th>students</th>\n",
       "      <th>suburban</th>\n",
       "      <th>successful</th>\n",
       "      <th>suddenly</th>\n",
       "      <th>summer</th>\n",
       "      <th>supernatural</th>\n",
       "      <th>survival</th>\n",
       "      <th>survive</th>\n",
       "      <th>taken</th>\n",
       "      <th>takes</th>\n",
       "      <th>taking</th>\n",
       "      <th>tale</th>\n",
       "      <th>target</th>\n",
       "      <th>teacher</th>\n",
       "      <th>team</th>\n",
       "      <th>teams</th>\n",
       "      <th>teen</th>\n",
       "      <th>teenage</th>\n",
       "      <th>teenager</th>\n",
       "      <th>tells</th>\n",
       "      <th>terrifying</th>\n",
       "      <th>test</th>\n",
       "      <th>texas</th>\n",
       "      <th>thing</th>\n",
       "      <th>things</th>\n",
       "      <th>thought</th>\n",
       "      <th>threatens</th>\n",
       "      <th>time</th>\n",
       "      <th>town</th>\n",
       "      <th>train</th>\n",
       "      <th>trapped</th>\n",
       "      <th>travel</th>\n",
       "      <th>travels</th>\n",
       "      <th>tries</th>\n",
       "      <th>trip</th>\n",
       "      <th>true</th>\n",
       "      <th>truth</th>\n",
       "      <th>try</th>\n",
       "      <th>trying</th>\n",
       "      <th>turn</th>\n",
       "      <th>turned</th>\n",
       "      <th>turns</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>ultimately</th>\n",
       "      <th>uncover</th>\n",
       "      <th>unexpected</th>\n",
       "      <th>united</th>\n",
       "      <th>unlikely</th>\n",
       "      <th>use</th>\n",
       "      <th>uses</th>\n",
       "      <th>using</th>\n",
       "      <th>vacation</th>\n",
       "      <th>vampire</th>\n",
       "      <th>veteran</th>\n",
       "      <th>village</th>\n",
       "      <th>violent</th>\n",
       "      <th>want</th>\n",
       "      <th>wants</th>\n",
       "      <th>war</th>\n",
       "      <th>way</th>\n",
       "      <th>ways</th>\n",
       "      <th>wealthy</th>\n",
       "      <th>wedding</th>\n",
       "      <th>white</th>\n",
       "      <th>wife</th>\n",
       "      <th>wild</th>\n",
       "      <th>win</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5fc86a4c6758f6963478d502</td>\n",
       "      <td>[Adventure, Action]</td>\n",
       "      <td>raiders-of-the-lost-ark</td>\n",
       "      <td>en</td>\n",
       "      <td>When Dr. Indiana Jones  the tweed-suited prof...</td>\n",
       "      <td>30.782</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>8.481832</td>\n",
       "      <td>3908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>5fc883036758f69634eeca6d</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>a-serious-man</td>\n",
       "      <td>en</td>\n",
       "      <td>It is 1967, and Larry Gopnik, a physics profes...</td>\n",
       "      <td>9.814</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.867454</td>\n",
       "      <td>2286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.442188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>5fc884ef6758f69634f73461</td>\n",
       "      <td>[Science Fiction, Adventure, Thriller]</td>\n",
       "      <td>the-hunger-games-mockingjay-part-1</td>\n",
       "      <td>en</td>\n",
       "      <td>Katniss Everdeen reluctantly becomes the symbo...</td>\n",
       "      <td>98.164</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>5.613938</td>\n",
       "      <td>2712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>5fc87c406758f69634c8fdf9</td>\n",
       "      <td>[Crime, Drama]</td>\n",
       "      <td>the-trial</td>\n",
       "      <td>en</td>\n",
       "      <td>An unassuming office worker is arrested and st...</td>\n",
       "      <td>7.391</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>7.837916</td>\n",
       "      <td>691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>5fc86f8e6758f696348fd592</td>\n",
       "      <td>[Comedy, Crime]</td>\n",
       "      <td>the-ladykillers</td>\n",
       "      <td>en</td>\n",
       "      <td>Five oddball criminals planning a bank robbery...</td>\n",
       "      <td>9.194</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>7.499157</td>\n",
       "      <td>593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>5fc876486758f69634b04d80</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>citizenfour</td>\n",
       "      <td>en</td>\n",
       "      <td>In June 2013, Laura Poitras and reporter Glenn...</td>\n",
       "      <td>11.448</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>7.816080</td>\n",
       "      <td>995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>5fc881bb6758f69634e7a521</td>\n",
       "      <td>[Animation]</td>\n",
       "      <td>dear-basketball</td>\n",
       "      <td>en</td>\n",
       "      <td>An animated telling of Kobe Bryant's titular p...</td>\n",
       "      <td>6.720</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.184035</td>\n",
       "      <td>451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>5fc878cd6758f69634baa4da</td>\n",
       "      <td>[Comedy, War]</td>\n",
       "      <td>to-be-or-not-to-be</td>\n",
       "      <td>en</td>\n",
       "      <td>During the Nazi occupation of Poland, an actin...</td>\n",
       "      <td>12.985</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>8.401639</td>\n",
       "      <td>976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>5fc8703b6758f69634919fe4</td>\n",
       "      <td>[Animation, Comedy, Music, Romance]</td>\n",
       "      <td>whats-opera-doc</td>\n",
       "      <td>en</td>\n",
       "      <td>Bugs is in drag as the Valkyrie Brunhilde who ...</td>\n",
       "      <td>6.776</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>8.221945</td>\n",
       "      <td>401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>5fc875c86758f69634ad1342</td>\n",
       "      <td>[Animation, Comedy, Family, Adventure]</td>\n",
       "      <td>up</td>\n",
       "      <td>en</td>\n",
       "      <td>Carl Fredricksen spent his entire life dreamin...</td>\n",
       "      <td>79.076</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.945097</td>\n",
       "      <td>3916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.740612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26515</td>\n",
       "      <td>0.185606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id                                  genres  \\\n",
       "80    5fc86a4c6758f6963478d502                     [Adventure, Action]   \n",
       "4330  5fc883036758f69634eeca6d                         [Comedy, Drama]   \n",
       "4651  5fc884ef6758f69634f73461  [Science Fiction, Adventure, Thriller]   \n",
       "3056  5fc87c406758f69634c8fdf9                          [Crime, Drama]   \n",
       "722   5fc86f8e6758f696348fd592                         [Comedy, Crime]   \n",
       "2000  5fc876486758f69634b04d80                           [Documentary]   \n",
       "4097  5fc881bb6758f69634e7a521                             [Animation]   \n",
       "2462  5fc878cd6758f69634baa4da                           [Comedy, War]   \n",
       "845   5fc8703b6758f69634919fe4     [Animation, Comedy, Music, Romance]   \n",
       "1871  5fc875c86758f69634ad1342  [Animation, Comedy, Family, Adventure]   \n",
       "\n",
       "                                movie_id original_language  \\\n",
       "80               raiders-of-the-lost-ark                en   \n",
       "4330                       a-serious-man                en   \n",
       "4651  the-hunger-games-mockingjay-part-1                en   \n",
       "3056                           the-trial                en   \n",
       "722                      the-ladykillers                en   \n",
       "2000                         citizenfour                en   \n",
       "4097                     dear-basketball                en   \n",
       "2462                  to-be-or-not-to-be                en   \n",
       "845                      whats-opera-doc                en   \n",
       "1871                                  up                en   \n",
       "\n",
       "                                               overview  popularity  runtime  \\\n",
       "80    When Dr. Indiana Jones  the tweed-suited prof...      30.782    115.0   \n",
       "4330  It is 1967, and Larry Gopnik, a physics profes...       9.814    106.0   \n",
       "4651  Katniss Everdeen reluctantly becomes the symbo...      98.164    123.0   \n",
       "3056  An unassuming office worker is arrested and st...       7.391    118.0   \n",
       "722   Five oddball criminals planning a bank robbery...       9.194     91.0   \n",
       "2000  In June 2013, Laura Poitras and reporter Glenn...      11.448    114.0   \n",
       "4097  An animated telling of Kobe Bryant's titular p...       6.720      6.0   \n",
       "2462  During the Nazi occupation of Poland, an actin...      12.985     99.0   \n",
       "845   Bugs is in drag as the Valkyrie Brunhilde who ...       6.776      7.0   \n",
       "1871  Carl Fredricksen spent his entire life dreamin...      79.076     96.0   \n",
       "\n",
       "      year_released  avg_rating  rating_count  000  accident  accidentally  \\\n",
       "80           1981.0    8.481832          3908  0.0       0.0           0.0   \n",
       "4330         2009.0    7.867454          2286  0.0       0.0           0.0   \n",
       "4651         2014.0    5.613938          2712  0.0       0.0           0.0   \n",
       "3056         1962.0    7.837916           691  0.0       0.0           0.0   \n",
       "722          1955.0    7.499157           593  0.0       0.0           0.0   \n",
       "2000         2014.0    7.816080           995  0.0       0.0           0.0   \n",
       "4097         2017.0    6.184035           451  0.0       0.0           0.0   \n",
       "2462         1942.0    8.401639           976  0.0       0.0           0.0   \n",
       "845          1957.0    8.221945           401  0.0       0.0           0.0   \n",
       "1871         2009.0    7.945097          3916  0.0       0.0           0.0   \n",
       "\n",
       "      act  action  adventure  agent  alex  alice  alien  america  american  \\\n",
       "80    0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "4330  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "4651  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "3056  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "722   0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "2000  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "4097  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "2462  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "845   0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "1871  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0       0.0   \n",
       "\n",
       "      ancient  angeles  apart  army  arrives  art  artist  attack  attempt  \\\n",
       "80        0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "4330      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "4651      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "3056      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "722       0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "2000      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "4097      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "2462      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "845       0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "1871      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "\n",
       "      attempts  away  baby  bad  band  based  battle  beautiful  begin  \\\n",
       "80         0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "4330       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "4651       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "3056       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "722        0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "2000       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "4097       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "2462       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "845        0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "1871       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "\n",
       "      begins  best  big  black  body  bond  book  born  boss  boy  boyfriend  \\\n",
       "80       0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "4330     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "4651     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "3056     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "722      0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "2000     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "4097     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "2462     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "845      0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "1871     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "\n",
       "      break  bring  brings  british  brother  brothers  business  california  \\\n",
       "80      0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "4330    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "4651    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "3056    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "722     0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "2000    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "4097    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "2462    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "845     0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "1871    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "\n",
       "      called  camp  captain  car  career  case  caught  century  chance  \\\n",
       "80       0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "4330     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "4651     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "3056     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "722      0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "2000     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "4097     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "2462     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "845      0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "1871     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "\n",
       "      change  charlie  child  childhood  children  christmas  cia  city  \\\n",
       "80       0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "4330     0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "4651     0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "3056     0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "722      0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "2000     0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "4097     0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "2462     0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "845      0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "1871     0.0      0.0    0.0        0.0       0.0        0.0  0.0   0.0   \n",
       "\n",
       "      class  classic  college  come  comedy  comes  community  company  \\\n",
       "80      0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "4330    0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "4651    0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "3056    0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "722     0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "2000    0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "4097    0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "2462    0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "845     0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "1871    0.0      0.0      0.0   0.0     0.0    0.0        0.0      0.0   \n",
       "\n",
       "      confront  control  cop  country  couple  course  creatures  crew  crime  \\\n",
       "80         0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "4330       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "4651       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "3056       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "722        0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "2000       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "4097       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "2462       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "845        0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "1871       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "\n",
       "      criminal  cross  dangerous  dark  daughter  david  day  days  dead  \\\n",
       "80         0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "4330       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "4651       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "3056       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "722        0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "2000       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "4097       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "2462       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "845        0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "1871       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "\n",
       "      deadly  deal  death  decide  decides  deep  desperate  despite  destroy  \\\n",
       "80       0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "4330     0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "4651     0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "3056     0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "722      0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "2000     0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "4097     0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "2462     0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "845      0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "1871     0.0   0.0    0.0     0.0      0.0   0.0        0.0      0.0      0.0   \n",
       "\n",
       "      detective  determined  different  director  discover  discovers  doctor  \\\n",
       "80          0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "4330        0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "4651        0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "3056        0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "722         0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "2000        0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "4097        0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "2462        0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "845         0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "1871        0.0         0.0        0.0       0.0       0.0        0.0     0.0   \n",
       "\n",
       "      documentary  does  doesn  dog  don        dr  dream  dreams  driver  \\\n",
       "80            0.0   0.0    0.0  0.0  0.0  0.370703    0.0     0.0     0.0   \n",
       "4330          0.0   0.0    0.0  0.0  0.0  0.000000    0.0     0.0     0.0   \n",
       "4651          0.0   0.0    0.0  0.0  0.0  0.000000    0.0     0.0     0.0   \n",
       "3056          0.0   0.0    0.0  0.0  0.0  0.000000    0.0     0.0     0.0   \n",
       "722           0.0   0.0    0.0  0.0  0.0  0.000000    0.0     0.0     0.0   \n",
       "2000          0.0   0.0    0.0  0.0  0.0  0.000000    0.0     0.0     0.0   \n",
       "4097          0.0   0.0    0.0  0.0  0.0  0.000000    0.0     0.0     0.0   \n",
       "2462          0.0   0.0    0.0  0.0  0.0  0.000000    0.0     0.0     0.0   \n",
       "845           0.0   0.0    0.0  0.0  0.0  0.000000    0.0     0.0     0.0   \n",
       "1871          0.0   0.0    0.0  0.0  0.0  0.000000    0.0     0.0     0.0   \n",
       "\n",
       "      drug  earth  eccentric  embark  embarks  encounter  end  ends  enemy  \\\n",
       "80     0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "4330   0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "4651   0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "3056   0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "722    0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "2000   0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "4097   0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "2462   0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "845    0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "1871   0.0    0.0        0.0     0.0      0.0        0.0  0.0   0.0    0.0   \n",
       "\n",
       "      england  english    entire  epic  escape  estranged  eve  events  \\\n",
       "80        0.0      0.0  0.421564   0.0     0.0        0.0  0.0     0.0   \n",
       "4330      0.0      0.0  0.000000   0.0     0.0        0.0  0.0     0.0   \n",
       "4651      0.0      0.0  0.000000   0.0     0.0        0.0  0.0     0.0   \n",
       "3056      0.0      0.0  0.000000   0.0     0.0        0.0  0.0     0.0   \n",
       "722       0.0      0.0  0.000000   0.0     0.0        0.0  0.0     0.0   \n",
       "2000      0.0      0.0  0.000000   0.0     0.0        0.0  0.0     0.0   \n",
       "4097      0.0      0.0  0.000000   0.0     0.0        0.0  0.0     0.0   \n",
       "2462      0.0      0.0  0.000000   0.0     0.0        0.0  0.0     0.0   \n",
       "845       0.0      0.0  0.000000   0.0     0.0        0.0  0.0     0.0   \n",
       "1871      0.0      0.0  0.349037   0.0     0.0        0.0  0.0     0.0   \n",
       "\n",
       "      eventually  evil   ex  existence  experience  eye  face  faces  fall  \\\n",
       "80           0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "4330         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "4651         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "3056         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "722          0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "2000         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "4097         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "2462         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "845          0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "1871         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   0.0   \n",
       "\n",
       "      falls  family  famous  far      fate  father  fbi  fear  fellow  fight  \\\n",
       "80      0.0     0.0     0.0  0.0  0.000000     0.0  0.0   0.0     0.0    0.0   \n",
       "4330    0.0     0.0     0.0  0.0  0.000000     0.0  0.0   0.0     0.0    0.0   \n",
       "4651    0.0     0.0     0.0  0.0  0.000000     0.0  0.0   0.0     0.0    0.0   \n",
       "3056    0.0     0.0     0.0  0.0  0.000000     0.0  0.0   0.0     0.0    0.0   \n",
       "722     0.0     0.0     0.0  0.0  0.000000     0.0  0.0   0.0     0.0    0.0   \n",
       "2000    0.0     0.0     0.0  0.0  0.000000     0.0  0.0   0.0     0.0    0.0   \n",
       "4097    0.0     0.0     0.0  0.0  0.000000     0.0  0.0   0.0     0.0    0.0   \n",
       "2462    0.0     0.0     0.0  0.0  0.000000     0.0  0.0   0.0     0.0    0.0   \n",
       "845     0.0     0.0     0.0  0.0  0.000000     0.0  0.0   0.0     0.0    0.0   \n",
       "1871    0.0     0.0     0.0  0.0  0.338436     0.0  0.0   0.0     0.0    0.0   \n",
       "\n",
       "      fighting  film  final  finally     finds  following  follows  force  \\\n",
       "80         0.0   0.0    0.0      0.0  0.280222        0.0      0.0    0.0   \n",
       "4330       0.0   0.0    0.0      0.0  0.000000        0.0      0.0    0.0   \n",
       "4651       0.0   0.0    0.0      0.0  0.000000        0.0      0.0    0.0   \n",
       "3056       0.0   0.0    0.0      0.0  0.000000        0.0      0.0    0.0   \n",
       "722        0.0   0.0    0.0      0.0  0.000000        0.0      0.0    0.0   \n",
       "2000       0.0   0.0    0.0      0.0  0.000000        0.0      0.0    0.0   \n",
       "4097       0.0   0.0    0.0      0.0  0.000000        0.0      0.0    0.0   \n",
       "2462       0.0   0.0    0.0      0.0  0.000000        0.0      0.0    0.0   \n",
       "845        0.0   0.0    0.0      0.0  0.000000        0.0      0.0    0.0   \n",
       "1871       0.0   0.0    0.0      0.0  0.000000        0.0      0.0    0.0   \n",
       "\n",
       "      forced  forces  forever  form  frank  free  friend  friends  friendship  \\\n",
       "80       0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "4330     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "4651     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "3056     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "722      0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "2000     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "4097     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "2462     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "845      0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "1871     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0         0.0   \n",
       "\n",
       "      future  game  gang  george  gets  getting  girl  girlfriend  girls  \\\n",
       "80       0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "4330     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "4651     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "3056     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "722      0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "2000     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "4097     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "2462     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "845      0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "1871     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0    0.0   \n",
       "\n",
       "      global  goes  going  good  government  great  group  guy  hands  hard  \\\n",
       "80       0.0   0.0    0.0   0.0    0.378118    0.0    0.0  0.0    0.0   0.0   \n",
       "4330     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   0.0   \n",
       "4651     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   0.0   \n",
       "3056     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   0.0   \n",
       "722      0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   0.0   \n",
       "2000     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   0.0   \n",
       "4097     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   0.0   \n",
       "2462     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   0.0   \n",
       "845      0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   0.0   \n",
       "1871     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   0.0   \n",
       "\n",
       "      harry  having  head  heart  heist  hell  help  henry  hero  high  \\\n",
       "80      0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "4330    0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "4651    0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "3056    0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "722     0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "2000    0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "4097    0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "2462    0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "845     0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "1871    0.0     0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0   0.0   \n",
       "\n",
       "      history  hit  holiday  hollywood  home  hope  horror  hospital  hotel  \\\n",
       "80        0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "4330      0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "4651      0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "3056      0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "722       0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "2000      0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "4097      0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "2462      0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "845       0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "1871      0.0  0.0      0.0        0.0   0.0   0.0     0.0       0.0    0.0   \n",
       "\n",
       "      house  human  humanity  humans  hunt  husband  identity   ii  including  \\\n",
       "80      0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "4330    0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "4651    0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "3056    0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "722     0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "2000    0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "4097    0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "2462    0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "845     0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "1871    0.0    0.0       0.0     0.0   0.0      0.0       0.0  0.0        0.0   \n",
       "\n",
       "      increasingly  inside  international  investigate  involved  island  \\\n",
       "80             0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "4330           0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "4651           0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "3056           0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "722            0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "2000           0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "4097           0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "2462           0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "845            0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "1871           0.0     0.0            0.0          0.0       0.0     0.0   \n",
       "\n",
       "      jack  james  job  john  johnny  join  joins  journey      just  \\\n",
       "80     0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.327787   \n",
       "4330   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.482463   \n",
       "4651   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.000000   \n",
       "3056   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.000000   \n",
       "722    0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.000000   \n",
       "2000   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.000000   \n",
       "4097   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.000000   \n",
       "2462   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.000000   \n",
       "845    0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.000000   \n",
       "1871   0.0    0.0  0.0   0.0     0.0   0.0    0.0      0.0  0.000000   \n",
       "\n",
       "      kidnapped  kids  kill  killed  killer  killing  king  know  known  land  \\\n",
       "80          0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "4330        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "4651        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "3056        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "722         0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "2000        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "4097        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "2462        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "845         0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "1871        0.0   0.0   0.0     0.0     0.0      0.0   0.0   0.0    0.0   0.0   \n",
       "\n",
       "      late  later  law  lawyer  lead  leader  leading  leads  learn  learns  \\\n",
       "80     0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "4330   0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "4651   0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "3056   0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "722    0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "2000   0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "4097   0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "2462   0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "845    0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "1871   0.0    0.0  0.0     0.0   0.0     0.0      0.0    0.0    0.0     0.0   \n",
       "\n",
       "      leave  leaves  led  left  legendary      life  like  little  live  \\\n",
       "80      0.0     0.0  0.0   0.0    0.41008  0.000000   0.0     0.0   0.0   \n",
       "4330    0.0     0.0  0.0   0.0    0.00000  0.000000   0.0     0.0   0.0   \n",
       "4651    0.0     0.0  0.0   0.0    0.00000  0.000000   0.0     0.0   0.0   \n",
       "3056    0.0     0.0  0.0   0.0    0.00000  0.000000   0.0     0.0   0.0   \n",
       "722     0.0     0.0  0.0   0.0    0.00000  0.000000   0.0     0.0   0.0   \n",
       "2000    0.0     0.0  0.0   0.0    0.00000  0.000000   0.0     0.0   0.0   \n",
       "4097    0.0     0.0  0.0   0.0    0.00000  0.000000   0.0     0.0   0.0   \n",
       "2462    0.0     0.0  0.0   0.0    0.00000  0.000000   0.0     0.0   0.0   \n",
       "845     0.0     0.0  0.0   0.0    0.00000  0.000000   0.0     0.0   0.0   \n",
       "1871    0.0     0.0  0.0   0.0    0.00000  0.740612   0.0     0.0   0.0   \n",
       "\n",
       "      lives  living  local  london  long  look  looking  lord  los  lost  \\\n",
       "80      0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "4330    0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "4651    0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "3056    0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "722     0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "2000    0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "4097    0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "2462    0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "845     0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "1871    0.0     0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0   0.0   \n",
       "\n",
       "          love  magical  make  makes  making  man  marriage  married  master  \\\n",
       "80    0.000000      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "4330  0.406128      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "4651  0.000000      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "3056  0.000000      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "722   0.000000      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "2000  0.000000      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "4097  0.000000      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "2462  0.000000      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "845   0.000000      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "1871  0.000000      0.0   0.0    0.0     0.0  0.0       0.0      0.0     0.0   \n",
       "\n",
       "      max  means  meet  meets  members  men  michael  middle  mike  military  \\\n",
       "80    0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "4330  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "4651  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "3056  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "722   0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "2000  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "4097  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "2462  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "845   0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "1871  0.0    0.0   0.0    0.0      0.0  0.0      0.0     0.0   0.0       0.0   \n",
       "\n",
       "      mind  missing  mission  money  monster  mother  moves  movie   mr  \\\n",
       "80     0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "4330   0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "4651   0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "3056   0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "722    0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "2000   0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "4097   0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "2462   0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "845    0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "1871   0.0      0.0      0.0    0.0      0.0     0.0    0.0    0.0  0.0   \n",
       "\n",
       "      murder  murdered  music  mysterious  mystery    named       new  night  \\\n",
       "80       0.0       0.0    0.0         0.0      0.0  0.00000  0.000000    0.0   \n",
       "4330     0.0       0.0    0.0         0.0      0.0  0.00000  0.000000    0.0   \n",
       "4651     0.0       0.0    0.0         0.0      0.0  0.00000  0.000000    0.0   \n",
       "3056     0.0       0.0    0.0         0.0      0.0  0.00000  0.000000    0.0   \n",
       "722      0.0       0.0    0.0         0.0      0.0  0.00000  0.000000    0.0   \n",
       "2000     0.0       0.0    0.0         0.0      0.0  0.00000  0.000000    0.0   \n",
       "4097     0.0       0.0    0.0         0.0      0.0  0.00000  0.000000    0.0   \n",
       "2462     0.0       0.0    0.0         0.0      0.0  0.00000  0.000000    0.0   \n",
       "845      0.0       0.0    0.0         0.0      0.0  0.00000  0.000000    0.0   \n",
       "1871     0.0       0.0    0.0         0.0      0.0  0.26515  0.185606    0.0   \n",
       "\n",
       "      notorious  obsessed  officer       old  older  order  owner  pair  \\\n",
       "80          0.0       0.0      0.0  0.000000    0.0    0.0    0.0   0.0   \n",
       "4330        0.0       0.0      0.0  0.000000    0.0    0.0    0.0   0.0   \n",
       "4651        0.0       0.0      0.0  0.000000    0.0    0.0    0.0   0.0   \n",
       "3056        0.0       0.0      0.0  0.000000    0.0    0.0    0.0   0.0   \n",
       "722         0.0       0.0      0.0  0.000000    0.0    0.0    0.0   0.0   \n",
       "2000        0.0       0.0      0.0  0.000000    0.0    0.0    0.0   0.0   \n",
       "4097        0.0       0.0      0.0  0.000000    0.0    0.0    0.0   0.0   \n",
       "2462        0.0       0.0      0.0  0.000000    0.0    0.0    0.0   0.0   \n",
       "845         0.0       0.0      0.0  0.000000    0.0    0.0    0.0   0.0   \n",
       "1871        0.0       0.0      0.0  0.229002    0.0    0.0    0.0   0.0   \n",
       "\n",
       "      parents  paris  park  partner  party  past  path  paul  people  perfect  \\\n",
       "80        0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "4330      0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "4651      0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "3056      0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "722       0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "2000      0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "4097      0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "2462      0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "845       0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "1871      0.0    0.0   0.0      0.0    0.0   0.0   0.0   0.0     0.0      0.0   \n",
       "\n",
       "      person  personal  peter  place  plan  planet  plans  play  plot  police  \\\n",
       "80       0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "4330     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "4651     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "3056     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "722      0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "2000     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "4097     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "2462     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "845      0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "1871     0.0       0.0    0.0    0.0   0.0     0.0    0.0   0.0   0.0     0.0   \n",
       "\n",
       "      popular  power  powerful  powers  president  prince  princess  prison  \\\n",
       "80        0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "4330      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "4651      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "3056      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "722       0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "2000      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "4097      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "2462      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "845       0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "1871      0.0    0.0       0.0     0.0        0.0     0.0       0.0     0.0   \n",
       "\n",
       "      private  professor  protect  prove  puts  queen  quest  quickly  race  \\\n",
       "80        0.0   0.433308      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "4330      0.0   0.637777      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "4651      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "3056      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "722       0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "2000      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "4097      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "2462      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "845       0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "1871      0.0   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   \n",
       "\n",
       "      real  reality  realizes  really  relationship  remote  rescue  rest  \\\n",
       "80     0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "4330   0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "4651   0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "3056   0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "722    0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "2000   0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "4097   0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "2462   0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "845    0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "1871   0.0      0.0       0.0     0.0           0.0     0.0     0.0   0.0   \n",
       "\n",
       "      return  returns  revenge  rich  right  road  rock  romance  romantic  \\\n",
       "80       0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "4330     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "4651     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "3056     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "722      0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "2000     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "4097     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "2462     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "845      0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "1871     0.0      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0   \n",
       "\n",
       "      run  runs  ruthless  sam  san  save  school  scientist  search  secret  \\\n",
       "80    0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "4330  0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "4651  0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "3056  0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "722   0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "2000  0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "4097  0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "2462  0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "845   0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "1871  0.0   0.0       0.0  0.0  0.0   0.0     0.0        0.0     0.0     0.0   \n",
       "\n",
       "      secrets  security  seek  seeks  seemingly  self  sent  serial  series  \\\n",
       "80        0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "4330      0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "4651      0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "3056      0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "722       0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "2000      0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "4097      0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "2462      0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "845       0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "1871      0.0       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "\n",
       "      set  sets  sex  ship  short  singer  single  sinister  sister  small  \\\n",
       "80    0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "4330  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "4651  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "3056  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "722   0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "2000  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "4097  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "2462  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "845   0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "1871  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "\n",
       "      social  society  son  soon  south  space  special  spirit  star  start  \\\n",
       "80       0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "4330     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "4651     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "3056     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "722      0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "2000     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "4097     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "2462     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "845      0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "1871     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0    0.0   \n",
       "\n",
       "      starts  state  states  stay  stop  story  strange  street  struggle  \\\n",
       "80       0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "4330     0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "4651     0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "3056     0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "722      0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "2000     0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "4097     0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "2462     0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "845      0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "1871     0.0    0.0     0.0   0.0   0.0    0.0      0.0     0.0       0.0   \n",
       "\n",
       "      struggles  struggling  student  students  suburban  successful  \\\n",
       "80          0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "4330        0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "4651        0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "3056        0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "722         0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "2000        0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "4097        0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "2462        0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "845         0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "1871        0.0         0.0      0.0       0.0       0.0         0.0   \n",
       "\n",
       "      suddenly  summer  supernatural  survival  survive  taken  takes  taking  \\\n",
       "80         0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "4330       0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "4651       0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "3056       0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "722        0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "2000       0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "4097       0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "2462       0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "845        0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "1871       0.0     0.0           0.0       0.0      0.0    0.0    0.0     0.0   \n",
       "\n",
       "      tale  target  teacher  team  teams  teen  teenage  teenager  tells  \\\n",
       "80     0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "4330   0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "4651   0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "3056   0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "722    0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "2000   0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "4097   0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "2462   0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "845    0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "1871   0.0     0.0      0.0   0.0    0.0   0.0      0.0       0.0    0.0   \n",
       "\n",
       "      terrifying  test  texas  thing  things  thought  threatens  time  town  \\\n",
       "80           0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "4330         0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "4651         0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "3056         0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "722          0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "2000         0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "4097         0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "2462         0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "845          0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "1871         0.0   0.0    0.0    0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "\n",
       "      train  trapped  travel  travels  tries  trip  true  truth  try  trying  \\\n",
       "80      0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "4330    0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "4651    0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "3056    0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "722     0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "2000    0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "4097    0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "2462    0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "845     0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "1871    0.0      0.0     0.0      0.0    0.0   0.0   0.0    0.0  0.0     0.0   \n",
       "\n",
       "      turn  turned  turns  ultimate  ultimately  uncover  unexpected  united  \\\n",
       "80     0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "4330   0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "4651   0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "3056   0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "722    0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "2000   0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "4097   0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "2462   0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "845    0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "1871   0.0     0.0    0.0       0.0         0.0      0.0         0.0     0.0   \n",
       "\n",
       "      unlikely  use  uses  using  vacation  vampire  veteran  village  \\\n",
       "80         0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "4330       0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "4651       0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "3056       0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "722        0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "2000       0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "4097       0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "2462       0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "845        0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "1871       0.0  0.0   0.0    0.0       0.0      0.0      0.0      0.0   \n",
       "\n",
       "      violent  want  wants  war  way  ways  wealthy  wedding  white      wife  \\\n",
       "80        0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.000000   \n",
       "4330      0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.442188   \n",
       "4651      0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.000000   \n",
       "3056      0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.000000   \n",
       "722       0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.000000   \n",
       "2000      0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.000000   \n",
       "4097      0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.000000   \n",
       "2462      0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.000000   \n",
       "845       0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.000000   \n",
       "1871      0.0   0.0    0.0  0.0  0.0   0.0      0.0      0.0    0.0  0.000000   \n",
       "\n",
       "      wild  win  woman  women  work  working  works  world  writer  wrong  \\\n",
       "80     0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "4330   0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "4651   0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "3056   0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "722    0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "2000   0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "4097   0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "2462   0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "845    0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "1871   0.0  0.0    0.0    0.0   0.0      0.0    0.0    0.0     0.0    0.0   \n",
       "\n",
       "          year  years  york  young  younger  \n",
       "80    0.000000    0.0   0.0    0.0      0.0  \n",
       "4330  0.000000    0.0   0.0    0.0      0.0  \n",
       "4651  0.000000    0.0   0.0    0.0      0.0  \n",
       "3056  0.000000    0.0   0.0    0.0      0.0  \n",
       "722   0.000000    0.0   0.0    0.0      0.0  \n",
       "2000  0.000000    0.0   0.0    0.0      0.0  \n",
       "4097  0.000000    0.0   0.0    0.0      0.0  \n",
       "2462  0.000000    0.0   0.0    0.0      0.0  \n",
       "845   0.000000    0.0   0.0    0.0      0.0  \n",
       "1871  0.240691    0.0   0.0    0.0      0.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing Similar Movies\n",
    "movie_df.iloc[indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f49dd2d-05e8-4c22-bed0-1795db4bf468",
   "metadata": {},
   "source": [
    "### Initial Modelling Insights\n",
    "This seems to be working okay... Hunger Games seems like a reasonably similar Adventure movie. Outside of that we dont have any great reccomendations. We see To be or not to be has a similar mention of Nazi Germany as our original movie have...\n",
    "\n",
    "Probably the best neighbour when evaluating qualitatively is Hunger Games, as that is Action/Adventure and is also a blockbuster style series film as Indiana Jones.\n",
    "\n",
    "**Room for improvement:** To add weighting to our comparison so that it adds more weight to genre. I dont think we have enough adventure/action movies here.\n",
    "\n",
    "**Important Note:** Nearest neighbours uses euclidian values by default, we can use these as our sort of \"score\" for our model. We will re do this model except using cosine similarity as our distance metric next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "feccbb6a-5300-4f57-90ba-7e87a9f8717f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.76837158e-07, 2.40022630e+01, 2.49713292e+01, 2.51455512e+01,\n",
       "        2.52060884e+01, 2.56604858e+01, 2.57354721e+01, 2.58172811e+01,\n",
       "        2.63741874e+01, 2.64813013e+01]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eucl_distance_raiders = distances\n",
    "\n",
    "eucl_distance_raiders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cacd29-0dcb-45f5-825d-84ce9a2fc7dd",
   "metadata": {},
   "source": [
    "Lets Try Again but with cosine. We will also scale our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "598ef1f5-8b70-4e56-a416-a345bd81db93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = movies_ML.drop(['movie_id'], axis=1)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the NearestNeighbors model\n",
    "#Using euclidian distance as distance metric by default\n",
    "nn_cos = NearestNeighbors(n_neighbors=10, algorithm='auto', metric = 'cosine')\n",
    "\n",
    "# Fit the model to your data\n",
    "nn_cos.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53c9efd9-7226-4898-a3b7-65c7404ce8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors Indices: [[  80 4330  696 3454 1655  847  965 4497 1921 4221]]\n",
      "Cosine Similarity to Neighbors: [[4.44089210e-16 5.38809972e-01 6.42677312e-01 6.58909809e-01\n",
      "  6.70335299e-01 6.78279507e-01 6.80386927e-01 6.82067243e-01\n",
      "  6.87740024e-01 6.88019300e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Get the features of Raiders of the Lost Ark movie \n",
    "input_movie_features = X_scaled[[indy_index]]  \n",
    "\n",
    "# Find the nearest neighbors with new model\n",
    "distances, indices = nn_cos.kneighbors(input_movie_features, n_neighbors=10)\n",
    "\n",
    "# The 'indices' variable contains the indices of the nearest neighbors\n",
    "# The 'distances' variable contains the distances to these neighbors\n",
    "\n",
    "# Print the indices and distances of the nearest neighbors\n",
    "print(\"Nearest Neighbors Indices:\", indices)\n",
    "print(\"Cosine Similarity to Neighbors:\", distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1ce6bf2-d4c8-4a7d-b3e8-a585474ddecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>000</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>agent</th>\n",
       "      <th>alex</th>\n",
       "      <th>alice</th>\n",
       "      <th>alien</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>ancient</th>\n",
       "      <th>angeles</th>\n",
       "      <th>apart</th>\n",
       "      <th>army</th>\n",
       "      <th>arrives</th>\n",
       "      <th>art</th>\n",
       "      <th>artist</th>\n",
       "      <th>attack</th>\n",
       "      <th>attempt</th>\n",
       "      <th>attempts</th>\n",
       "      <th>away</th>\n",
       "      <th>baby</th>\n",
       "      <th>bad</th>\n",
       "      <th>band</th>\n",
       "      <th>based</th>\n",
       "      <th>battle</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>begin</th>\n",
       "      <th>begins</th>\n",
       "      <th>best</th>\n",
       "      <th>big</th>\n",
       "      <th>black</th>\n",
       "      <th>body</th>\n",
       "      <th>bond</th>\n",
       "      <th>book</th>\n",
       "      <th>born</th>\n",
       "      <th>boss</th>\n",
       "      <th>boy</th>\n",
       "      <th>boyfriend</th>\n",
       "      <th>break</th>\n",
       "      <th>bring</th>\n",
       "      <th>brings</th>\n",
       "      <th>british</th>\n",
       "      <th>brother</th>\n",
       "      <th>brothers</th>\n",
       "      <th>business</th>\n",
       "      <th>california</th>\n",
       "      <th>called</th>\n",
       "      <th>camp</th>\n",
       "      <th>captain</th>\n",
       "      <th>car</th>\n",
       "      <th>career</th>\n",
       "      <th>case</th>\n",
       "      <th>caught</th>\n",
       "      <th>century</th>\n",
       "      <th>chance</th>\n",
       "      <th>change</th>\n",
       "      <th>charlie</th>\n",
       "      <th>child</th>\n",
       "      <th>childhood</th>\n",
       "      <th>children</th>\n",
       "      <th>christmas</th>\n",
       "      <th>cia</th>\n",
       "      <th>city</th>\n",
       "      <th>class</th>\n",
       "      <th>classic</th>\n",
       "      <th>college</th>\n",
       "      <th>come</th>\n",
       "      <th>comedy</th>\n",
       "      <th>comes</th>\n",
       "      <th>community</th>\n",
       "      <th>company</th>\n",
       "      <th>confront</th>\n",
       "      <th>control</th>\n",
       "      <th>cop</th>\n",
       "      <th>country</th>\n",
       "      <th>couple</th>\n",
       "      <th>course</th>\n",
       "      <th>creatures</th>\n",
       "      <th>crew</th>\n",
       "      <th>crime</th>\n",
       "      <th>criminal</th>\n",
       "      <th>cross</th>\n",
       "      <th>dangerous</th>\n",
       "      <th>dark</th>\n",
       "      <th>daughter</th>\n",
       "      <th>david</th>\n",
       "      <th>day</th>\n",
       "      <th>days</th>\n",
       "      <th>dead</th>\n",
       "      <th>deadly</th>\n",
       "      <th>deal</th>\n",
       "      <th>death</th>\n",
       "      <th>decide</th>\n",
       "      <th>decides</th>\n",
       "      <th>deep</th>\n",
       "      <th>desperate</th>\n",
       "      <th>despite</th>\n",
       "      <th>destroy</th>\n",
       "      <th>detective</th>\n",
       "      <th>determined</th>\n",
       "      <th>different</th>\n",
       "      <th>director</th>\n",
       "      <th>discover</th>\n",
       "      <th>discovers</th>\n",
       "      <th>doctor</th>\n",
       "      <th>documentary</th>\n",
       "      <th>does</th>\n",
       "      <th>doesn</th>\n",
       "      <th>dog</th>\n",
       "      <th>don</th>\n",
       "      <th>dr</th>\n",
       "      <th>dream</th>\n",
       "      <th>dreams</th>\n",
       "      <th>driver</th>\n",
       "      <th>drug</th>\n",
       "      <th>earth</th>\n",
       "      <th>eccentric</th>\n",
       "      <th>embark</th>\n",
       "      <th>embarks</th>\n",
       "      <th>encounter</th>\n",
       "      <th>end</th>\n",
       "      <th>ends</th>\n",
       "      <th>enemy</th>\n",
       "      <th>england</th>\n",
       "      <th>english</th>\n",
       "      <th>entire</th>\n",
       "      <th>epic</th>\n",
       "      <th>escape</th>\n",
       "      <th>estranged</th>\n",
       "      <th>eve</th>\n",
       "      <th>events</th>\n",
       "      <th>eventually</th>\n",
       "      <th>evil</th>\n",
       "      <th>ex</th>\n",
       "      <th>existence</th>\n",
       "      <th>experience</th>\n",
       "      <th>eye</th>\n",
       "      <th>face</th>\n",
       "      <th>faces</th>\n",
       "      <th>fall</th>\n",
       "      <th>falls</th>\n",
       "      <th>family</th>\n",
       "      <th>famous</th>\n",
       "      <th>far</th>\n",
       "      <th>fate</th>\n",
       "      <th>father</th>\n",
       "      <th>fbi</th>\n",
       "      <th>fear</th>\n",
       "      <th>fellow</th>\n",
       "      <th>fight</th>\n",
       "      <th>fighting</th>\n",
       "      <th>film</th>\n",
       "      <th>final</th>\n",
       "      <th>finally</th>\n",
       "      <th>finds</th>\n",
       "      <th>following</th>\n",
       "      <th>follows</th>\n",
       "      <th>force</th>\n",
       "      <th>forced</th>\n",
       "      <th>forces</th>\n",
       "      <th>forever</th>\n",
       "      <th>form</th>\n",
       "      <th>frank</th>\n",
       "      <th>free</th>\n",
       "      <th>friend</th>\n",
       "      <th>friends</th>\n",
       "      <th>friendship</th>\n",
       "      <th>future</th>\n",
       "      <th>game</th>\n",
       "      <th>gang</th>\n",
       "      <th>george</th>\n",
       "      <th>gets</th>\n",
       "      <th>getting</th>\n",
       "      <th>girl</th>\n",
       "      <th>girlfriend</th>\n",
       "      <th>girls</th>\n",
       "      <th>global</th>\n",
       "      <th>goes</th>\n",
       "      <th>going</th>\n",
       "      <th>good</th>\n",
       "      <th>government</th>\n",
       "      <th>great</th>\n",
       "      <th>group</th>\n",
       "      <th>guy</th>\n",
       "      <th>hands</th>\n",
       "      <th>hard</th>\n",
       "      <th>harry</th>\n",
       "      <th>having</th>\n",
       "      <th>head</th>\n",
       "      <th>heart</th>\n",
       "      <th>heist</th>\n",
       "      <th>hell</th>\n",
       "      <th>help</th>\n",
       "      <th>henry</th>\n",
       "      <th>hero</th>\n",
       "      <th>high</th>\n",
       "      <th>history</th>\n",
       "      <th>hit</th>\n",
       "      <th>holiday</th>\n",
       "      <th>hollywood</th>\n",
       "      <th>home</th>\n",
       "      <th>hope</th>\n",
       "      <th>horror</th>\n",
       "      <th>hospital</th>\n",
       "      <th>hotel</th>\n",
       "      <th>house</th>\n",
       "      <th>human</th>\n",
       "      <th>humanity</th>\n",
       "      <th>humans</th>\n",
       "      <th>hunt</th>\n",
       "      <th>husband</th>\n",
       "      <th>identity</th>\n",
       "      <th>ii</th>\n",
       "      <th>including</th>\n",
       "      <th>increasingly</th>\n",
       "      <th>inside</th>\n",
       "      <th>international</th>\n",
       "      <th>investigate</th>\n",
       "      <th>involved</th>\n",
       "      <th>island</th>\n",
       "      <th>jack</th>\n",
       "      <th>james</th>\n",
       "      <th>job</th>\n",
       "      <th>john</th>\n",
       "      <th>johnny</th>\n",
       "      <th>join</th>\n",
       "      <th>joins</th>\n",
       "      <th>journey</th>\n",
       "      <th>just</th>\n",
       "      <th>kidnapped</th>\n",
       "      <th>kids</th>\n",
       "      <th>kill</th>\n",
       "      <th>killed</th>\n",
       "      <th>killer</th>\n",
       "      <th>killing</th>\n",
       "      <th>king</th>\n",
       "      <th>know</th>\n",
       "      <th>known</th>\n",
       "      <th>land</th>\n",
       "      <th>late</th>\n",
       "      <th>later</th>\n",
       "      <th>law</th>\n",
       "      <th>lawyer</th>\n",
       "      <th>lead</th>\n",
       "      <th>leader</th>\n",
       "      <th>leading</th>\n",
       "      <th>leads</th>\n",
       "      <th>learn</th>\n",
       "      <th>learns</th>\n",
       "      <th>leave</th>\n",
       "      <th>leaves</th>\n",
       "      <th>led</th>\n",
       "      <th>left</th>\n",
       "      <th>legendary</th>\n",
       "      <th>life</th>\n",
       "      <th>like</th>\n",
       "      <th>little</th>\n",
       "      <th>live</th>\n",
       "      <th>lives</th>\n",
       "      <th>living</th>\n",
       "      <th>local</th>\n",
       "      <th>london</th>\n",
       "      <th>long</th>\n",
       "      <th>look</th>\n",
       "      <th>looking</th>\n",
       "      <th>lord</th>\n",
       "      <th>los</th>\n",
       "      <th>lost</th>\n",
       "      <th>love</th>\n",
       "      <th>magical</th>\n",
       "      <th>make</th>\n",
       "      <th>makes</th>\n",
       "      <th>making</th>\n",
       "      <th>man</th>\n",
       "      <th>marriage</th>\n",
       "      <th>married</th>\n",
       "      <th>master</th>\n",
       "      <th>max</th>\n",
       "      <th>means</th>\n",
       "      <th>meet</th>\n",
       "      <th>meets</th>\n",
       "      <th>members</th>\n",
       "      <th>men</th>\n",
       "      <th>michael</th>\n",
       "      <th>middle</th>\n",
       "      <th>mike</th>\n",
       "      <th>military</th>\n",
       "      <th>mind</th>\n",
       "      <th>missing</th>\n",
       "      <th>mission</th>\n",
       "      <th>money</th>\n",
       "      <th>monster</th>\n",
       "      <th>mother</th>\n",
       "      <th>moves</th>\n",
       "      <th>movie</th>\n",
       "      <th>mr</th>\n",
       "      <th>murder</th>\n",
       "      <th>murdered</th>\n",
       "      <th>music</th>\n",
       "      <th>mysterious</th>\n",
       "      <th>mystery</th>\n",
       "      <th>named</th>\n",
       "      <th>new</th>\n",
       "      <th>night</th>\n",
       "      <th>notorious</th>\n",
       "      <th>obsessed</th>\n",
       "      <th>officer</th>\n",
       "      <th>old</th>\n",
       "      <th>older</th>\n",
       "      <th>order</th>\n",
       "      <th>owner</th>\n",
       "      <th>pair</th>\n",
       "      <th>parents</th>\n",
       "      <th>paris</th>\n",
       "      <th>park</th>\n",
       "      <th>partner</th>\n",
       "      <th>party</th>\n",
       "      <th>past</th>\n",
       "      <th>path</th>\n",
       "      <th>paul</th>\n",
       "      <th>people</th>\n",
       "      <th>perfect</th>\n",
       "      <th>person</th>\n",
       "      <th>personal</th>\n",
       "      <th>peter</th>\n",
       "      <th>place</th>\n",
       "      <th>plan</th>\n",
       "      <th>planet</th>\n",
       "      <th>plans</th>\n",
       "      <th>play</th>\n",
       "      <th>plot</th>\n",
       "      <th>police</th>\n",
       "      <th>popular</th>\n",
       "      <th>power</th>\n",
       "      <th>powerful</th>\n",
       "      <th>powers</th>\n",
       "      <th>president</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>prison</th>\n",
       "      <th>private</th>\n",
       "      <th>professor</th>\n",
       "      <th>protect</th>\n",
       "      <th>prove</th>\n",
       "      <th>puts</th>\n",
       "      <th>queen</th>\n",
       "      <th>quest</th>\n",
       "      <th>quickly</th>\n",
       "      <th>race</th>\n",
       "      <th>real</th>\n",
       "      <th>reality</th>\n",
       "      <th>realizes</th>\n",
       "      <th>really</th>\n",
       "      <th>relationship</th>\n",
       "      <th>remote</th>\n",
       "      <th>rescue</th>\n",
       "      <th>rest</th>\n",
       "      <th>return</th>\n",
       "      <th>returns</th>\n",
       "      <th>revenge</th>\n",
       "      <th>rich</th>\n",
       "      <th>right</th>\n",
       "      <th>road</th>\n",
       "      <th>rock</th>\n",
       "      <th>romance</th>\n",
       "      <th>romantic</th>\n",
       "      <th>run</th>\n",
       "      <th>runs</th>\n",
       "      <th>ruthless</th>\n",
       "      <th>sam</th>\n",
       "      <th>san</th>\n",
       "      <th>save</th>\n",
       "      <th>school</th>\n",
       "      <th>scientist</th>\n",
       "      <th>search</th>\n",
       "      <th>secret</th>\n",
       "      <th>secrets</th>\n",
       "      <th>security</th>\n",
       "      <th>seek</th>\n",
       "      <th>seeks</th>\n",
       "      <th>seemingly</th>\n",
       "      <th>self</th>\n",
       "      <th>sent</th>\n",
       "      <th>serial</th>\n",
       "      <th>series</th>\n",
       "      <th>set</th>\n",
       "      <th>sets</th>\n",
       "      <th>sex</th>\n",
       "      <th>ship</th>\n",
       "      <th>short</th>\n",
       "      <th>singer</th>\n",
       "      <th>single</th>\n",
       "      <th>sinister</th>\n",
       "      <th>sister</th>\n",
       "      <th>small</th>\n",
       "      <th>social</th>\n",
       "      <th>society</th>\n",
       "      <th>son</th>\n",
       "      <th>soon</th>\n",
       "      <th>south</th>\n",
       "      <th>space</th>\n",
       "      <th>special</th>\n",
       "      <th>spirit</th>\n",
       "      <th>star</th>\n",
       "      <th>start</th>\n",
       "      <th>starts</th>\n",
       "      <th>state</th>\n",
       "      <th>states</th>\n",
       "      <th>stay</th>\n",
       "      <th>stop</th>\n",
       "      <th>story</th>\n",
       "      <th>strange</th>\n",
       "      <th>street</th>\n",
       "      <th>struggle</th>\n",
       "      <th>struggles</th>\n",
       "      <th>struggling</th>\n",
       "      <th>student</th>\n",
       "      <th>students</th>\n",
       "      <th>suburban</th>\n",
       "      <th>successful</th>\n",
       "      <th>suddenly</th>\n",
       "      <th>summer</th>\n",
       "      <th>supernatural</th>\n",
       "      <th>survival</th>\n",
       "      <th>survive</th>\n",
       "      <th>taken</th>\n",
       "      <th>takes</th>\n",
       "      <th>taking</th>\n",
       "      <th>tale</th>\n",
       "      <th>target</th>\n",
       "      <th>teacher</th>\n",
       "      <th>team</th>\n",
       "      <th>teams</th>\n",
       "      <th>teen</th>\n",
       "      <th>teenage</th>\n",
       "      <th>teenager</th>\n",
       "      <th>tells</th>\n",
       "      <th>terrifying</th>\n",
       "      <th>test</th>\n",
       "      <th>texas</th>\n",
       "      <th>thing</th>\n",
       "      <th>things</th>\n",
       "      <th>thought</th>\n",
       "      <th>threatens</th>\n",
       "      <th>time</th>\n",
       "      <th>town</th>\n",
       "      <th>train</th>\n",
       "      <th>trapped</th>\n",
       "      <th>travel</th>\n",
       "      <th>travels</th>\n",
       "      <th>tries</th>\n",
       "      <th>trip</th>\n",
       "      <th>true</th>\n",
       "      <th>truth</th>\n",
       "      <th>try</th>\n",
       "      <th>trying</th>\n",
       "      <th>turn</th>\n",
       "      <th>turned</th>\n",
       "      <th>turns</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>ultimately</th>\n",
       "      <th>uncover</th>\n",
       "      <th>unexpected</th>\n",
       "      <th>united</th>\n",
       "      <th>unlikely</th>\n",
       "      <th>use</th>\n",
       "      <th>uses</th>\n",
       "      <th>using</th>\n",
       "      <th>vacation</th>\n",
       "      <th>vampire</th>\n",
       "      <th>veteran</th>\n",
       "      <th>village</th>\n",
       "      <th>violent</th>\n",
       "      <th>want</th>\n",
       "      <th>wants</th>\n",
       "      <th>war</th>\n",
       "      <th>way</th>\n",
       "      <th>ways</th>\n",
       "      <th>wealthy</th>\n",
       "      <th>wedding</th>\n",
       "      <th>white</th>\n",
       "      <th>wife</th>\n",
       "      <th>wild</th>\n",
       "      <th>win</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5fc86a4c6758f6963478d502</td>\n",
       "      <td>[Adventure, Action]</td>\n",
       "      <td>raiders-of-the-lost-ark</td>\n",
       "      <td>en</td>\n",
       "      <td>When Dr. Indiana Jones  the tweed-suited prof...</td>\n",
       "      <td>30.782</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>8.481832</td>\n",
       "      <td>3908</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>5fc883036758f69634eeca6d</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>a-serious-man</td>\n",
       "      <td>en</td>\n",
       "      <td>It is 1967, and Larry Gopnik, a physics profes...</td>\n",
       "      <td>9.814</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.867454</td>\n",
       "      <td>2286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.442188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>5fc86f6d6758f696348f8521</td>\n",
       "      <td>[Thriller, Drama]</td>\n",
       "      <td>pawn-sacrifice</td>\n",
       "      <td>en</td>\n",
       "      <td>American chess champion Bobby Fischer prepares...</td>\n",
       "      <td>7.860</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>5.924390</td>\n",
       "      <td>410</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>5fc87e6b6758f69634d20605</td>\n",
       "      <td>[Drama, Thriller, History]</td>\n",
       "      <td>spotlight</td>\n",
       "      <td>en</td>\n",
       "      <td>The true story of how the Boston Globe uncover...</td>\n",
       "      <td>15.982</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>7.771767</td>\n",
       "      <td>3457</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>5fc874a96758f69634a9c7f8</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>good-will-hunting</td>\n",
       "      <td>en</td>\n",
       "      <td>Will Hunting has a genius-level IQ but chooses...</td>\n",
       "      <td>30.169</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>8.016067</td>\n",
       "      <td>3361</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>5fc8702c6758f69634917c92</td>\n",
       "      <td>[Horror]</td>\n",
       "      <td>horror-express</td>\n",
       "      <td>en</td>\n",
       "      <td>Mysterious and unearthly deaths start to occur...</td>\n",
       "      <td>7.542</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>6.776256</td>\n",
       "      <td>438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>5fc870ea6758f6963494022c</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>animal-house</td>\n",
       "      <td>en</td>\n",
       "      <td>At a 1962 College, Dean Vernon Wormer is deter...</td>\n",
       "      <td>12.712</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>6.674107</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.491817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>5fc884076758f69634f300f8</td>\n",
       "      <td>[Animation, Comedy, Family, Fantasy]</td>\n",
       "      <td>monster-house</td>\n",
       "      <td>en</td>\n",
       "      <td>Monsters under the bed are scary enough, but w...</td>\n",
       "      <td>41.379</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>6.298050</td>\n",
       "      <td>1795</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>5fc875f76758f69634ae31ec</td>\n",
       "      <td>[Adventure, Drama]</td>\n",
       "      <td>into-the-wild</td>\n",
       "      <td>en</td>\n",
       "      <td>After graduating from Emory University in 1992...</td>\n",
       "      <td>22.180</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>7.104249</td>\n",
       "      <td>1765</td>\n",
       "      <td>0.5491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>5fc882696758f69634ebfdec</td>\n",
       "      <td>[Comedy, Family, Science Fiction]</td>\n",
       "      <td>flubber</td>\n",
       "      <td>en</td>\n",
       "      <td>Professor Phillip Brainard, an absent minded p...</td>\n",
       "      <td>16.166</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>4.188643</td>\n",
       "      <td>1039</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id                                genres  \\\n",
       "80    5fc86a4c6758f6963478d502                   [Adventure, Action]   \n",
       "4330  5fc883036758f69634eeca6d                       [Comedy, Drama]   \n",
       "696   5fc86f6d6758f696348f8521                     [Thriller, Drama]   \n",
       "3454  5fc87e6b6758f69634d20605            [Drama, Thriller, History]   \n",
       "1655  5fc874a96758f69634a9c7f8                               [Drama]   \n",
       "847   5fc8702c6758f69634917c92                              [Horror]   \n",
       "965   5fc870ea6758f6963494022c                              [Comedy]   \n",
       "4497  5fc884076758f69634f300f8  [Animation, Comedy, Family, Fantasy]   \n",
       "1921  5fc875f76758f69634ae31ec                    [Adventure, Drama]   \n",
       "4221  5fc882696758f69634ebfdec     [Comedy, Family, Science Fiction]   \n",
       "\n",
       "                     movie_id original_language  \\\n",
       "80    raiders-of-the-lost-ark                en   \n",
       "4330            a-serious-man                en   \n",
       "696            pawn-sacrifice                en   \n",
       "3454                spotlight                en   \n",
       "1655        good-will-hunting                en   \n",
       "847            horror-express                en   \n",
       "965              animal-house                en   \n",
       "4497            monster-house                en   \n",
       "1921            into-the-wild                en   \n",
       "4221                  flubber                en   \n",
       "\n",
       "                                               overview  popularity  runtime  \\\n",
       "80    When Dr. Indiana Jones  the tweed-suited prof...      30.782    115.0   \n",
       "4330  It is 1967, and Larry Gopnik, a physics profes...       9.814    106.0   \n",
       "696   American chess champion Bobby Fischer prepares...       7.860    115.0   \n",
       "3454  The true story of how the Boston Globe uncover...      15.982    129.0   \n",
       "1655  Will Hunting has a genius-level IQ but chooses...      30.169    127.0   \n",
       "847   Mysterious and unearthly deaths start to occur...       7.542     90.0   \n",
       "965   At a 1962 College, Dean Vernon Wormer is deter...      12.712    109.0   \n",
       "4497  Monsters under the bed are scary enough, but w...      41.379     91.0   \n",
       "1921  After graduating from Emory University in 1992...      22.180    148.0   \n",
       "4221  Professor Phillip Brainard, an absent minded p...      16.166     93.0   \n",
       "\n",
       "      year_released  avg_rating  rating_count     000  accident  accidentally  \\\n",
       "80           1981.0    8.481832          3908  0.0000       0.0           0.0   \n",
       "4330         2009.0    7.867454          2286  0.0000       0.0           0.0   \n",
       "696          2014.0    5.924390           410  0.0000       0.0           0.0   \n",
       "3454         2015.0    7.771767          3457  0.0000       0.0           0.0   \n",
       "1655         1997.0    8.016067          3361  0.0000       0.0           0.0   \n",
       "847          1972.0    6.776256           438  0.0000       0.0           0.0   \n",
       "965          1978.0    6.674107          1120  0.0000       0.0           0.0   \n",
       "4497         2006.0    6.298050          1795  0.0000       0.0           0.0   \n",
       "1921         2007.0    7.104249          1765  0.5491       0.0           0.0   \n",
       "4221         1997.0    4.188643          1039  0.0000       0.0           0.0   \n",
       "\n",
       "      act  action  adventure  agent  alex  alice  alien  america  american  \\\n",
       "80    0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000   \n",
       "4330  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000   \n",
       "696   0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.614072   \n",
       "3454  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000   \n",
       "1655  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000   \n",
       "847   0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000   \n",
       "965   0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000   \n",
       "4497  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000   \n",
       "1921  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000   \n",
       "4221  0.0     0.0        0.0    0.0   0.0    0.0    0.0      0.0  0.000000   \n",
       "\n",
       "      ancient  angeles  apart  army  arrives  art  artist  attack  attempt  \\\n",
       "80        0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "4330      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "696       0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "3454      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "1655      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "847       0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "965       0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "4497      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "1921      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "4221      0.0      0.0    0.0   0.0      0.0  0.0     0.0     0.0      0.0   \n",
       "\n",
       "      attempts  away  baby  bad  band  based  battle  beautiful  begin  \\\n",
       "80         0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "4330       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "696        0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "3454       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "1655       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "847        0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "965        0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "4497       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "1921       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "4221       0.0   0.0   0.0  0.0   0.0    0.0     0.0        0.0    0.0   \n",
       "\n",
       "      begins  best  big  black  body  bond  book  born  boss  boy  boyfriend  \\\n",
       "80       0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "4330     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "696      0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "3454     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "1655     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "847      0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "965      0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "4497     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "1921     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "4221     0.0   0.0  0.0    0.0   0.0   0.0   0.0   0.0   0.0  0.0        0.0   \n",
       "\n",
       "      break  bring  brings  british  brother  brothers  business  california  \\\n",
       "80      0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "4330    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "696     0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "3454    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "1655    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "847     0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "965     0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "4497    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "1921    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "4221    0.0    0.0     0.0      0.0      0.0       0.0       0.0         0.0   \n",
       "\n",
       "      called  camp  captain  car  career  case  caught  century  chance  \\\n",
       "80       0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "4330     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "696      0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "3454     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "1655     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "847      0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "965      0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "4497     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "1921     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "4221     0.0   0.0      0.0  0.0     0.0   0.0     0.0      0.0     0.0   \n",
       "\n",
       "      change  charlie     child  childhood  children  christmas  cia  city  \\\n",
       "80       0.0      0.0  0.000000        0.0       0.0        0.0  0.0   0.0   \n",
       "4330     0.0      0.0  0.000000        0.0       0.0        0.0  0.0   0.0   \n",
       "696      0.0      0.0  0.000000        0.0       0.0        0.0  0.0   0.0   \n",
       "3454     0.0      0.0  0.454849        0.0       0.0        0.0  0.0   0.0   \n",
       "1655     0.0      0.0  0.000000        0.0       0.0        0.0  0.0   0.0   \n",
       "847      0.0      0.0  0.000000        0.0       0.0        0.0  0.0   0.0   \n",
       "965      0.0      0.0  0.000000        0.0       0.0        0.0  0.0   0.0   \n",
       "4497     0.0      0.0  0.000000        0.0       0.0        0.0  0.0   0.0   \n",
       "1921     0.0      0.0  0.000000        0.0       0.0        0.0  0.0   0.0   \n",
       "4221     0.0      0.0  0.000000        0.0       0.0        0.0  0.0   0.0   \n",
       "\n",
       "      class  classic   college  come  comedy  comes  community  company  \\\n",
       "80      0.0      0.0  0.000000   0.0     0.0    0.0        0.0      0.0   \n",
       "4330    0.0      0.0  0.000000   0.0     0.0    0.0        0.0      0.0   \n",
       "696     0.0      0.0  0.000000   0.0     0.0    0.0        0.0      0.0   \n",
       "3454    0.0      0.0  0.000000   0.0     0.0    0.0        0.0      0.0   \n",
       "1655    0.0      0.0  0.000000   0.0     0.0    0.0        0.0      0.0   \n",
       "847     0.0      0.0  0.000000   0.0     0.0    0.0        0.0      0.0   \n",
       "965     0.0      0.0  0.466749   0.0     0.0    0.0        0.0      0.0   \n",
       "4497    0.0      0.0  0.000000   0.0     0.0    0.0        0.0      0.0   \n",
       "1921    0.0      0.0  0.000000   0.0     0.0    0.0        0.0      0.0   \n",
       "4221    0.0      0.0  0.202174   0.0     0.0    0.0        0.0      0.0   \n",
       "\n",
       "      confront  control  cop  country  couple  course  creatures  crew  crime  \\\n",
       "80         0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "4330       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "696        0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "3454       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "1655       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "847        0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "965        0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "4497       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "1921       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "4221       0.0      0.0  0.0      0.0     0.0     0.0        0.0   0.0    0.0   \n",
       "\n",
       "      criminal  cross  dangerous  dark  daughter  david  day  days  dead  \\\n",
       "80         0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "4330       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "696        0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "3454       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "1655       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "847        0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "965        0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "4497       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "1921       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "4221       0.0    0.0        0.0   0.0       0.0    0.0  0.0   0.0   0.0   \n",
       "\n",
       "      deadly      deal  death  decide   decides  deep  desperate  despite  \\\n",
       "80       0.0  0.000000    0.0     0.0  0.000000   0.0        0.0      0.0   \n",
       "4330     0.0  0.000000    0.0     0.0  0.000000   0.0        0.0      0.0   \n",
       "696      0.0  0.000000    0.0     0.0  0.000000   0.0        0.0      0.0   \n",
       "3454     0.0  0.000000    0.0     0.0  0.000000   0.0        0.0      0.0   \n",
       "1655     0.0  0.324973    0.0     0.0  0.275298   0.0        0.0      0.0   \n",
       "847      0.0  0.000000    0.0     0.0  0.000000   0.0        0.0      0.0   \n",
       "965      0.0  0.000000    0.0     0.0  0.000000   0.0        0.0      0.0   \n",
       "4497     0.0  0.000000    0.0     0.0  0.000000   0.0        0.0      0.0   \n",
       "1921     0.0  0.000000    0.0     0.0  0.000000   0.0        0.0      0.0   \n",
       "4221     0.0  0.000000    0.0     0.0  0.000000   0.0        0.0      0.0   \n",
       "\n",
       "      destroy  detective  determined  different  director  discover  \\\n",
       "80        0.0        0.0    0.000000        0.0       0.0       0.0   \n",
       "4330      0.0        0.0    0.000000        0.0       0.0       0.0   \n",
       "696       0.0        0.0    0.000000        0.0       0.0       0.0   \n",
       "3454      0.0        0.0    0.000000        0.0       0.0       0.0   \n",
       "1655      0.0        0.0    0.000000        0.0       0.0       0.0   \n",
       "847       0.0        0.0    0.000000        0.0       0.0       0.0   \n",
       "965       0.0        0.0    0.491817        0.0       0.0       0.0   \n",
       "4497      0.0        0.0    0.000000        0.0       0.0       0.0   \n",
       "1921      0.0        0.0    0.000000        0.0       0.0       0.0   \n",
       "4221      0.0        0.0    0.000000        0.0       0.0       0.0   \n",
       "\n",
       "      discovers  doctor  documentary  does  doesn  dog  don        dr  dream  \\\n",
       "80          0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.370703    0.0   \n",
       "4330        0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
       "696         0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
       "3454        0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
       "1655        0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
       "847         0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
       "965         0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
       "4497        0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
       "1921        0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
       "4221        0.0     0.0          0.0   0.0    0.0  0.0  0.0  0.000000    0.0   \n",
       "\n",
       "      dreams  driver  drug  earth  eccentric  embark  embarks  encounter  end  \\\n",
       "80       0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "4330     0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "696      0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "3454     0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "1655     0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "847      0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "965      0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "4497     0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "1921     0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "4221     0.0     0.0   0.0    0.0        0.0     0.0      0.0        0.0  0.0   \n",
       "\n",
       "      ends  enemy  england  english    entire  epic  escape  estranged  eve  \\\n",
       "80     0.0    0.0      0.0      0.0  0.421564   0.0     0.0        0.0  0.0   \n",
       "4330   0.0    0.0      0.0      0.0  0.000000   0.0     0.0        0.0  0.0   \n",
       "696    0.0    0.0      0.0      0.0  0.000000   0.0     0.0        0.0  0.0   \n",
       "3454   0.0    0.0      0.0      0.0  0.526840   0.0     0.0        0.0  0.0   \n",
       "1655   0.0    0.0      0.0      0.0  0.000000   0.0     0.0        0.0  0.0   \n",
       "847    0.0    0.0      0.0      0.0  0.000000   0.0     0.0        0.0  0.0   \n",
       "965    0.0    0.0      0.0      0.0  0.540624   0.0     0.0        0.0  0.0   \n",
       "4497   0.0    0.0      0.0      0.0  0.568964   0.0     0.0        0.0  0.0   \n",
       "1921   0.0    0.0      0.0      0.0  0.527328   0.0     0.0        0.0  0.0   \n",
       "4221   0.0    0.0      0.0      0.0  0.000000   0.0     0.0        0.0  0.0   \n",
       "\n",
       "      events  eventually  evil   ex  existence  experience  eye  face  faces  \\\n",
       "80       0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "4330     0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "696      0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "3454     0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "1655     0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "847      0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "965      0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "4497     0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "1921     0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "4221     0.0         0.0   0.0  0.0        0.0         0.0  0.0   0.0    0.0   \n",
       "\n",
       "      fall  falls  family  famous  far  fate  father  fbi  fear  fellow  \\\n",
       "80     0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "4330   0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "696    0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "3454   0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "1655   0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "847    0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "965    0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "4497   0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "1921   0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "4221   0.0    0.0     0.0     0.0  0.0   0.0     0.0  0.0   0.0     0.0   \n",
       "\n",
       "      fight  fighting  film  final  finally     finds  following  follows  \\\n",
       "80      0.0       0.0   0.0    0.0      0.0  0.280222        0.0      0.0   \n",
       "4330    0.0       0.0   0.0    0.0      0.0  0.000000        0.0      0.0   \n",
       "696     0.0       0.0   0.0    0.0      0.0  0.000000        0.0      0.0   \n",
       "3454    0.0       0.0   0.0    0.0      0.0  0.000000        0.0      0.0   \n",
       "1655    0.0       0.0   0.0    0.0      0.0  0.000000        0.0      0.0   \n",
       "847     0.0       0.0   0.0    0.0      0.0  0.000000        0.0      0.0   \n",
       "965     0.0       0.0   0.0    0.0      0.0  0.000000        0.0      0.0   \n",
       "4497    0.0       0.0   0.0    0.0      0.0  0.000000        0.0      0.0   \n",
       "1921    0.0       0.0   0.0    0.0      0.0  0.000000        0.0      0.0   \n",
       "4221    0.0       0.0   0.0    0.0      0.0  0.000000        0.0      0.0   \n",
       "\n",
       "      force  forced  forces  forever  form  frank  free  friend  friends  \\\n",
       "80      0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "4330    0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "696     0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "3454    0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "1655    0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "847     0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "965     0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "4497    0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "1921    0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "4221    0.0     0.0     0.0      0.0   0.0    0.0   0.0     0.0      0.0   \n",
       "\n",
       "      friendship  future  game  gang  george  gets  getting  girl  girlfriend  \\\n",
       "80           0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "4330         0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "696          0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "3454         0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "1655         0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "847          0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "965          0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "4497         0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "1921         0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "4221         0.0     0.0   0.0   0.0     0.0   0.0      0.0   0.0         0.0   \n",
       "\n",
       "      girls  global  goes  going  good  government  great  group  guy  hands  \\\n",
       "80      0.0     0.0   0.0    0.0   0.0    0.378118    0.0    0.0  0.0    0.0   \n",
       "4330    0.0     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   \n",
       "696     0.0     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   \n",
       "3454    0.0     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   \n",
       "1655    0.0     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   \n",
       "847     0.0     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   \n",
       "965     0.0     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   \n",
       "4497    0.0     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   \n",
       "1921    0.0     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   \n",
       "4221    0.0     0.0   0.0    0.0   0.0    0.000000    0.0    0.0  0.0    0.0   \n",
       "\n",
       "      hard  harry  having  head  heart  heist  hell      help  henry  hero  \\\n",
       "80     0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.000000    0.0   0.0   \n",
       "4330   0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.000000    0.0   0.0   \n",
       "696    0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.000000    0.0   0.0   \n",
       "3454   0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.000000    0.0   0.0   \n",
       "1655   0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.224298    0.0   0.0   \n",
       "847    0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.000000    0.0   0.0   \n",
       "965    0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.000000    0.0   0.0   \n",
       "4497   0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.000000    0.0   0.0   \n",
       "1921   0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.000000    0.0   0.0   \n",
       "4221   0.0    0.0     0.0   0.0    0.0    0.0   0.0  0.000000    0.0   0.0   \n",
       "\n",
       "      high  history  hit  holiday  hollywood      home  hope  horror  \\\n",
       "80     0.0      0.0  0.0      0.0        0.0  0.000000   0.0     0.0   \n",
       "4330   0.0      0.0  0.0      0.0        0.0  0.000000   0.0     0.0   \n",
       "696    0.0      0.0  0.0      0.0        0.0  0.000000   0.0     0.0   \n",
       "3454   0.0      0.0  0.0      0.0        0.0  0.000000   0.0     0.0   \n",
       "1655   0.0      0.0  0.0      0.0        0.0  0.000000   0.0     0.0   \n",
       "847    0.0      0.0  0.0      0.0        0.0  0.000000   0.0     0.0   \n",
       "965    0.0      0.0  0.0      0.0        0.0  0.000000   0.0     0.0   \n",
       "4497   0.0      0.0  0.0      0.0        0.0  0.387065   0.0     0.0   \n",
       "1921   0.0      0.0  0.0      0.0        0.0  0.000000   0.0     0.0   \n",
       "4221   0.0      0.0  0.0      0.0        0.0  0.000000   0.0     0.0   \n",
       "\n",
       "      hospital  hotel     house  human  humanity  humans  hunt  husband  \\\n",
       "80         0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "4330       0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "696        0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "3454       0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "1655       0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "847        0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "965        0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "4497       0.0    0.0  0.444806    0.0       0.0     0.0   0.0      0.0   \n",
       "1921       0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "4221       0.0    0.0  0.000000    0.0       0.0     0.0   0.0      0.0   \n",
       "\n",
       "      identity   ii  including  increasingly  inside  international  \\\n",
       "80         0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "4330       0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "696        0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "3454       0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "1655       0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "847        0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "965        0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "4497       0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "1921       0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "4221       0.0  0.0        0.0           0.0     0.0            0.0   \n",
       "\n",
       "      investigate  involved  island  jack  james  job  john  johnny  join  \\\n",
       "80            0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "4330          0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "696           0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "3454          0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "1655          0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "847           0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "965           0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "4497          0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "1921          0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "4221          0.0       0.0     0.0   0.0    0.0  0.0   0.0     0.0   0.0   \n",
       "\n",
       "      joins  journey      just  kidnapped  kids  kill  killed  killer  \\\n",
       "80      0.0      0.0  0.327787        0.0   0.0   0.0     0.0     0.0   \n",
       "4330    0.0      0.0  0.482463        0.0   0.0   0.0     0.0     0.0   \n",
       "696     0.0      0.0  0.000000        0.0   0.0   0.0     0.0     0.0   \n",
       "3454    0.0      0.0  0.000000        0.0   0.0   0.0     0.0     0.0   \n",
       "1655    0.0      0.0  0.000000        0.0   0.0   0.0     0.0     0.0   \n",
       "847     0.0      0.0  0.000000        0.0   0.0   0.0     0.0     0.0   \n",
       "965     0.0      0.0  0.000000        0.0   0.0   0.0     0.0     0.0   \n",
       "4497    0.0      0.0  0.000000        0.0   0.0   0.0     0.0     0.0   \n",
       "1921    0.0      0.0  0.000000        0.0   0.0   0.0     0.0     0.0   \n",
       "4221    0.0      0.0  0.000000        0.0   0.0   0.0     0.0     0.0   \n",
       "\n",
       "      killing  king  know  known  land  late  later  law  lawyer  lead  \\\n",
       "80        0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "4330      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "696       0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "3454      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "1655      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "847       0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "965       0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "4497      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "1921      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "4221      0.0   0.0   0.0    0.0   0.0   0.0    0.0  0.0     0.0   0.0   \n",
       "\n",
       "      leader  leading  leads  learn  learns  leave  leaves  led  left  \\\n",
       "80       0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "4330     0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "696      0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "3454     0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "1655     0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "847      0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "965      0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "4497     0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "1921     0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "4221     0.0      0.0    0.0    0.0     0.0    0.0     0.0  0.0   0.0   \n",
       "\n",
       "      legendary  life  like  little      live  lives  living     local  \\\n",
       "80      0.41008   0.0   0.0     0.0  0.000000    0.0     0.0  0.000000   \n",
       "4330    0.00000   0.0   0.0     0.0  0.000000    0.0     0.0  0.000000   \n",
       "696     0.78925   0.0   0.0     0.0  0.000000    0.0     0.0  0.000000   \n",
       "3454    0.00000   0.0   0.0     0.0  0.000000    0.0     0.0  0.464262   \n",
       "1655    0.00000   0.0   0.0     0.0  0.000000    0.0     0.0  0.000000   \n",
       "847     0.00000   0.0   0.0     0.0  0.000000    0.0     0.0  0.000000   \n",
       "965     0.00000   0.0   0.0     0.0  0.000000    0.0     0.0  0.000000   \n",
       "4497    0.00000   0.0   0.0     0.0  0.000000    0.0     0.0  0.000000   \n",
       "1921    0.00000   0.0   0.0     0.0  0.441161    0.0     0.0  0.000000   \n",
       "4221    0.00000   0.0   0.0     0.0  0.000000    0.0     0.0  0.000000   \n",
       "\n",
       "      london  long  look  looking  lord  los  lost      love  magical  make  \\\n",
       "80       0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.000000      0.0   0.0   \n",
       "4330     0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.406128      0.0   0.0   \n",
       "696      0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.000000      0.0   0.0   \n",
       "3454     0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.000000      0.0   0.0   \n",
       "1655     0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.000000      0.0   0.0   \n",
       "847      0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.000000      0.0   0.0   \n",
       "965      0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.000000      0.0   0.0   \n",
       "4497     0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.000000      0.0   0.0   \n",
       "1921     0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.000000      0.0   0.0   \n",
       "4221     0.0   0.0   0.0      0.0   0.0  0.0   0.0  0.000000      0.0   0.0   \n",
       "\n",
       "         makes  making  man  marriage  married  master  max  means  meet  \\\n",
       "80    0.000000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "4330  0.000000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "696   0.000000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "3454  0.000000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "1655  0.286206     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "847   0.000000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "965   0.000000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "4497  0.000000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "1921  0.000000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "4221  0.000000     0.0  0.0       0.0      0.0     0.0  0.0    0.0   0.0   \n",
       "\n",
       "      meets  members  men  michael  middle  mike  military  mind  missing  \\\n",
       "80      0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "4330    0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "696     0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "3454    0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "1655    0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "847     0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "965     0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "4497    0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "1921    0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "4221    0.0      0.0  0.0      0.0     0.0   0.0       0.0   0.0      0.0   \n",
       "\n",
       "      mission  money  monster  mother  moves  movie   mr  murder  murdered  \\\n",
       "80        0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "4330      0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "696       0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "3454      0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "1655      0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "847       0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "965       0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "4497      0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "1921      0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "4221      0.0    0.0      0.0     0.0    0.0    0.0  0.0     0.0       0.0   \n",
       "\n",
       "      music  mysterious  mystery  named       new  night  notorious  obsessed  \\\n",
       "80      0.0    0.000000      0.0    0.0  0.000000    0.0        0.0       0.0   \n",
       "4330    0.0    0.000000      0.0    0.0  0.000000    0.0        0.0       0.0   \n",
       "696     0.0    0.000000      0.0    0.0  0.000000    0.0        0.0       0.0   \n",
       "3454    0.0    0.000000      0.0    0.0  0.000000    0.0        0.0       0.0   \n",
       "1655    0.0    0.000000      0.0    0.0  0.000000    0.0        0.0       0.0   \n",
       "847     0.0    0.456333      0.0    0.0  0.000000    0.0        0.0       0.0   \n",
       "965     0.0    0.000000      0.0    0.0  0.000000    0.0        0.0       0.0   \n",
       "4497    0.0    0.000000      0.0    0.0  0.000000    0.0        0.0       0.0   \n",
       "1921    0.0    0.000000      0.0    0.0  0.000000    0.0        0.0       0.0   \n",
       "4221    0.0    0.000000      0.0    0.0  0.124525    0.0        0.0       0.0   \n",
       "\n",
       "       officer  old  older  order  owner  pair  parents  paris  park  partner  \\\n",
       "80    0.000000  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "4330  0.000000  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "696   0.000000  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "3454  0.000000  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "1655  0.314267  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "847   0.000000  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "965   0.000000  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "4497  0.000000  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "1921  0.000000  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "4221  0.000000  0.0    0.0    0.0    0.0   0.0      0.0    0.0   0.0      0.0   \n",
       "\n",
       "      party  past  path  paul  people  perfect  person  personal  peter  \\\n",
       "80      0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "4330    0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "696     0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "3454    0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "1655    0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "847     0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "965     0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "4497    0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "1921    0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "4221    0.0   0.0   0.0   0.0     0.0      0.0     0.0       0.0    0.0   \n",
       "\n",
       "      place  plan  planet     plans  play  plot    police  popular  power  \\\n",
       "80      0.0   0.0     0.0  0.000000   0.0   0.0  0.000000      0.0    0.0   \n",
       "4330    0.0   0.0     0.0  0.000000   0.0   0.0  0.000000      0.0    0.0   \n",
       "696     0.0   0.0     0.0  0.000000   0.0   0.0  0.000000      0.0    0.0   \n",
       "3454    0.0   0.0     0.0  0.000000   0.0   0.0  0.000000      0.0    0.0   \n",
       "1655    0.0   0.0     0.0  0.000000   0.0   0.0  0.265707      0.0    0.0   \n",
       "847     0.0   0.0     0.0  0.000000   0.0   0.0  0.000000      0.0    0.0   \n",
       "965     0.0   0.0     0.0  0.497983   0.0   0.0  0.000000      0.0    0.0   \n",
       "4497    0.0   0.0     0.0  0.000000   0.0   0.0  0.000000      0.0    0.0   \n",
       "1921    0.0   0.0     0.0  0.000000   0.0   0.0  0.000000      0.0    0.0   \n",
       "4221    0.0   0.0     0.0  0.000000   0.0   0.0  0.000000      0.0    0.0   \n",
       "\n",
       "      powerful  powers  president  prince  princess  prison  private  \\\n",
       "80         0.0     0.0   0.000000     0.0       0.0     0.0      0.0   \n",
       "4330       0.0     0.0   0.000000     0.0       0.0     0.0      0.0   \n",
       "696        0.0     0.0   0.000000     0.0       0.0     0.0      0.0   \n",
       "3454       0.0     0.0   0.000000     0.0       0.0     0.0      0.0   \n",
       "1655       0.0     0.0   0.000000     0.0       0.0     0.0      0.0   \n",
       "847        0.0     0.0   0.000000     0.0       0.0     0.0      0.0   \n",
       "965        0.0     0.0   0.000000     0.0       0.0     0.0      0.0   \n",
       "4497       0.0     0.0   0.000000     0.0       0.0     0.0      0.0   \n",
       "1921       0.0     0.0   0.000000     0.0       0.0     0.0      0.0   \n",
       "4221       0.0     0.0   0.236844     0.0       0.0     0.0      0.0   \n",
       "\n",
       "      professor  protect  prove  puts  queen  quest  quickly  race  real  \\\n",
       "80     0.433308      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "4330   0.637777      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "696    0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "3454   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "1655   0.670495      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "847    0.664145      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "965    0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "4497   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "1921   0.000000      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "4221   0.722091      0.0    0.0   0.0    0.0    0.0      0.0   0.0   0.0   \n",
       "\n",
       "      reality  realizes  really  relationship  remote  rescue  rest  return  \\\n",
       "80        0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "4330      0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "696       0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "3454      0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "1655      0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "847       0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "965       0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "4497      0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "1921      0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "4221      0.0       0.0     0.0           0.0     0.0     0.0   0.0     0.0   \n",
       "\n",
       "      returns  revenge  rich  right  road  rock  romance  romantic  run  runs  \\\n",
       "80        0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "4330      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "696       0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "3454      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "1655      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "847       0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "965       0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "4497      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "1921      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "4221      0.0      0.0   0.0    0.0   0.0   0.0      0.0       0.0  0.0   0.0   \n",
       "\n",
       "      ruthless  sam  san      save  school  scientist  search  secret  \\\n",
       "80         0.0  0.0  0.0  0.000000     0.0        0.0     0.0     0.0   \n",
       "4330       0.0  0.0  0.0  0.000000     0.0        0.0     0.0     0.0   \n",
       "696        0.0  0.0  0.0  0.000000     0.0        0.0     0.0     0.0   \n",
       "3454       0.0  0.0  0.0  0.000000     0.0        0.0     0.0     0.0   \n",
       "1655       0.0  0.0  0.0  0.000000     0.0        0.0     0.0     0.0   \n",
       "847        0.0  0.0  0.0  0.000000     0.0        0.0     0.0     0.0   \n",
       "965        0.0  0.0  0.0  0.000000     0.0        0.0     0.0     0.0   \n",
       "4497       0.0  0.0  0.0  0.000000     0.0        0.0     0.0     0.0   \n",
       "1921       0.0  0.0  0.0  0.000000     0.0        0.0     0.0     0.0   \n",
       "4221       0.0  0.0  0.0  0.177893     0.0        0.0     0.0     0.0   \n",
       "\n",
       "       secrets  security  seek  seeks  seemingly  self  sent  serial  series  \\\n",
       "80    0.000000       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "4330  0.000000       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "696   0.000000       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "3454  0.000000       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "1655  0.000000       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "847   0.000000       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "965   0.000000       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "4497  0.573243       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "1921  0.000000       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "4221  0.000000       0.0   0.0    0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "\n",
       "      set  sets  sex  ship  short  singer  single  sinister  sister  small  \\\n",
       "80    0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "4330  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "696   0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "3454  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "1655  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "847   0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "965   0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "4497  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "1921  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "4221  0.0   0.0  0.0   0.0    0.0     0.0     0.0       0.0     0.0    0.0   \n",
       "\n",
       "      social  society  son  soon  south  space  special  spirit  star  \\\n",
       "80       0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "4330     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "696      0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "3454     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "1655     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "847      0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "965      0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "4497     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "1921     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "4221     0.0      0.0  0.0   0.0    0.0    0.0      0.0     0.0   0.0   \n",
       "\n",
       "         start  starts  state  states  stay  stop     story  strange  street  \\\n",
       "80    0.000000     0.0    0.0     0.0   0.0   0.0  0.000000      0.0     0.0   \n",
       "4330  0.000000     0.0    0.0     0.0   0.0   0.0  0.000000      0.0     0.0   \n",
       "696   0.000000     0.0    0.0     0.0   0.0   0.0  0.000000      0.0     0.0   \n",
       "3454  0.000000     0.0    0.0     0.0   0.0   0.0  0.357775      0.0     0.0   \n",
       "1655  0.000000     0.0    0.0     0.0   0.0   0.0  0.000000      0.0     0.0   \n",
       "847   0.592176     0.0    0.0     0.0   0.0   0.0  0.000000      0.0     0.0   \n",
       "965   0.000000     0.0    0.0     0.0   0.0   0.0  0.000000      0.0     0.0   \n",
       "4497  0.000000     0.0    0.0     0.0   0.0   0.0  0.000000      0.0     0.0   \n",
       "1921  0.000000     0.0    0.0     0.0   0.0   0.0  0.000000      0.0     0.0   \n",
       "4221  0.000000     0.0    0.0     0.0   0.0   0.0  0.000000      0.0     0.0   \n",
       "\n",
       "      struggle  struggles  struggling   student  students  suburban  \\\n",
       "80         0.0        0.0         0.0  0.000000       0.0       0.0   \n",
       "4330       0.0        0.0         0.0  0.000000       0.0       0.0   \n",
       "696        0.0        0.0         0.0  0.000000       0.0       0.0   \n",
       "3454       0.0        0.0         0.0  0.000000       0.0       0.0   \n",
       "1655       0.0        0.0         0.0  0.000000       0.0       0.0   \n",
       "847        0.0        0.0         0.0  0.000000       0.0       0.0   \n",
       "965        0.0        0.0         0.0  0.000000       0.0       0.0   \n",
       "4497       0.0        0.0         0.0  0.000000       0.0       0.0   \n",
       "1921       0.0        0.0         0.0  0.475175       0.0       0.0   \n",
       "4221       0.0        0.0         0.0  0.000000       0.0       0.0   \n",
       "\n",
       "      successful  suddenly  summer  supernatural  survival  survive  taken  \\\n",
       "80           0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "4330         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "696          0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "3454         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "1655         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "847          0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "965          0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "4497         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "1921         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "4221         0.0       0.0     0.0           0.0       0.0      0.0    0.0   \n",
       "\n",
       "      takes  taking  tale  target  teacher  team  teams  teen  teenage  \\\n",
       "80      0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "4330    0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "696     0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "3454    0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "1655    0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "847     0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "965     0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "4497    0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "1921    0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "4221    0.0     0.0   0.0     0.0      0.0   0.0    0.0   0.0      0.0   \n",
       "\n",
       "      teenager  tells  terrifying  test  texas  thing  things  thought  \\\n",
       "80         0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "4330       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "696        0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "3454       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "1655       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "847        0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "965        0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "4497       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "1921       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "4221       0.0    0.0         0.0   0.0    0.0    0.0     0.0      0.0   \n",
       "\n",
       "      threatens  time  town  train  trapped  travel  travels  tries  trip  \\\n",
       "80          0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "4330        0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "696         0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "3454        0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "1655        0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "847         0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "965         0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "4497        0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "1921        0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "4221        0.0   0.0   0.0    0.0      0.0     0.0      0.0    0.0   0.0   \n",
       "\n",
       "         true  truth  try    trying  turn  turned  turns  ultimate  \\\n",
       "80    0.00000    0.0  0.0  0.000000   0.0     0.0    0.0       0.0   \n",
       "4330  0.00000    0.0  0.0  0.000000   0.0     0.0    0.0       0.0   \n",
       "696   0.00000    0.0  0.0  0.000000   0.0     0.0    0.0       0.0   \n",
       "3454  0.41474    0.0  0.0  0.000000   0.0     0.0    0.0       0.0   \n",
       "1655  0.00000    0.0  0.0  0.000000   0.0     0.0    0.0       0.0   \n",
       "847   0.00000    0.0  0.0  0.000000   0.0     0.0    0.0       0.0   \n",
       "965   0.00000    0.0  0.0  0.000000   0.0     0.0    0.0       0.0   \n",
       "4497  0.00000    0.0  0.0  0.000000   0.0     0.0    0.0       0.0   \n",
       "1921  0.00000    0.0  0.0  0.000000   0.0     0.0    0.0       0.0   \n",
       "4221  0.00000    0.0  0.0  0.208158   0.0     0.0    0.0       0.0   \n",
       "\n",
       "      ultimately  uncover  unexpected  united  unlikely  use  uses  using  \\\n",
       "80           0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "4330         0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "696          0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "3454         0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "1655         0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "847          0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "965          0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "4497         0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "1921         0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "4221         0.0      0.0         0.0     0.0       0.0  0.0   0.0    0.0   \n",
       "\n",
       "      vacation  vampire  veteran  village  violent  want  wants  war  way  \\\n",
       "80         0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "4330       0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "696        0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "3454       0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "1655       0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "847        0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "965        0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "4497       0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "1921       0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "4221       0.0      0.0      0.0      0.0      0.0   0.0    0.0  0.0  0.0   \n",
       "\n",
       "      ways  wealthy   wedding  white      wife  wild  win  woman  women  \\\n",
       "80     0.0      0.0  0.000000    0.0  0.000000   0.0  0.0    0.0    0.0   \n",
       "4330   0.0      0.0  0.000000    0.0  0.442188   0.0  0.0    0.0    0.0   \n",
       "696    0.0      0.0  0.000000    0.0  0.000000   0.0  0.0    0.0    0.0   \n",
       "3454   0.0      0.0  0.000000    0.0  0.000000   0.0  0.0    0.0    0.0   \n",
       "1655   0.0      0.0  0.000000    0.0  0.000000   0.0  0.0    0.0    0.0   \n",
       "847    0.0      0.0  0.000000    0.0  0.000000   0.0  0.0    0.0    0.0   \n",
       "965    0.0      0.0  0.000000    0.0  0.000000   0.0  0.0    0.0    0.0   \n",
       "4497   0.0      0.0  0.000000    0.0  0.000000   0.0  0.0    0.0    0.0   \n",
       "1921   0.0      0.0  0.000000    0.0  0.000000   0.0  0.0    0.0    0.0   \n",
       "4221   0.0      0.0  0.487684    0.0  0.000000   0.0  0.0    0.0    0.0   \n",
       "\n",
       "          work  working     works  world  writer  wrong  year  years  york  \\\n",
       "80    0.000000      0.0  0.000000    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "4330  0.000000      0.0  0.000000    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "696   0.000000      0.0  0.000000    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "3454  0.000000      0.0  0.000000    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "1655  0.259718      0.0  0.000000    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "847   0.000000      0.0  0.000000    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "965   0.000000      0.0  0.000000    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "4497  0.000000      0.0  0.000000    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "1921  0.000000      0.0  0.000000    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "4221  0.000000      0.0  0.230861    0.0     0.0    0.0   0.0    0.0   0.0   \n",
       "\n",
       "      young  younger  \n",
       "80      0.0      0.0  \n",
       "4330    0.0      0.0  \n",
       "696     0.0      0.0  \n",
       "3454    0.0      0.0  \n",
       "1655    0.0      0.0  \n",
       "847     0.0      0.0  \n",
       "965     0.0      0.0  \n",
       "4497    0.0      0.0  \n",
       "1921    0.0      0.0  \n",
       "4221    0.0      0.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.iloc[indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bae1bc-9129-4499-9067-260100062b0d",
   "metadata": {},
   "source": [
    "Hmm... this doesn't seem to be doing great in terms of finding similar movies. I am not familiar with all of them, but we only see one other adventure movies. I am sure there are some similarities within the movie overview, but not great.\n",
    "\n",
    "Lets define a function and check out how we are doing with other movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "338da472-04c5-4862-b2e3-65af217e17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_movies(movie_df, X_scaled, nn_model, movie_name):\n",
    "    \"\"\"\n",
    "    Finds movies similar to a given movie using nearest neighbors.\n",
    "\n",
    "    Parameters:\n",
    "    - movie_df (pandas.DataFrame): DataFrame containing movie details.\n",
    "    - X_scaled (numpy.ndarray): Scaled features of the movies.\n",
    "    - nn_model: Nearest neighbors model trained on the movie features.\n",
    "    - movie_name (str): Name of the movie to find similar movies for.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing details of similar movies.\n",
    "    Columns: 'movie_id', 'genres', 'overview', 'avg_rating', 'rating_count', 'cosine_distance'.\n",
    "    'cosine_distance' represents the cosine distance to the original movie (rounded to 5 decimal places).\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the index of the movie\n",
    "    movie_index = movie_df[movie_df['movie_id'] == movie_name].index[0]\n",
    "    \n",
    "    # Get the features of the movie\n",
    "    input_movie_features = X_scaled[[movie_index]]\n",
    "    \n",
    "    # Find the nearest neighbors with the provided model\n",
    "    distances, indices = nn_model.kneighbors(input_movie_features, n_neighbors=10)\n",
    "    \n",
    "    # Return the movies that are most similar\n",
    "    sim_movies = movie_df.iloc[indices[0]]\n",
    "    \n",
    "    # Create a DataFrame containing selected columns\n",
    "    similar_movies = sim_movies[['movie_id', 'genres', 'overview', 'avg_rating', 'rating_count']]\n",
    "    \n",
    "    # Add a new column with cosine distance to the original movie (and round to 5 decimal places)\n",
    "    similar_movies['cosine_distance'] = np.round(distances[0], 5)\n",
    "    \n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539c11c-7131-4e09-a717-aa91db409edf",
   "metadata": {},
   "source": [
    "Lets look at a very famous movie, Toy Story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32abb80b-765d-4919-987c-2c8dd30c7077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_17952/3764737102.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>toy-story</td>\n",
       "      <td>[Animation, Adventure, Family, Comedy]</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>8.378398</td>\n",
       "      <td>4046</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>underdog</td>\n",
       "      <td>[Family, Action, Adventure, Comedy, Fantasy]</td>\n",
       "      <td>A lab accident gives a hound named Shoeshine s...</td>\n",
       "      <td>3.214133</td>\n",
       "      <td>467</td>\n",
       "      <td>0.66427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>steel-magnolias</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>This heart wrenching drama is about a beauty s...</td>\n",
       "      <td>6.833667</td>\n",
       "      <td>499</td>\n",
       "      <td>0.66787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>guess-whos-coming-to-dinner</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>A couple's attitudes are challenged when their...</td>\n",
       "      <td>7.299101</td>\n",
       "      <td>779</td>\n",
       "      <td>0.70246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>in-the-heights</td>\n",
       "      <td>[Drama, Music, Romance]</td>\n",
       "      <td>The story of Usnavi, a bodega owner who has mi...</td>\n",
       "      <td>6.845094</td>\n",
       "      <td>1814</td>\n",
       "      <td>0.70726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>the-brady-bunch-movie</td>\n",
       "      <td>[Family, Comedy]</td>\n",
       "      <td>The original '70s TV family is now placed in t...</td>\n",
       "      <td>6.277405</td>\n",
       "      <td>447</td>\n",
       "      <td>0.70857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>toy-story-2</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>Andy heads off to Cowboy Camp, leaving his toy...</td>\n",
       "      <td>8.157448</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.71692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>a-bugs-life</td>\n",
       "      <td>[Adventure, Animation, Comedy, Family]</td>\n",
       "      <td>On behalf of \"oppressed bugs everywhere,\" an i...</td>\n",
       "      <td>6.588957</td>\n",
       "      <td>2608</td>\n",
       "      <td>0.72123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>the-many-adventures-of-winnie-the-pooh</td>\n",
       "      <td>[Animation, Family]</td>\n",
       "      <td>Whether were young or forever young at heart,...</td>\n",
       "      <td>7.524404</td>\n",
       "      <td>881</td>\n",
       "      <td>0.72277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>dirty-work-1998</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>Unemployed and recently dumped, Mitch and his ...</td>\n",
       "      <td>6.307071</td>\n",
       "      <td>495</td>\n",
       "      <td>0.72474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    movie_id  \\\n",
       "1524                               toy-story   \n",
       "4423                                underdog   \n",
       "1239                         steel-magnolias   \n",
       "1729             guess-whos-coming-to-dinner   \n",
       "4956                          in-the-heights   \n",
       "1388                   the-brady-bunch-movie   \n",
       "484                              toy-story-2   \n",
       "32                               a-bugs-life   \n",
       "366   the-many-adventures-of-winnie-the-pooh   \n",
       "2473                         dirty-work-1998   \n",
       "\n",
       "                                            genres  \\\n",
       "1524        [Animation, Adventure, Family, Comedy]   \n",
       "4423  [Family, Action, Adventure, Comedy, Fantasy]   \n",
       "1239                      [Comedy, Drama, Romance]   \n",
       "1729                                       [Drama]   \n",
       "4956                       [Drama, Music, Romance]   \n",
       "1388                              [Family, Comedy]   \n",
       "484                    [Animation, Comedy, Family]   \n",
       "32          [Adventure, Animation, Comedy, Family]   \n",
       "366                            [Animation, Family]   \n",
       "2473                                      [Comedy]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "1524  Led by Woody, Andy's toys live happily in his ...    8.378398   \n",
       "4423  A lab accident gives a hound named Shoeshine s...    3.214133   \n",
       "1239  This heart wrenching drama is about a beauty s...    6.833667   \n",
       "1729  A couple's attitudes are challenged when their...    7.299101   \n",
       "4956  The story of Usnavi, a bodega owner who has mi...    6.845094   \n",
       "1388  The original '70s TV family is now placed in t...    6.277405   \n",
       "484   Andy heads off to Cowboy Camp, leaving his toy...    8.157448   \n",
       "32    On behalf of \"oppressed bugs everywhere,\" an i...    6.588957   \n",
       "366   Whether were young or forever young at heart,...    7.524404   \n",
       "2473  Unemployed and recently dumped, Mitch and his ...    6.307071   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "1524          4046          0.00000  \n",
       "4423           467          0.66427  \n",
       "1239           499          0.66787  \n",
       "1729           779          0.70246  \n",
       "4956          1814          0.70726  \n",
       "1388           447          0.70857  \n",
       "484           3652          0.71692  \n",
       "32            2608          0.72123  \n",
       "366            881          0.72277  \n",
       "2473           495          0.72474  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_movies(movie_df, X_scaled, nn_cos, 'toy-story')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27bb0a-e375-4db5-9ad0-65d9edab947c",
   "metadata": {},
   "source": [
    "Intersting! This one is actually performing quite a bit better.\n",
    "\n",
    "I know qualititatively that Toy Story 2, Bugs Life, and The Many adventures of Winnie the Pooh are quite strong reccomendations. Some of the other movies look similar too. \n",
    "\n",
    "With TF_IDF we are putting a higher value on words in the overview that are not very common, therefor movies with more destinct descriptors will probably perform better with our current model. Since Toy Story like has some interesting descriptors such as the word \"toy\" the model is picking up and showing us Toy Story two which likely containst the same. \n",
    "\n",
    "Lets checkout another famous movie in a different genre, Goodfellas, the classic maffia movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d474f57-d26c-4f69-af4a-498b5591e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_17952/3764737102.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>goodfellas</td>\n",
       "      <td>[Drama, Crime]</td>\n",
       "      <td>The true story of Henry Hill, a half-Irish, ha...</td>\n",
       "      <td>8.858363</td>\n",
       "      <td>4215</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>chimes-at-midnight</td>\n",
       "      <td>[Comedy, Drama, History]</td>\n",
       "      <td>The culmination of Orson Welless lifelong obs...</td>\n",
       "      <td>7.916382</td>\n",
       "      <td>586</td>\n",
       "      <td>0.34277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>stay</td>\n",
       "      <td>[Mystery, Thriller, Drama]</td>\n",
       "      <td>Psychiatrist Sam Foster has a new patient, Hen...</td>\n",
       "      <td>5.843091</td>\n",
       "      <td>427</td>\n",
       "      <td>0.35299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>henry-portrait-of-a-serial-killer</td>\n",
       "      <td>[Crime, Drama, Horror, Thriller]</td>\n",
       "      <td>Henry likes to kill people, in different ways ...</td>\n",
       "      <td>7.320626</td>\n",
       "      <td>1023</td>\n",
       "      <td>0.35922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>hardcore-henry</td>\n",
       "      <td>[Action, Adventure, Science Fiction]</td>\n",
       "      <td>Henry, a newly resurrected cyborg who must sav...</td>\n",
       "      <td>5.758114</td>\n",
       "      <td>1294</td>\n",
       "      <td>0.38148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>the-time-travelers-wife</td>\n",
       "      <td>[Drama, Romance, Fantasy]</td>\n",
       "      <td>Due to a genetic disorder, handsome librarian ...</td>\n",
       "      <td>5.529540</td>\n",
       "      <td>457</td>\n",
       "      <td>0.38448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>detachment</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>A chronicle of three weeks in the lives of sev...</td>\n",
       "      <td>7.014519</td>\n",
       "      <td>551</td>\n",
       "      <td>0.43719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>a-man-for-all-seasons</td>\n",
       "      <td>[Drama, History]</td>\n",
       "      <td>A depiction of the conflict between King Henry...</td>\n",
       "      <td>7.217300</td>\n",
       "      <td>474</td>\n",
       "      <td>0.45174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>50-first-dates</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "      <td>Henry is a player skilled at seducing women. B...</td>\n",
       "      <td>5.680778</td>\n",
       "      <td>1748</td>\n",
       "      <td>0.47280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>the-book-of-henry</td>\n",
       "      <td>[Drama, Crime, Thriller]</td>\n",
       "      <td>Susan, a single mother of two, works as a wait...</td>\n",
       "      <td>3.356696</td>\n",
       "      <td>799</td>\n",
       "      <td>0.47441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movie_id                                genres  \\\n",
       "212                          goodfellas                        [Drama, Crime]   \n",
       "828                  chimes-at-midnight              [Comedy, Drama, History]   \n",
       "4505                               stay            [Mystery, Thriller, Drama]   \n",
       "4217  henry-portrait-of-a-serial-killer      [Crime, Drama, Horror, Thriller]   \n",
       "392                      hardcore-henry  [Action, Adventure, Science Fiction]   \n",
       "4410            the-time-travelers-wife             [Drama, Romance, Fantasy]   \n",
       "545                          detachment                               [Drama]   \n",
       "1325              a-man-for-all-seasons                      [Drama, History]   \n",
       "1293                     50-first-dates                     [Comedy, Romance]   \n",
       "660                   the-book-of-henry              [Drama, Crime, Thriller]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "212   The true story of Henry Hill, a half-Irish, ha...    8.858363   \n",
       "828   The culmination of Orson Welless lifelong obs...    7.916382   \n",
       "4505  Psychiatrist Sam Foster has a new patient, Hen...    5.843091   \n",
       "4217  Henry likes to kill people, in different ways ...    7.320626   \n",
       "392   Henry, a newly resurrected cyborg who must sav...    5.758114   \n",
       "4410  Due to a genetic disorder, handsome librarian ...    5.529540   \n",
       "545   A chronicle of three weeks in the lives of sev...    7.014519   \n",
       "1325  A depiction of the conflict between King Henry...    7.217300   \n",
       "1293  Henry is a player skilled at seducing women. B...    5.680778   \n",
       "660   Susan, a single mother of two, works as a wait...    3.356696   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "212           4215          0.00000  \n",
       "828            586          0.34277  \n",
       "4505           427          0.35299  \n",
       "4217          1023          0.35922  \n",
       "392           1294          0.38148  \n",
       "4410           457          0.38448  \n",
       "545            551          0.43719  \n",
       "1325           474          0.45174  \n",
       "1293          1748          0.47280  \n",
       "660            799          0.47441  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_movies(movie_df, X_scaled, nn_cos, 'goodfellas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa28f07b-51df-4732-8ce4-b00fe48d6126",
   "metadata": {},
   "source": [
    "We are getting a lot overviews with \"Henry\" involved, our TF-IDF vectorization could be putting too heavy a weight there as it doesnt understand context, simply puts higher value on less frequently occuring words. \n",
    "\n",
    "However, we are seeing a fair amount of Crime movies. This is a promising sign.\n",
    "\n",
    "Lets check another famous, but abstract movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5141e269-1f72-4caa-a504-588df3ad06a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_17952/3764737102.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>interstellar</td>\n",
       "      <td>[Adventure, Drama, Science Fiction]</td>\n",
       "      <td>The adventures of a group of explorers who mak...</td>\n",
       "      <td>7.918451</td>\n",
       "      <td>4905</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>space-cowboys</td>\n",
       "      <td>[Action, Adventure, Thriller]</td>\n",
       "      <td>Frank Corvin, Hawk Hawkins, Jerry O'Neill an...</td>\n",
       "      <td>5.760504</td>\n",
       "      <td>476</td>\n",
       "      <td>0.62011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>silence</td>\n",
       "      <td>[Drama, History]</td>\n",
       "      <td>Two Jesuit priests travel to seventeenth centu...</td>\n",
       "      <td>7.936971</td>\n",
       "      <td>2364</td>\n",
       "      <td>0.64369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>gattaca</td>\n",
       "      <td>[Thriller, Science Fiction, Mystery, Romance]</td>\n",
       "      <td>In a future society in the era of indefinite e...</td>\n",
       "      <td>7.165963</td>\n",
       "      <td>1657</td>\n",
       "      <td>0.67039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>planes-trains-and-automobiles</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>An irritable marketing executive, Neal Page, i...</td>\n",
       "      <td>7.599783</td>\n",
       "      <td>1844</td>\n",
       "      <td>0.67440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>that-awkward-moment</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "      <td>Best pals Jason and Daniel indulge in casual f...</td>\n",
       "      <td>4.357798</td>\n",
       "      <td>654</td>\n",
       "      <td>0.68342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>new-rose-hotel</td>\n",
       "      <td>[Drama, Mystery, Science Fiction]</td>\n",
       "      <td>A corporate raider and his henchman use a chan...</td>\n",
       "      <td>7.104034</td>\n",
       "      <td>471</td>\n",
       "      <td>0.69104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>dune</td>\n",
       "      <td>[Action, Science Fiction, Adventure]</td>\n",
       "      <td>In the year 10,191, the world is at war for co...</td>\n",
       "      <td>5.307387</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.69438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>the-lego-movie-2-the-second-part</td>\n",
       "      <td>[Action, Adventure, Animation, Comedy, Family]</td>\n",
       "      <td>It's been five years since everything was awes...</td>\n",
       "      <td>6.308259</td>\n",
       "      <td>1901</td>\n",
       "      <td>0.69455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>bananas</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>When a bumbling New Yorker is dumped by his ac...</td>\n",
       "      <td>6.547660</td>\n",
       "      <td>577</td>\n",
       "      <td>0.69511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              movie_id  \\\n",
       "926                       interstellar   \n",
       "1796                     space-cowboys   \n",
       "2543                           silence   \n",
       "474                            gattaca   \n",
       "2685     planes-trains-and-automobiles   \n",
       "1356               that-awkward-moment   \n",
       "64                      new-rose-hotel   \n",
       "4383                              dune   \n",
       "1588  the-lego-movie-2-the-second-part   \n",
       "3406                           bananas   \n",
       "\n",
       "                                              genres  \\\n",
       "926              [Adventure, Drama, Science Fiction]   \n",
       "1796                   [Action, Adventure, Thriller]   \n",
       "2543                                [Drama, History]   \n",
       "474    [Thriller, Science Fiction, Mystery, Romance]   \n",
       "2685                                        [Comedy]   \n",
       "1356                               [Comedy, Romance]   \n",
       "64                 [Drama, Mystery, Science Fiction]   \n",
       "4383            [Action, Science Fiction, Adventure]   \n",
       "1588  [Action, Adventure, Animation, Comedy, Family]   \n",
       "3406                                        [Comedy]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "926   The adventures of a group of explorers who mak...    7.918451   \n",
       "1796  Frank Corvin, Hawk Hawkins, Jerry O'Neill an...    5.760504   \n",
       "2543  Two Jesuit priests travel to seventeenth centu...    7.936971   \n",
       "474   In a future society in the era of indefinite e...    7.165963   \n",
       "2685  An irritable marketing executive, Neal Page, i...    7.599783   \n",
       "1356  Best pals Jason and Daniel indulge in casual f...    4.357798   \n",
       "64    A corporate raider and his henchman use a chan...    7.104034   \n",
       "4383  In the year 10,191, the world is at war for co...    5.307387   \n",
       "1588  It's been five years since everything was awes...    6.308259   \n",
       "3406  When a bumbling New Yorker is dumped by his ac...    6.547660   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "926           4905          0.00000  \n",
       "1796           476          0.62011  \n",
       "2543          2364          0.64369  \n",
       "474           1657          0.67039  \n",
       "2685          1844          0.67440  \n",
       "1356           654          0.68342  \n",
       "64             471          0.69104  \n",
       "4383          2017          0.69438  \n",
       "1588          1901          0.69455  \n",
       "3406           577          0.69511  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_movies(movie_df, X_scaled, nn_cos, 'interstellar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff354fb-6fec-48c1-9dd6-42c32677cfe5",
   "metadata": {},
   "source": [
    "Intersting! Gattaca seems like an interesting suggstion when reading the overview. Space cowboys and dune also seem like reasonable reccomendations.  \n",
    "\n",
    "However we are also getting some pretty poor reccomendations such as 'That Awkward Moment'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9be909b-c562-4e25-8d9f-699e399c5692",
   "metadata": {},
   "source": [
    "# Initial Modelling Conclusion\n",
    "* We are far from a strong reccomendation system, but we have made good progress on being able to recognize familiar movies\n",
    "* With a unsupervised model it is hard to determine an evaluation method at the moment, in the long run we will be looking to use Root Mean Square, but for now qualititave is our best bet.\n",
    "    * Cosine seems to be the stronger distance metric for us, qualititavely and theoreticcally. \n",
    "* We may need to look into weighting certain aspect of our data for modelling as well as look into other models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050445d8-b3ba-48b4-8d89-166d4b8110c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Hugging Face NLP Transformer\n",
    "\n",
    "Before we move on to collaborative filtering we are going to look at re-vectorizing our movie overview to get more similar movies. To do this we will be looking at using Hugging Face Transformers to get contextual embeddings that should perform much better than our standard TF-IDF. \n",
    "\n",
    "Models from Hugging Face understand movie descriptions better than TF-IDF by grasping context, nuances, and relationships between words, leading to more accurate and nuanced content-based recommendations.\n",
    "\n",
    "* Contextual embedding will be much better at understanding semantic meaning behind our overviews.\n",
    "* We will us BERT, which will provide us Bi-direction understanding (both left and right context when processing language) \n",
    "    * BERT is pretrained on huge amounts of data, and thus will be very smart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3231f95",
   "metadata": {
    "id": "a3231f95"
   },
   "source": [
    "First lets load up our data before we vectorized it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2dec864",
   "metadata": {
    "id": "b2dec864"
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('data/movies_letterboxd_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "I7l7KauZ8j-A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "I7l7KauZ8j-A",
    "outputId": "231df222-3c51-41f1-9215-abab44e87646"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fc85ff26758f696344ad07f</td>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>en</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fc85ff26758f696344aceeb</td>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>en</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fc85ff26758f696344acf29</td>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>en</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5fc85ff26758f696344ad019</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>en</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fc85ff26758f696344ad100</td>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>en</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5fc85ff26758f696344ad07f   \n",
       "1  5fc85ff26758f696344aceeb   \n",
       "2  5fc85ff26758f696344acf29   \n",
       "3  5fc85ff26758f696344ad019   \n",
       "4  5fc85ff26758f696344ad100   \n",
       "\n",
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id original_language  \\\n",
       "0  house-at-the-end-of-the-street                en   \n",
       "1          green-street-hooligans                en   \n",
       "2           beverly-hills-cop-iii                en   \n",
       "3                     bad-boys-ii                en   \n",
       "4                    a-single-man                en   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  \n",
       "0         2012.0    3.880987           689  \n",
       "1         2005.0    5.953771           411  \n",
       "2         1994.0    4.492424           528  \n",
       "3         2003.0    6.021593          1343  \n",
       "4         2009.0    7.660256          1404  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FGsU6Sbm9PN_",
   "metadata": {
    "id": "FGsU6Sbm9PN_"
   },
   "source": [
    "Lets drop the original language column now that we only have english movies. We can also drop index as we wont be using this in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pMbIb96D9Ngo",
   "metadata": {
    "id": "pMbIb96D9Ngo"
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['original_language', '_id']\n",
    "df_1.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qrUByv5W9dVf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "qrUByv5W9dVf",
    "outputId": "b0bd9e57-20bb-48e5-a82c-6a993cd27f01",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id  \\\n",
       "0  house-at-the-end-of-the-street   \n",
       "1          green-street-hooligans   \n",
       "2           beverly-hills-cop-iii   \n",
       "3                     bad-boys-ii   \n",
       "4                    a-single-man   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  \n",
       "0         2012.0    3.880987           689  \n",
       "1         2005.0    5.953771           411  \n",
       "2         1994.0    4.492424           528  \n",
       "3         2003.0    6.021593          1343  \n",
       "4         2009.0    7.660256          1404  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DRgTp_Rg91tw",
   "metadata": {
    "id": "DRgTp_Rg91tw"
   },
   "source": [
    "We will need to pip install transformers and torch.\n",
    "\n",
    "* Transformers package contains the Hugging Face transformer models we want to use (including BERT).\n",
    "  * This will allow us to work with pre-trained models and tokenizers\n",
    "* Torch is the PyTorch library used for tensor computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1zcUc3db-kxd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zcUc3db-kxd",
    "outputId": "2ef13aa8-096b-4f96-f56d-98492b1241c6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: torch in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: boto3 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.76)\n",
      "Requirement already satisfied: requests in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: sentencepiece in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from transformers) (0.1.99)\n",
      "Requirement already satisfied: sacremoses in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.76 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from boto3->transformers) (1.29.76)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from boto3->transformers) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: six in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from sacremoses->transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from sacremoses->transformers) (1.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/colebeevor-potts/anaconda3/lib/python3.11/site-packages (from botocore<1.30.0,>=1.29.76->boto3->transformers) (2.8.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912e191",
   "metadata": {},
   "source": [
    "# BERT Text Embeddings with Hugging Face\n",
    "Now we camn use BERT (Bidirectional Encoder Representations from Transformers) model from Hugging Face's transformers library to generate embeddings for text in a DataFrame column called 'overview'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BRpxfLTGpWay",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "2bbf983010b14b57a12488b005526bd3",
      "1c857e48a86541c3aa47c3bc9eebbd15",
      "b9989b46ba5f454e9d989a509b45df53",
      "49017e693a394253bc794f8ae6393f89",
      "dbca2e3c6194421d9874aea3a416ba85",
      "ae8cad26821c4a94886a830adcc7a71f",
      "9a98df6bdb594d4d897926bd63329c65",
      "2d9e7317666e44a388bf38ac381baee8",
      "d641fb36b35a48348db0c0b7709f9bb2",
      "70fc1fea1f934eae8b703eb290460cf9",
      "d5ee10fd99eb4e9f913bb6eb51325b13",
      "90f904a4319b41ffb3dfe5889ba5db60",
      "70dad2a045194258befc7483c9e8249d",
      "784067dc1ec34e478b27e619974d72e8",
      "efc83b9245a748f5825bc66d2246e7c0",
      "01ea18352a4a425b8bd3dc18e9fdf2f6",
      "f5a77dd0dde44b8b8cb25ca0625495c6",
      "7cae2b09f1764cf9923ff928f04debc6",
      "da7aa017905943169508891c71e7f9cb",
      "290bbb0005d942b6af66df3bbf684cbe",
      "24b8719d7e2f4a22851da4efff8d79bb",
      "d78c7682c1e14a6fb5d4123e5d42f68e",
      "a1df12bfebf542899e51f2aeb2d9f6f6",
      "46a8354e3a084e86afe64ed8a9b6ae00",
      "b2d7967b9d554cf387691920f0296bb8",
      "9cdd199b391d47a3aa077490ddc6ea9e",
      "1293d7e33c8a40578790afad29791e5a",
      "625ed3cdc21d4aeea80e2c2a63f82db3",
      "f2ed7b8541a94459a8cadaecaecff9b6",
      "9784318aecac40839350e1f83dedec51",
      "4c19bc709c474f9a9f4fb8c389c8db72",
      "9b9de5eeb96b47deab49b97cdba5edfe",
      "f46c9e1547be443886c934f6b1c87765",
      "9e450458d3744198b451b0476ab1e453",
      "314cc8d49dd946c5843134380d06d39d",
      "99d5e44c9c4a4acc8d39d31a40581aba",
      "9d5a054aa2a546528f6bebb69ca17f60",
      "27095043607b4435bd2a46a790469474",
      "e0ddbe231e984fc485a4b1a73e780c2f",
      "2e64ef73f8924b4e8d7a1b4ee41e13e0",
      "f9a5ea63e4994fc181ce1e0bff1242d4",
      "f66e0724e1f24f52ab0965f7c110efca",
      "1bcd092ee3434014a948d0dfa6e88a67",
      "2a3d6895f842457da5af6f76b9f6d6ad",
      "cb8683e872f749feb1c11c89c6795da6",
      "ab5e454f57bc42a0bebc89b3b7e77eac",
      "66db178a05034f1489e15e3995a98d8b",
      "0097bdb96fb14638ad6b6a0402c32639",
      "9d7f9c17f3b144f798c5d85e1b342ecf",
      "8e07b958b76247aab9d9b627223aea73",
      "3b80661d94a149bb937da9bf11a10ce0",
      "27cd7054ec8f4bb89035d899c6cd74a6",
      "6c3fa5c727f945ba8fa79c10db4873d9",
      "40faf633c757434384d547d2d514c843",
      "e6634286cade4f27b7c80430ec5ff499"
     ]
    },
    "id": "BRpxfLTGpWay",
    "outputId": "16807001-ec40-47cb-f965-fe0bd3c8a42e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbf983010b14b57a12488b005526bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f904a4319b41ffb3dfe5889ba5db60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1df12bfebf542899e51f2aeb2d9f6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e450458d3744198b451b0476ab1e453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8683e872f749feb1c11c89c6795da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel #Pre trained modules from HuggingFace\n",
    "\n",
    "# Define pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# Load the pre trained BERT model\n",
    "bert_model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize and obtain BERT embeddings for the 'overview' column\n",
    "def get_bert_embeddings(text):\n",
    "     \"\"\"\n",
    "    Get BERT embeddings for the given text.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): Input text to generate BERT embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - embeddings (numpy.ndarray): BERT embeddings for the input text.\n",
    "\n",
    "    This function tokenizes the input text using a pre-trained BERT tokenizer,\n",
    "    converts the tokens into PyTorch tensors, and passes them through a pre-trained\n",
    "    BERT model to obtain embeddings. The obtained embeddings represent a fixed-size\n",
    "    numerical representation of the input text, capturing its contextual information\n",
    "    based on the pre-trained BERT model. These embeddings are returned as a NumPy\n",
    "    array for further analysis.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad(): #dont use gradients because model is already trained\n",
    "        outputs = bert_model(**tokens)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Apply BERT embeddings to the 'overview' column\n",
    "df_1['overview_embeddings'] = df_1['overview'].apply(get_bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bv1flYGnvwST",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "bv1flYGnvwST",
    "outputId": "a19d870c-8451-455a-f884-955d8dd2fb8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a56cf13a-3ab1-40d9-b9e5-66efdff23333\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>overview_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "      <td>[[-0.09418693, -0.11440811, 0.41866848, -0.144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "      <td>[[-0.0868503, 0.06448872, 0.2141984, -0.293964...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "      <td>[[-0.03214478, -0.17523718, 0.20841049, 0.0298...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "      <td>[[-0.038505197, -0.054682262, 0.38358197, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "      <td>[[-0.07349635, 0.13890934, 0.32025003, -0.4259...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a56cf13a-3ab1-40d9-b9e5-66efdff23333')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a56cf13a-3ab1-40d9-b9e5-66efdff23333 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a56cf13a-3ab1-40d9-b9e5-66efdff23333');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-24887847-684e-4a79-8840-6bcafa5d75fc\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24887847-684e-4a79-8840-6bcafa5d75fc')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-24887847-684e-4a79-8840-6bcafa5d75fc button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id  \\\n",
       "0  house-at-the-end-of-the-street   \n",
       "1          green-street-hooligans   \n",
       "2           beverly-hills-cop-iii   \n",
       "3                     bad-boys-ii   \n",
       "4                    a-single-man   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  \\\n",
       "0         2012.0    3.880987           689   \n",
       "1         2005.0    5.953771           411   \n",
       "2         1994.0    4.492424           528   \n",
       "3         2003.0    6.021593          1343   \n",
       "4         2009.0    7.660256          1404   \n",
       "\n",
       "                                 overview_embeddings  \n",
       "0  [[-0.09418693, -0.11440811, 0.41866848, -0.144...  \n",
       "1  [[-0.0868503, 0.06448872, 0.2141984, -0.293964...  \n",
       "2  [[-0.03214478, -0.17523718, 0.20841049, 0.0298...  \n",
       "3  [[-0.038505197, -0.054682262, 0.38358197, -0.0...  \n",
       "4  [[-0.07349635, 0.13890934, 0.32025003, -0.4259...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7UtteqmaAB3E",
   "metadata": {
    "id": "7UtteqmaAB3E"
   },
   "source": [
    "Awesome. We have our embeddings split into seperate columns for each of our movies so that we can run them through our Nearest Neighbour Model.\n",
    "\n",
    "I was getting an error with shape using tensors, lets test the shape of this new approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7pGf6zwGfs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b7pGf6zwGfs",
    "outputId": "212a2a9a-25dc-4d53-d2d3-8d29f90dd1e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5061,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape of the entire 'overview_embeddings' column in the DataFrame\n",
    "df_1['overview_embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vkbXeR5Xwj-e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkbXeR5Xwj-e",
    "outputId": "a5af3332-7da5-4178-e5f1-2b84e8caf576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape of the overview embeddings for the first movie\n",
    "df_1['overview_embeddings'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YpeVA91Wwqui",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpeVA91Wwqui",
    "outputId": "c5e373bf-1f02-4f36-d5b6-ae20fc6dc4d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape of the overview embeddings for the second movie\n",
    "df_1['overview_embeddings'][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-cXHQwqSCOCe",
   "metadata": {
    "id": "-cXHQwqSCOCe"
   },
   "source": [
    "# Pre-processing for our Model\n",
    "Looks good so far! now we can move into splitting our embedding array into seperate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hBbgmIXozmDr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBbgmIXozmDr",
    "outputId": "30a5da7d-19f0-49f5-e438-3a72db94645a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n",
      "<ipython-input-34-7aee8348f664>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_1[new_columns] = df_1.apply(split_array, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Function to split arrays into separate columns\n",
    "def split_array(row):\n",
    "    # Return a Pandas Series from the first element of 'overview_embeddings'\n",
    "    return pd.Series(row['overview_embeddings'][0])\n",
    "\n",
    "# Obtain the number of columns in the embedding array\n",
    "num_columns = df_1['overview_embeddings'][0].shape[1]\n",
    "\n",
    "# Create column names for the new columns\n",
    "new_columns = [f'embed{i+1}' for i in range(num_columns)]\n",
    "\n",
    "# Apply the split_array function to each row and assign the results to new columns\n",
    "df_1[new_columns] = df_1.apply(split_array, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aTFDaPcy0heN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "aTFDaPcy0heN",
    "outputId": "4732dbb4-4c4f-41a8-f93f-feb45f4d71f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a0cc561a-3a52-4fab-af38-6a1f82a78fef\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>overview_embeddings</th>\n",
       "      <th>embed1</th>\n",
       "      <th>...</th>\n",
       "      <th>embed759</th>\n",
       "      <th>embed760</th>\n",
       "      <th>embed761</th>\n",
       "      <th>embed762</th>\n",
       "      <th>embed763</th>\n",
       "      <th>embed764</th>\n",
       "      <th>embed765</th>\n",
       "      <th>embed766</th>\n",
       "      <th>embed767</th>\n",
       "      <th>embed768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "      <td>[[-0.09418693, -0.11440811, 0.41866848, -0.144...</td>\n",
       "      <td>-0.094187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187498</td>\n",
       "      <td>-0.141819</td>\n",
       "      <td>-0.393746</td>\n",
       "      <td>-0.264628</td>\n",
       "      <td>-0.284240</td>\n",
       "      <td>-0.228978</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>-0.244107</td>\n",
       "      <td>0.125971</td>\n",
       "      <td>-0.100652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "      <td>[[-0.0868503, 0.06448872, 0.2141984, -0.293964...</td>\n",
       "      <td>-0.086850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>-0.181906</td>\n",
       "      <td>-0.124396</td>\n",
       "      <td>-0.409928</td>\n",
       "      <td>-0.073736</td>\n",
       "      <td>-0.344885</td>\n",
       "      <td>-0.287368</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>-0.013028</td>\n",
       "      <td>0.039776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "      <td>[[-0.03214478, -0.17523718, 0.20841049, 0.0298...</td>\n",
       "      <td>-0.032145</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238653</td>\n",
       "      <td>-0.076611</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.330764</td>\n",
       "      <td>0.020014</td>\n",
       "      <td>0.104707</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.028200</td>\n",
       "      <td>0.138410</td>\n",
       "      <td>-0.228308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "      <td>[[-0.038505197, -0.054682262, 0.38358197, -0.0...</td>\n",
       "      <td>-0.038505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307804</td>\n",
       "      <td>-0.150111</td>\n",
       "      <td>0.084804</td>\n",
       "      <td>-0.491340</td>\n",
       "      <td>-0.114525</td>\n",
       "      <td>-0.111116</td>\n",
       "      <td>-0.300794</td>\n",
       "      <td>-0.280891</td>\n",
       "      <td>0.213256</td>\n",
       "      <td>-0.447817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "      <td>[[-0.07349635, 0.13890934, 0.32025003, -0.4259...</td>\n",
       "      <td>-0.073496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097426</td>\n",
       "      <td>-0.109338</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>-0.556834</td>\n",
       "      <td>-0.202869</td>\n",
       "      <td>-0.185133</td>\n",
       "      <td>-0.144681</td>\n",
       "      <td>-0.042935</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>-0.096624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  777 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0cc561a-3a52-4fab-af38-6a1f82a78fef')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a0cc561a-3a52-4fab-af38-6a1f82a78fef button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a0cc561a-3a52-4fab-af38-6a1f82a78fef');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b174aab0-1479-49e7-b30d-597c06d78f5d\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b174aab0-1479-49e7-b30d-597c06d78f5d')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b174aab0-1479-49e7-b30d-597c06d78f5d button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id  \\\n",
       "0  house-at-the-end-of-the-street   \n",
       "1          green-street-hooligans   \n",
       "2           beverly-hills-cop-iii   \n",
       "3                     bad-boys-ii   \n",
       "4                    a-single-man   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  \\\n",
       "0         2012.0    3.880987           689   \n",
       "1         2005.0    5.953771           411   \n",
       "2         1994.0    4.492424           528   \n",
       "3         2003.0    6.021593          1343   \n",
       "4         2009.0    7.660256          1404   \n",
       "\n",
       "                                 overview_embeddings    embed1  ...  embed759  \\\n",
       "0  [[-0.09418693, -0.11440811, 0.41866848, -0.144... -0.094187  ... -0.187498   \n",
       "1  [[-0.0868503, 0.06448872, 0.2141984, -0.293964... -0.086850  ...  0.012002   \n",
       "2  [[-0.03214478, -0.17523718, 0.20841049, 0.0298... -0.032145  ... -0.238653   \n",
       "3  [[-0.038505197, -0.054682262, 0.38358197, -0.0... -0.038505  ... -0.307804   \n",
       "4  [[-0.07349635, 0.13890934, 0.32025003, -0.4259... -0.073496  ...  0.097426   \n",
       "\n",
       "   embed760  embed761  embed762  embed763  embed764  embed765  embed766  \\\n",
       "0 -0.141819 -0.393746 -0.264628 -0.284240 -0.228978  0.015331 -0.244107   \n",
       "1 -0.181906 -0.124396 -0.409928 -0.073736 -0.344885 -0.287368  0.009852   \n",
       "2 -0.076611 -0.008018 -0.330764  0.020014  0.104707  0.000675 -0.028200   \n",
       "3 -0.150111  0.084804 -0.491340 -0.114525 -0.111116 -0.300794 -0.280891   \n",
       "4 -0.109338  0.002772 -0.556834 -0.202869 -0.185133 -0.144681 -0.042935   \n",
       "\n",
       "   embed767  embed768  \n",
       "0  0.125971 -0.100652  \n",
       "1 -0.013028  0.039776  \n",
       "2  0.138410 -0.228308  \n",
       "3  0.213256 -0.447817  \n",
       "4  0.000639 -0.096624  \n",
       "\n",
       "[5 rows x 777 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y8XQMb7-8JX2",
   "metadata": {
    "id": "Y8XQMb7-8JX2"
   },
   "source": [
    "Lets save this as a CSV now that we have splt out our embeddings out into seperate colums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mxWBP7AsGkDf",
   "metadata": {
    "id": "mxWBP7AsGkDf"
   },
   "outputs": [],
   "source": [
    "#saving into CSV\n",
    "df_1.to_csv('data/embeddings_df_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4Qw8Q_6G0BFu",
   "metadata": {
    "id": "4Qw8Q_6G0BFu"
   },
   "outputs": [],
   "source": [
    "#loading the CSV back\n",
    "df_1 = pd.read_csv('data/embeddings_df_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bozfpH6OCuym",
   "metadata": {
    "id": "bozfpH6OCuym"
   },
   "source": [
    "Now we will get ready to train a new Nearest neighbour model so we can find the most similar movies based on the embeddings we found. Lets drop all columns except, for the embeddings and the movie_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Scn9ruynwz0F",
   "metadata": {
    "id": "Scn9ruynwz0F"
   },
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['genres', 'overview','overview_embeddings', 'runtime', 'popularity', 'year_released', 'avg_rating', 'rating_count']\n",
    "\n",
    "# Create a copy of df_1 and drop the specified columns\n",
    "df_only_embed = df_1.drop(columns=columns_to_drop).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "trnuR11CDyZV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "trnuR11CDyZV",
    "outputId": "e5085f4e-6141-413d-bab1-0574e2d4b527"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>embed1</th>\n",
       "      <th>embed2</th>\n",
       "      <th>embed3</th>\n",
       "      <th>embed4</th>\n",
       "      <th>embed5</th>\n",
       "      <th>embed6</th>\n",
       "      <th>embed7</th>\n",
       "      <th>embed8</th>\n",
       "      <th>embed9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed759</th>\n",
       "      <th>embed760</th>\n",
       "      <th>embed761</th>\n",
       "      <th>embed762</th>\n",
       "      <th>embed763</th>\n",
       "      <th>embed764</th>\n",
       "      <th>embed765</th>\n",
       "      <th>embed766</th>\n",
       "      <th>embed767</th>\n",
       "      <th>embed768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>-0.094187</td>\n",
       "      <td>-0.114408</td>\n",
       "      <td>0.418668</td>\n",
       "      <td>-0.144036</td>\n",
       "      <td>0.425034</td>\n",
       "      <td>0.032762</td>\n",
       "      <td>0.320194</td>\n",
       "      <td>0.478216</td>\n",
       "      <td>0.377975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187498</td>\n",
       "      <td>-0.141819</td>\n",
       "      <td>-0.393746</td>\n",
       "      <td>-0.264628</td>\n",
       "      <td>-0.284240</td>\n",
       "      <td>-0.228978</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>-0.244107</td>\n",
       "      <td>0.125971</td>\n",
       "      <td>-0.100652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>-0.086850</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>0.214198</td>\n",
       "      <td>-0.293965</td>\n",
       "      <td>0.336228</td>\n",
       "      <td>-0.043790</td>\n",
       "      <td>0.194410</td>\n",
       "      <td>0.440571</td>\n",
       "      <td>0.390315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>-0.181906</td>\n",
       "      <td>-0.124396</td>\n",
       "      <td>-0.409928</td>\n",
       "      <td>-0.073736</td>\n",
       "      <td>-0.344885</td>\n",
       "      <td>-0.287368</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>-0.013028</td>\n",
       "      <td>0.039776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>-0.032145</td>\n",
       "      <td>-0.175237</td>\n",
       "      <td>0.208410</td>\n",
       "      <td>0.029855</td>\n",
       "      <td>0.389175</td>\n",
       "      <td>-0.035812</td>\n",
       "      <td>0.363868</td>\n",
       "      <td>0.355118</td>\n",
       "      <td>0.184765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238653</td>\n",
       "      <td>-0.076611</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.330764</td>\n",
       "      <td>0.020014</td>\n",
       "      <td>0.104707</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.028200</td>\n",
       "      <td>0.138410</td>\n",
       "      <td>-0.228308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>-0.038505</td>\n",
       "      <td>-0.054682</td>\n",
       "      <td>0.383582</td>\n",
       "      <td>-0.060498</td>\n",
       "      <td>0.393801</td>\n",
       "      <td>-0.195273</td>\n",
       "      <td>0.145992</td>\n",
       "      <td>0.395095</td>\n",
       "      <td>0.360342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307804</td>\n",
       "      <td>-0.150111</td>\n",
       "      <td>0.084804</td>\n",
       "      <td>-0.491340</td>\n",
       "      <td>-0.114525</td>\n",
       "      <td>-0.111116</td>\n",
       "      <td>-0.300794</td>\n",
       "      <td>-0.280891</td>\n",
       "      <td>0.213256</td>\n",
       "      <td>-0.447817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a-single-man</td>\n",
       "      <td>-0.073496</td>\n",
       "      <td>0.138909</td>\n",
       "      <td>0.320250</td>\n",
       "      <td>-0.425920</td>\n",
       "      <td>0.452002</td>\n",
       "      <td>0.280139</td>\n",
       "      <td>0.047498</td>\n",
       "      <td>0.329194</td>\n",
       "      <td>0.252887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097426</td>\n",
       "      <td>-0.109338</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>-0.556834</td>\n",
       "      <td>-0.202869</td>\n",
       "      <td>-0.185133</td>\n",
       "      <td>-0.144681</td>\n",
       "      <td>-0.042935</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>-0.096624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         movie_id    embed1    embed2    embed3    embed4  \\\n",
       "0  house-at-the-end-of-the-street -0.094187 -0.114408  0.418668 -0.144036   \n",
       "1          green-street-hooligans -0.086850  0.064489  0.214198 -0.293965   \n",
       "2           beverly-hills-cop-iii -0.032145 -0.175237  0.208410  0.029855   \n",
       "3                     bad-boys-ii -0.038505 -0.054682  0.383582 -0.060498   \n",
       "4                    a-single-man -0.073496  0.138909  0.320250 -0.425920   \n",
       "\n",
       "     embed5    embed6    embed7    embed8    embed9  ...  embed759  embed760  \\\n",
       "0  0.425034  0.032762  0.320194  0.478216  0.377975  ... -0.187498 -0.141819   \n",
       "1  0.336228 -0.043790  0.194410  0.440571  0.390315  ...  0.012002 -0.181906   \n",
       "2  0.389175 -0.035812  0.363868  0.355118  0.184765  ... -0.238653 -0.076611   \n",
       "3  0.393801 -0.195273  0.145992  0.395095  0.360342  ... -0.307804 -0.150111   \n",
       "4  0.452002  0.280139  0.047498  0.329194  0.252887  ...  0.097426 -0.109338   \n",
       "\n",
       "   embed761  embed762  embed763  embed764  embed765  embed766  embed767  \\\n",
       "0 -0.393746 -0.264628 -0.284240 -0.228978  0.015331 -0.244107  0.125971   \n",
       "1 -0.124396 -0.409928 -0.073736 -0.344885 -0.287368  0.009852 -0.013028   \n",
       "2 -0.008018 -0.330764  0.020014  0.104707  0.000675 -0.028200  0.138410   \n",
       "3  0.084804 -0.491340 -0.114525 -0.111116 -0.300794 -0.280891  0.213256   \n",
       "4  0.002772 -0.556834 -0.202869 -0.185133 -0.144681 -0.042935  0.000639   \n",
       "\n",
       "   embed768  \n",
       "0 -0.100652  \n",
       "1  0.039776  \n",
       "2 -0.228308  \n",
       "3 -0.447817  \n",
       "4 -0.096624  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "df_only_embed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w0_PCivLvmYi",
   "metadata": {
    "id": "w0_PCivLvmYi"
   },
   "source": [
    "Lets save this as a CSV so we dont have to constantly re run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yAADu37Mvkx0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAADu37Mvkx0",
    "outputId": "47d8a8b4-6aa3-4fde-b3cc-fbb15563151b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#Saving our CSV\n",
    "df_only_embed.to_csv('data/only_embeddings_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gdulVPx-x1Nr",
   "metadata": {
    "id": "gdulVPx-x1Nr"
   },
   "outputs": [],
   "source": [
    "#Reading back our CSV\n",
    "df_only_embed = pd.read_csv(path + 'only_embeddings_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JNXjaNLYEF8s",
   "metadata": {
    "id": "JNXjaNLYEF8s"
   },
   "source": [
    "# Modelling with BERT Embeddings\n",
    "Now lets fit a model on just the embeddings and see what we get for reccomendations!\n",
    "\n",
    "**Note:** We will again use cosine as our metric in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7iVKZTMkEEZO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "7iVKZTMkEEZO",
    "outputId": "5602d390-e813-4623-81d9-43add7e0aec2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning our data to X, dropping movie_id to only include the embeddings\n",
    "X = df_only_embed.drop(['movie_id'], axis=1)\n",
    "\n",
    "# Initialize the NearestNeighbors model\n",
    "#Using cosine distance as distance metric\n",
    "NearestNeighbour1 = NearestNeighbors(n_neighbors=10, algorithm='auto', metric = 'cosine')\n",
    "\n",
    "# Fit the model to your data\n",
    "NearestNeighbour1.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a940d2ed",
   "metadata": {},
   "source": [
    "## Qualitative Evaluation on BERT Model\n",
    "Now lets define a fintion to return similar movies so we can qualitatively evaluate our models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0XlCFs3oEbma",
   "metadata": {
    "id": "0XlCFs3oEbma"
   },
   "outputs": [],
   "source": [
    "def similar_movies_embed(df_1, X, NearestNeighbour1, movie_id):\n",
    "    \"\"\"\n",
    "    Finds movies similar to a given movie using nearest neighbors.\n",
    "\n",
    "    Parameters:\n",
    "    - movie_df (pandas.DataFrame): DataFrame containing movie details.\n",
    "    - X_scaled (numpy.ndarray): Scaled features of the movies.\n",
    "    - nn_model: Nearest neighbors model trained on the movie features.\n",
    "    - movie_name (str): Name of the movie to find similar movies for.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing details of similar movies.\n",
    "    Columns: 'movie_id', 'genres', 'overview', 'avg_rating', 'rating_count', 'cosine_distance'.\n",
    "    'cosine_distance' represents the cosine distance to the original movie (rounded to 5 decimal places).\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the index of the movie\n",
    "    movie_index = df_1[df_only_embed['movie_id'] == movie_id].index[0]\n",
    "\n",
    "    # Get the features of the movie\n",
    "    input_movie_features = X.loc[[movie_index]]\n",
    "\n",
    "    # Find the nearest neighbors with the provided model\n",
    "    distances, indices = NearestNeighbour1.kneighbors(input_movie_features, n_neighbors=10)\n",
    "\n",
    "    # Return the movies that are most similar\n",
    "    sim_movies = df_1.iloc[indices[0]]\n",
    "\n",
    "    # Create a DataFrame containing selected columns\n",
    "    similar_movies = sim_movies[['movie_id', 'genres', 'overview', 'avg_rating', 'rating_count']]\n",
    "\n",
    "    # Add a new column with cosine distance to the original movie (and round to 5 decimal places)\n",
    "    similar_movies['cosine_distance'] = np.round(distances[0], 5)\n",
    "\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gP7NjlBNEi_z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "gP7NjlBNEi_z",
    "outputId": "5329c967-92d1-48d7-8a0b-1a3ee1ad7458"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_26094/993226041.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>goodfellas</td>\n",
       "      <td>[\"Drama\",\"Crime\"]</td>\n",
       "      <td>The true story of Henry Hill, a half-Irish, ha...</td>\n",
       "      <td>8.858363</td>\n",
       "      <td>4215</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>the-many-saints-of-newark</td>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>Young Anthony Soprano is growing up in one of ...</td>\n",
       "      <td>5.803846</td>\n",
       "      <td>780</td>\n",
       "      <td>0.11846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>the-irishman-2019</td>\n",
       "      <td>[\"Crime\",\"Drama\",\"History\"]</td>\n",
       "      <td>Pennsylvania, 1956. Frank Sheeran, a war veter...</td>\n",
       "      <td>8.156963</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.12394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>the-godfather</td>\n",
       "      <td>[\"Drama\",\"Crime\"]</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>9.052349</td>\n",
       "      <td>4279</td>\n",
       "      <td>0.12549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>cruising</td>\n",
       "      <td>[\"Crime\",\"Mystery\",\"Thriller\"]</td>\n",
       "      <td>A serial killer brutally slays and dismembers ...</td>\n",
       "      <td>7.222642</td>\n",
       "      <td>1060</td>\n",
       "      <td>0.13133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>the-talented-mr-ripley</td>\n",
       "      <td>[\"Thriller\",\"Crime\",\"Drama\"]</td>\n",
       "      <td>Tom Ripley is a calculating young man who beli...</td>\n",
       "      <td>7.657143</td>\n",
       "      <td>1645</td>\n",
       "      <td>0.13147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>casino</td>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>In early-1970s Las Vegas, low-level mobster Sa...</td>\n",
       "      <td>8.183462</td>\n",
       "      <td>2600</td>\n",
       "      <td>0.13184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>black-mass-2015</td>\n",
       "      <td>[\"Drama\",\"Crime\",\"History\"]</td>\n",
       "      <td>The true story of Whitey Bulger, the brother o...</td>\n",
       "      <td>5.745171</td>\n",
       "      <td>1346</td>\n",
       "      <td>0.13252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>catch-me-if-you-can-2002</td>\n",
       "      <td>[\"Drama\",\"Crime\"]</td>\n",
       "      <td>A true story about Frank Abagnale Jr. who, bef...</td>\n",
       "      <td>7.898315</td>\n",
       "      <td>3442</td>\n",
       "      <td>0.13395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>good-time</td>\n",
       "      <td>[\"Crime\",\"Drama\",\"Thriller\"]</td>\n",
       "      <td>After a botched bank robbery lands his younger...</td>\n",
       "      <td>7.990950</td>\n",
       "      <td>4199</td>\n",
       "      <td>0.13492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       movie_id                          genres  \\\n",
       "212                  goodfellas               [\"Drama\",\"Crime\"]   \n",
       "5036  the-many-saints-of-newark               [\"Crime\",\"Drama\"]   \n",
       "170           the-irishman-2019     [\"Crime\",\"Drama\",\"History\"]   \n",
       "3151              the-godfather               [\"Drama\",\"Crime\"]   \n",
       "1243                   cruising  [\"Crime\",\"Mystery\",\"Thriller\"]   \n",
       "369      the-talented-mr-ripley    [\"Thriller\",\"Crime\",\"Drama\"]   \n",
       "3208                     casino               [\"Crime\",\"Drama\"]   \n",
       "2018            black-mass-2015     [\"Drama\",\"Crime\",\"History\"]   \n",
       "267    catch-me-if-you-can-2002               [\"Drama\",\"Crime\"]   \n",
       "4357                  good-time    [\"Crime\",\"Drama\",\"Thriller\"]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "212   The true story of Henry Hill, a half-Irish, ha...    8.858363   \n",
       "5036  Young Anthony Soprano is growing up in one of ...    5.803846   \n",
       "170   Pennsylvania, 1956. Frank Sheeran, a war veter...    8.156963   \n",
       "3151  Spanning the years 1945 to 1955, a chronicle o...    9.052349   \n",
       "1243  A serial killer brutally slays and dismembers ...    7.222642   \n",
       "369   Tom Ripley is a calculating young man who beli...    7.657143   \n",
       "3208  In early-1970s Las Vegas, low-level mobster Sa...    8.183462   \n",
       "2018  The true story of Whitey Bulger, the brother o...    5.745171   \n",
       "267   A true story about Frank Abagnale Jr. who, bef...    7.898315   \n",
       "4357  After a botched bank robbery lands his younger...    7.990950   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "212           4215          0.00000  \n",
       "5036           780          0.11846  \n",
       "170           4122          0.12394  \n",
       "3151          4279          0.12549  \n",
       "1243          1060          0.13133  \n",
       "369           1645          0.13147  \n",
       "3208          2600          0.13184  \n",
       "2018          1346          0.13252  \n",
       "267           3442          0.13395  \n",
       "4357          4199          0.13492  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies_embed(df_1, X, NearestNeighbour1, 'goodfellas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NbcYS0mKExFC",
   "metadata": {
    "id": "NbcYS0mKExFC"
   },
   "source": [
    "### Initial Insights\n",
    "Wow this is WAY better than our TF-IDF!!! We didnt even include genre in our model and we can see all of our reccomendations are crime movies! We can start to see the impact of context and how our word embeddings help us capture that.\n",
    "\n",
    "It is one thing to get reccomended crime movies on words like \"maffia\" or \"FBI\" etc, but the movie \"Catch Me If You Can\" seems to be a much smarter reccomendation as the plot follows a similarily narrated style as Goodfellas with a lot of similarity, but it is by no means a mob/maffia movie. \n",
    "\n",
    "However, even the suggestions of the Maffia movies shows some good understanding of context.\n",
    "\n",
    "When we used TF_IDF we we were getting some crime movies but this is largely outperforming so far. \n",
    "\n",
    "We can also note that avg_rating is relatively high for most movies sugggested here. Cosine distances are also relatively low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YiZMjLkFNfbU",
   "metadata": {
    "id": "YiZMjLkFNfbU"
   },
   "source": [
    "Lets look at another movie we have looked at throughout this project: Raiders of the Lost Ark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-81onL9FefN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "c-81onL9FefN",
    "outputId": "30256012-6e0b-489a-ebc3-fa88e097f92f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-92-8f658e174062>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-65c953c5-db52-444f-86a3-733718f70ea8\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>raiders-of-the-lost-ark</td>\n",
       "      <td>[\"Adventure\",\"Action\"]</td>\n",
       "      <td>When Dr. Indiana Jones  the tweed-suited prof...</td>\n",
       "      <td>8.481832</td>\n",
       "      <td>3908</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>indiana-jones-and-the-last-crusade</td>\n",
       "      <td>[\"Adventure\",\"Action\"]</td>\n",
       "      <td>When Dr. Henry Jones Sr. suddenly goes missing...</td>\n",
       "      <td>8.033586</td>\n",
       "      <td>3037</td>\n",
       "      <td>0.09130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>captain-america-the-first-avenger</td>\n",
       "      <td>[\"Action\",\"Adventure\",\"Science Fiction\"]</td>\n",
       "      <td>During World War II, Steve Rogers is a sickly ...</td>\n",
       "      <td>6.433465</td>\n",
       "      <td>4058</td>\n",
       "      <td>0.09424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>indiana-jones-and-the-temple-of-doom</td>\n",
       "      <td>[\"Adventure\",\"Action\"]</td>\n",
       "      <td>After arriving in India, Indiana Jones is aske...</td>\n",
       "      <td>7.048237</td>\n",
       "      <td>3006</td>\n",
       "      <td>0.10521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>the-sorcerers-apprentice-2010</td>\n",
       "      <td>[\"Fantasy\",\"Adventure\",\"Action\"]</td>\n",
       "      <td>Balthazar Blake is a master sorcerer in modern...</td>\n",
       "      <td>4.674912</td>\n",
       "      <td>849</td>\n",
       "      <td>0.10731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>tron-legacy</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Science Fiction\"]</td>\n",
       "      <td>Sam Flynn, the tech-savvy and daring son of Ke...</td>\n",
       "      <td>5.995614</td>\n",
       "      <td>1824</td>\n",
       "      <td>0.10917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>the-mummy-tomb-of-the-dragon-emperor</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Fantasy\"]</td>\n",
       "      <td>Archaeologist Rick O'Connell travels to China,...</td>\n",
       "      <td>3.675772</td>\n",
       "      <td>842</td>\n",
       "      <td>0.11246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>time-bandits</td>\n",
       "      <td>[\"Family\",\"Fantasy\",\"Science Fiction\",\"Adventu...</td>\n",
       "      <td>Young history buff Kevin can scarcely believe ...</td>\n",
       "      <td>6.998967</td>\n",
       "      <td>968</td>\n",
       "      <td>0.11275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>wargames</td>\n",
       "      <td>[\"Action\"]</td>\n",
       "      <td>High School student David Lightman has a talen...</td>\n",
       "      <td>6.744111</td>\n",
       "      <td>934</td>\n",
       "      <td>0.11440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>land-of-the-lost</td>\n",
       "      <td>[\"Adventure\",\"Comedy\",\"Science Fiction\",\"Family\"]</td>\n",
       "      <td>On his latest expedition, Dr. Rick Marshall is...</td>\n",
       "      <td>4.044017</td>\n",
       "      <td>727</td>\n",
       "      <td>0.11466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65c953c5-db52-444f-86a3-733718f70ea8')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-65c953c5-db52-444f-86a3-733718f70ea8 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-65c953c5-db52-444f-86a3-733718f70ea8');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-32096d3a-7021-4839-ba3a-ff41340446ab\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32096d3a-7021-4839-ba3a-ff41340446ab')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-32096d3a-7021-4839-ba3a-ff41340446ab button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                  movie_id  \\\n",
       "80                 raiders-of-the-lost-ark   \n",
       "4406    indiana-jones-and-the-last-crusade   \n",
       "1413     captain-america-the-first-avenger   \n",
       "1181  indiana-jones-and-the-temple-of-doom   \n",
       "2243         the-sorcerers-apprentice-2010   \n",
       "2608                           tron-legacy   \n",
       "1449  the-mummy-tomb-of-the-dragon-emperor   \n",
       "2826                          time-bandits   \n",
       "3034                              wargames   \n",
       "4319                      land-of-the-lost   \n",
       "\n",
       "                                                 genres  \\\n",
       "80                               [\"Adventure\",\"Action\"]   \n",
       "4406                             [\"Adventure\",\"Action\"]   \n",
       "1413           [\"Action\",\"Adventure\",\"Science Fiction\"]   \n",
       "1181                             [\"Adventure\",\"Action\"]   \n",
       "2243                   [\"Fantasy\",\"Adventure\",\"Action\"]   \n",
       "2608           [\"Adventure\",\"Action\",\"Science Fiction\"]   \n",
       "1449                   [\"Adventure\",\"Action\",\"Fantasy\"]   \n",
       "2826  [\"Family\",\"Fantasy\",\"Science Fiction\",\"Adventu...   \n",
       "3034                                         [\"Action\"]   \n",
       "4319  [\"Adventure\",\"Comedy\",\"Science Fiction\",\"Family\"]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "80    When Dr. Indiana Jones  the tweed-suited prof...    8.481832   \n",
       "4406  When Dr. Henry Jones Sr. suddenly goes missing...    8.033586   \n",
       "1413  During World War II, Steve Rogers is a sickly ...    6.433465   \n",
       "1181  After arriving in India, Indiana Jones is aske...    7.048237   \n",
       "2243  Balthazar Blake is a master sorcerer in modern...    4.674912   \n",
       "2608  Sam Flynn, the tech-savvy and daring son of Ke...    5.995614   \n",
       "1449  Archaeologist Rick O'Connell travels to China,...    3.675772   \n",
       "2826  Young history buff Kevin can scarcely believe ...    6.998967   \n",
       "3034  High School student David Lightman has a talen...    6.744111   \n",
       "4319  On his latest expedition, Dr. Rick Marshall is...    4.044017   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "80            3908          0.00000  \n",
       "4406          3037          0.09130  \n",
       "1413          4058          0.09424  \n",
       "1181          3006          0.10521  \n",
       "2243           849          0.10731  \n",
       "2608          1824          0.10917  \n",
       "1449           842          0.11246  \n",
       "2826           968          0.11275  \n",
       "3034           934          0.11440  \n",
       "4319           727          0.11466  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies_embed(df_1, X, NearestNeighbour1, 'raiders-of-the-lost-ark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04997c1a",
   "metadata": {},
   "source": [
    "**Remember:** When we used TF_IDF we didn't get ANY other Indiana Jones movies,our best reccomendation was Hunger Games.\n",
    "\n",
    "Now we are getting Indiana Jones and The Last Crusade and Indiana Jones and the Temple of Doom. But, an improved version of our TF_IDF vectorizer may have been able to pick this up.\n",
    "\n",
    "More impressively our model reccomends movies like Captaim America, though Indiana Jones isn't a super hero its that same style of hero, action, adventure movie and even takes place in the world war era. \n",
    "\n",
    "We see more good suggestions with The Mummy.\n",
    "\n",
    "It is very noticeable that our model is now performing better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "CSu8dU6_HUrz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "CSu8dU6_HUrz",
    "outputId": "68210df3-0982-4f57-ac39-a0ec4bf66912",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_26094/993226041.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>interstellar</td>\n",
       "      <td>[\"Adventure\",\"Drama\",\"Science Fiction\"]</td>\n",
       "      <td>The adventures of a group of explorers who mak...</td>\n",
       "      <td>7.918451</td>\n",
       "      <td>4905</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>lost-in-space</td>\n",
       "      <td>[\"Science Fiction\",\"Adventure\"]</td>\n",
       "      <td>The prospects for continuing life on Earth in ...</td>\n",
       "      <td>3.980306</td>\n",
       "      <td>457</td>\n",
       "      <td>0.10899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>ad-astra-2019</td>\n",
       "      <td>[\"Science Fiction\",\"Drama\"]</td>\n",
       "      <td>The near future, a time when both hope and har...</td>\n",
       "      <td>7.230031</td>\n",
       "      <td>3230</td>\n",
       "      <td>0.11328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>prometheus</td>\n",
       "      <td>[\"Science Fiction\",\"Adventure\",\"Mystery\"]</td>\n",
       "      <td>A team of explorers discover a clue to the ori...</td>\n",
       "      <td>6.490489</td>\n",
       "      <td>2944</td>\n",
       "      <td>0.11370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>star-trek-iv-the-voyage-home</td>\n",
       "      <td>[\"Science Fiction\",\"Adventure\"]</td>\n",
       "      <td>It's the 23rd century, and a mysterious alien ...</td>\n",
       "      <td>7.350120</td>\n",
       "      <td>834</td>\n",
       "      <td>0.11574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>gattaca</td>\n",
       "      <td>[\"Thriller\",\"Science Fiction\",\"Mystery\",\"Roman...</td>\n",
       "      <td>In a future society in the era of indefinite e...</td>\n",
       "      <td>7.165963</td>\n",
       "      <td>1657</td>\n",
       "      <td>0.12016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>the-black-hole</td>\n",
       "      <td>[\"Adventure\",\"Family\",\"Science Fiction\",\"Action\"]</td>\n",
       "      <td>The explorer craft USS Palomino is returning t...</td>\n",
       "      <td>5.740099</td>\n",
       "      <td>404</td>\n",
       "      <td>0.12185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>2001-a-space-odyssey</td>\n",
       "      <td>[\"Science Fiction\",\"Mystery\",\"Adventure\"]</td>\n",
       "      <td>Humanity finds a mysterious object buried bene...</td>\n",
       "      <td>8.931693</td>\n",
       "      <td>4187</td>\n",
       "      <td>0.12444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>the-tomorrow-war</td>\n",
       "      <td>[\"Action\",\"Science Fiction\",\"Adventure\"]</td>\n",
       "      <td>The world is stunned when a group of time trav...</td>\n",
       "      <td>5.173752</td>\n",
       "      <td>1082</td>\n",
       "      <td>0.12475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>the-5th-wave</td>\n",
       "      <td>[\"Science Fiction\",\"Adventure\",\"Action\"]</td>\n",
       "      <td>16-year-old Cassie Sullivan tries to survive i...</td>\n",
       "      <td>3.529101</td>\n",
       "      <td>756</td>\n",
       "      <td>0.12602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          movie_id  \\\n",
       "926                   interstellar   \n",
       "964                  lost-in-space   \n",
       "1820                 ad-astra-2019   \n",
       "2788                    prometheus   \n",
       "1966  star-trek-iv-the-voyage-home   \n",
       "474                        gattaca   \n",
       "4163                the-black-hole   \n",
       "2734          2001-a-space-odyssey   \n",
       "4989              the-tomorrow-war   \n",
       "592                   the-5th-wave   \n",
       "\n",
       "                                                 genres  \\\n",
       "926             [\"Adventure\",\"Drama\",\"Science Fiction\"]   \n",
       "964                     [\"Science Fiction\",\"Adventure\"]   \n",
       "1820                        [\"Science Fiction\",\"Drama\"]   \n",
       "2788          [\"Science Fiction\",\"Adventure\",\"Mystery\"]   \n",
       "1966                    [\"Science Fiction\",\"Adventure\"]   \n",
       "474   [\"Thriller\",\"Science Fiction\",\"Mystery\",\"Roman...   \n",
       "4163  [\"Adventure\",\"Family\",\"Science Fiction\",\"Action\"]   \n",
       "2734          [\"Science Fiction\",\"Mystery\",\"Adventure\"]   \n",
       "4989           [\"Action\",\"Science Fiction\",\"Adventure\"]   \n",
       "592            [\"Science Fiction\",\"Adventure\",\"Action\"]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "926   The adventures of a group of explorers who mak...    7.918451   \n",
       "964   The prospects for continuing life on Earth in ...    3.980306   \n",
       "1820  The near future, a time when both hope and har...    7.230031   \n",
       "2788  A team of explorers discover a clue to the ori...    6.490489   \n",
       "1966  It's the 23rd century, and a mysterious alien ...    7.350120   \n",
       "474   In a future society in the era of indefinite e...    7.165963   \n",
       "4163  The explorer craft USS Palomino is returning t...    5.740099   \n",
       "2734  Humanity finds a mysterious object buried bene...    8.931693   \n",
       "4989  The world is stunned when a group of time trav...    5.173752   \n",
       "592   16-year-old Cassie Sullivan tries to survive i...    3.529101   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "926           4905          0.00000  \n",
       "964            457          0.10899  \n",
       "1820          3230          0.11328  \n",
       "2788          2944          0.11370  \n",
       "1966           834          0.11574  \n",
       "474           1657          0.12016  \n",
       "4163           404          0.12185  \n",
       "2734          4187          0.12444  \n",
       "4989          1082          0.12475  \n",
       "592            756          0.12602  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies_embed(df_1, X, NearestNeighbour1, 'interstellar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1144f717",
   "metadata": {},
   "source": [
    "Our TF_IDF performed surprisingly well, we are even getting Gattaca reccomended again. However what stands out here again is the consistency, all of these movies are SciFi movies that tie much closer to the nuances of Interstellar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c4a0b",
   "metadata": {},
   "source": [
    "## Insights from BERT Embedding Model\n",
    "It is obvious our model is performing signifcantly better and doing a much better job at reccomending similar themes within a relevant context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V6OxapGuJd5_",
   "metadata": {
    "id": "V6OxapGuJd5_"
   },
   "source": [
    "# Modelling with BERT Embeddings and Numerical Features\n",
    "The performance is pretty good so far with just embeddings. Lets see what happens when we also include the other numerical columns we had and engineered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "L-j5w68cDU1z",
   "metadata": {
    "id": "L-j5w68cDU1z"
   },
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['genres', 'overview','overview_embeddings']\n",
    "\n",
    "# Create a copy of df_1 and drop the specified columns\n",
    "df_2 = df_1.drop(columns=columns_to_drop).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a36c8",
   "metadata": {},
   "source": [
    "We can see below all the numerical columns we will now be running through our NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "FM7dbhQaxTHx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "FM7dbhQaxTHx",
    "outputId": "719a0df1-5cba-4e2c-b912-13904c45e7ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>embed1</th>\n",
       "      <th>embed2</th>\n",
       "      <th>embed3</th>\n",
       "      <th>embed4</th>\n",
       "      <th>...</th>\n",
       "      <th>embed759</th>\n",
       "      <th>embed760</th>\n",
       "      <th>embed761</th>\n",
       "      <th>embed762</th>\n",
       "      <th>embed763</th>\n",
       "      <th>embed764</th>\n",
       "      <th>embed765</th>\n",
       "      <th>embed766</th>\n",
       "      <th>embed767</th>\n",
       "      <th>embed768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "      <td>-0.094187</td>\n",
       "      <td>-0.114408</td>\n",
       "      <td>0.418668</td>\n",
       "      <td>-0.144036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187498</td>\n",
       "      <td>-0.141819</td>\n",
       "      <td>-0.393746</td>\n",
       "      <td>-0.264628</td>\n",
       "      <td>-0.284240</td>\n",
       "      <td>-0.228978</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>-0.244107</td>\n",
       "      <td>0.125971</td>\n",
       "      <td>-0.100652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "      <td>-0.086850</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>0.214198</td>\n",
       "      <td>-0.293965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>-0.181906</td>\n",
       "      <td>-0.124396</td>\n",
       "      <td>-0.409928</td>\n",
       "      <td>-0.073736</td>\n",
       "      <td>-0.344885</td>\n",
       "      <td>-0.287368</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>-0.013028</td>\n",
       "      <td>0.039776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "      <td>-0.032145</td>\n",
       "      <td>-0.175237</td>\n",
       "      <td>0.208410</td>\n",
       "      <td>0.029855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238653</td>\n",
       "      <td>-0.076611</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.330764</td>\n",
       "      <td>0.020014</td>\n",
       "      <td>0.104707</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.028200</td>\n",
       "      <td>0.138410</td>\n",
       "      <td>-0.228308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "      <td>-0.038505</td>\n",
       "      <td>-0.054682</td>\n",
       "      <td>0.383582</td>\n",
       "      <td>-0.060498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307804</td>\n",
       "      <td>-0.150111</td>\n",
       "      <td>0.084804</td>\n",
       "      <td>-0.491340</td>\n",
       "      <td>-0.114525</td>\n",
       "      <td>-0.111116</td>\n",
       "      <td>-0.300794</td>\n",
       "      <td>-0.280891</td>\n",
       "      <td>0.213256</td>\n",
       "      <td>-0.447817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a-single-man</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "      <td>-0.073496</td>\n",
       "      <td>0.138909</td>\n",
       "      <td>0.320250</td>\n",
       "      <td>-0.425920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097426</td>\n",
       "      <td>-0.109338</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>-0.556834</td>\n",
       "      <td>-0.202869</td>\n",
       "      <td>-0.185133</td>\n",
       "      <td>-0.144681</td>\n",
       "      <td>-0.042935</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>-0.096624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  774 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         movie_id  popularity  runtime  year_released  \\\n",
       "0  house-at-the-end-of-the-street      11.088    101.0         2012.0   \n",
       "1          green-street-hooligans      14.690    109.0         2005.0   \n",
       "2           beverly-hills-cop-iii      13.890    105.0         1994.0   \n",
       "3                     bad-boys-ii      32.121    147.0         2003.0   \n",
       "4                    a-single-man      11.640     97.0         2009.0   \n",
       "\n",
       "   avg_rating  rating_count    embed1    embed2    embed3    embed4  ...  \\\n",
       "0    3.880987           689 -0.094187 -0.114408  0.418668 -0.144036  ...   \n",
       "1    5.953771           411 -0.086850  0.064489  0.214198 -0.293965  ...   \n",
       "2    4.492424           528 -0.032145 -0.175237  0.208410  0.029855  ...   \n",
       "3    6.021593          1343 -0.038505 -0.054682  0.383582 -0.060498  ...   \n",
       "4    7.660256          1404 -0.073496  0.138909  0.320250 -0.425920  ...   \n",
       "\n",
       "   embed759  embed760  embed761  embed762  embed763  embed764  embed765  \\\n",
       "0 -0.187498 -0.141819 -0.393746 -0.264628 -0.284240 -0.228978  0.015331   \n",
       "1  0.012002 -0.181906 -0.124396 -0.409928 -0.073736 -0.344885 -0.287368   \n",
       "2 -0.238653 -0.076611 -0.008018 -0.330764  0.020014  0.104707  0.000675   \n",
       "3 -0.307804 -0.150111  0.084804 -0.491340 -0.114525 -0.111116 -0.300794   \n",
       "4  0.097426 -0.109338  0.002772 -0.556834 -0.202869 -0.185133 -0.144681   \n",
       "\n",
       "   embed766  embed767  embed768  \n",
       "0 -0.244107  0.125971 -0.100652  \n",
       "1  0.009852 -0.013028  0.039776  \n",
       "2 -0.028200  0.138410 -0.228308  \n",
       "3 -0.280891  0.213256 -0.447817  \n",
       "4 -0.042935  0.000639 -0.096624  \n",
       "\n",
       "[5 rows x 774 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tTl4tHL_xoEf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "tTl4tHL_xoEf",
    "outputId": "ef4ebade-638a-4b04-9e50-08ce3b95d6eb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning our data to X\n",
    "X = df_2.drop(['movie_id'], axis=1)\n",
    "\n",
    "# Initialize the NearestNeighbors model\n",
    "#Using cosine distance as distance metric\n",
    "NearestNeighbour = NearestNeighbors(n_neighbors=10, algorithm='auto', metric = 'cosine')\n",
    "\n",
    "# Fit the model to your data\n",
    "NearestNeighbour.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcec1d",
   "metadata": {},
   "source": [
    "## Evaluations for BERT & Numerical Columns\n",
    "\n",
    "Lets see how the the model performs now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4jJlJQQ2QUj",
   "metadata": {
    "id": "d4jJlJQQ2QUj"
   },
   "outputs": [],
   "source": [
    "def similar_movies(df_1, X, NearestNeighbour, movie_id):\n",
    "    \"\"\"\n",
    "    Finds movies similar to a given movie using nearest neighbors.\n",
    "\n",
    "    Parameters:\n",
    "    - movie_df (pandas.DataFrame): DataFrame containing movie details.\n",
    "    - X_scaled (numpy.ndarray): Scaled features of the movies.\n",
    "    - nn_model: Nearest neighbors model trained on the movie features.\n",
    "    - movie_name (str): Name of the movie to find similar movies for.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing details of similar movies.\n",
    "    Columns: 'movie_id', 'genres', 'overview', 'avg_rating', 'rating_count', 'cosine_distance'.\n",
    "    'cosine_distance' represents the cosine distance to the original movie (rounded to 5 decimal places).\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the index of the movie\n",
    "    movie_index = df_1[df_1['movie_id'] == movie_id].index[0]\n",
    "\n",
    "    # Get the features of the movie\n",
    "    input_movie_features = X.loc[[movie_index]]\n",
    "\n",
    "    # Find the nearest neighbors with the provided model\n",
    "    distances, indices = NearestNeighbour.kneighbors(input_movie_features, n_neighbors=10)\n",
    "\n",
    "    # Return the movies that are most similar\n",
    "    sim_movies = df_1.iloc[indices[0]]\n",
    "\n",
    "    # Create a DataFrame containing selected columns\n",
    "    similar_movies = sim_movies[['movie_id', 'genres', 'overview', 'avg_rating', 'rating_count']]\n",
    "\n",
    "    # Add a new column with cosine distance to the original movie (and round to 5 decimal places)\n",
    "    similar_movies['cosine_distance'] = np.round(distances[0], 5)\n",
    "\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5bbcc",
   "metadata": {},
   "source": [
    "Lets once again check how the model performs with Goodfellas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sFrUdP0d3V8l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "id": "sFrUdP0d3V8l",
    "outputId": "21038437-ceb9-4d5d-dbb8-358503851cc3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_26094/1483608306.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>goodfellas</td>\n",
       "      <td>[\"Drama\",\"Crime\"]</td>\n",
       "      <td>The true story of Henry Hill, a half-Irish, ha...</td>\n",
       "      <td>8.858363</td>\n",
       "      <td>4215</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>2001-a-space-odyssey</td>\n",
       "      <td>[\"Science Fiction\",\"Mystery\",\"Adventure\"]</td>\n",
       "      <td>Humanity finds a mysterious object buried bene...</td>\n",
       "      <td>8.931693</td>\n",
       "      <td>4187</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>jaws</td>\n",
       "      <td>[\"Horror\",\"Thriller\",\"Adventure\"]</td>\n",
       "      <td>When an insatiable great white shark terrorize...</td>\n",
       "      <td>8.536173</td>\n",
       "      <td>4202</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>batman-begins</td>\n",
       "      <td>[\"Action\",\"Crime\",\"Drama\"]</td>\n",
       "      <td>Driven by tragedy, billionaire Bruce Wayne ded...</td>\n",
       "      <td>7.393256</td>\n",
       "      <td>4211</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>return-of-the-jedi</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Science Fiction\"]</td>\n",
       "      <td>Luke Skywalker leads a mission to rescue his f...</td>\n",
       "      <td>7.734511</td>\n",
       "      <td>4245</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>no-country-for-old-men</td>\n",
       "      <td>[\"Crime\",\"Drama\",\"Thriller\"]</td>\n",
       "      <td>Llewelyn Moss stumbles upon dead bodies, $2 mi...</td>\n",
       "      <td>8.629499</td>\n",
       "      <td>4251</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4529</th>\n",
       "      <td>blackkklansman</td>\n",
       "      <td>[\"Crime\",\"Drama\",\"History\",\"Comedy\"]</td>\n",
       "      <td>Colorado Springs, late 1970s. Ron Stallworth, ...</td>\n",
       "      <td>7.746531</td>\n",
       "      <td>4324</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>the-shape-of-water</td>\n",
       "      <td>[\"Drama\",\"Fantasy\",\"Romance\"]</td>\n",
       "      <td>An other-worldly story, set against the backdr...</td>\n",
       "      <td>7.641302</td>\n",
       "      <td>4271</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>annihilation</td>\n",
       "      <td>[\"Science Fiction\",\"Horror\"]</td>\n",
       "      <td>A biologist signs up for a dangerous, secret e...</td>\n",
       "      <td>7.419279</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>the-dark-knight-rises</td>\n",
       "      <td>[\"Action\",\"Crime\",\"Drama\",\"Thriller\"]</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>6.876709</td>\n",
       "      <td>4242</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    movie_id                                     genres  \\\n",
       "212               goodfellas                          [\"Drama\",\"Crime\"]   \n",
       "2734    2001-a-space-odyssey  [\"Science Fiction\",\"Mystery\",\"Adventure\"]   \n",
       "2153                    jaws          [\"Horror\",\"Thriller\",\"Adventure\"]   \n",
       "4893           batman-begins                 [\"Action\",\"Crime\",\"Drama\"]   \n",
       "1738      return-of-the-jedi   [\"Adventure\",\"Action\",\"Science Fiction\"]   \n",
       "3262  no-country-for-old-men               [\"Crime\",\"Drama\",\"Thriller\"]   \n",
       "4529          blackkklansman       [\"Crime\",\"Drama\",\"History\",\"Comedy\"]   \n",
       "530       the-shape-of-water              [\"Drama\",\"Fantasy\",\"Romance\"]   \n",
       "4640            annihilation               [\"Science Fiction\",\"Horror\"]   \n",
       "3092   the-dark-knight-rises      [\"Action\",\"Crime\",\"Drama\",\"Thriller\"]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "212   The true story of Henry Hill, a half-Irish, ha...    8.858363   \n",
       "2734  Humanity finds a mysterious object buried bene...    8.931693   \n",
       "2153  When an insatiable great white shark terrorize...    8.536173   \n",
       "4893  Driven by tragedy, billionaire Bruce Wayne ded...    7.393256   \n",
       "1738  Luke Skywalker leads a mission to rescue his f...    7.734511   \n",
       "3262  Llewelyn Moss stumbles upon dead bodies, $2 mi...    8.629499   \n",
       "4529  Colorado Springs, late 1970s. Ron Stallworth, ...    7.746531   \n",
       "530   An other-worldly story, set against the backdr...    7.641302   \n",
       "4640  A biologist signs up for a dangerous, secret e...    7.419279   \n",
       "3092  Following the death of District Attorney Harve...    6.876709   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "212           4215          0.00000  \n",
       "2734          4187          0.00000  \n",
       "2153          4202          0.00001  \n",
       "4893          4211          0.00001  \n",
       "1738          4245          0.00001  \n",
       "3262          4251          0.00001  \n",
       "4529          4324          0.00002  \n",
       "530           4271          0.00002  \n",
       "4640          4274          0.00002  \n",
       "3092          4242          0.00004  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies(df_1, X, NearestNeighbour, 'goodfellas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce123edc",
   "metadata": {},
   "source": [
    "Immediately we can see the model is performing significantly worse when including the numerical columns. \n",
    "\n",
    "We are getting some 'good' highly rated movies now though that we have are including the overall 'high' rating for Goodfellas. However, lets remember the scope for content based reccomendation is to find something similar not neccessarily the best rated movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0d927cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_26094/1483608306.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>raiders-of-the-lost-ark</td>\n",
       "      <td>[\"Adventure\",\"Action\"]</td>\n",
       "      <td>When Dr. Indiana Jones  the tweed-suited prof...</td>\n",
       "      <td>8.481832</td>\n",
       "      <td>3908</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>black-swan</td>\n",
       "      <td>[\"Drama\",\"Thriller\",\"Horror\"]</td>\n",
       "      <td>A journey through the psyche of a young baller...</td>\n",
       "      <td>8.233835</td>\n",
       "      <td>3990</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>the-lobster</td>\n",
       "      <td>[\"Comedy\",\"Drama\",\"Romance\"]</td>\n",
       "      <td>In a dystopian near future, single people, acc...</td>\n",
       "      <td>7.707893</td>\n",
       "      <td>3978</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>hot-fuzz</td>\n",
       "      <td>[\"Crime\",\"Action\",\"Comedy\"]</td>\n",
       "      <td>As a former London constable, Nicholas Angel f...</td>\n",
       "      <td>8.225370</td>\n",
       "      <td>3989</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>star-wars-episode-i-the-phantom-menace</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Science Fiction\"]</td>\n",
       "      <td>Anakin Skywalker, a young slave strong with th...</td>\n",
       "      <td>4.863177</td>\n",
       "      <td>3954</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>memento</td>\n",
       "      <td>[\"Mystery\",\"Thriller\"]</td>\n",
       "      <td>Leonard Shelby is tracking down the man who ra...</td>\n",
       "      <td>8.231520</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>shutter-island</td>\n",
       "      <td>[\"Drama\",\"Thriller\",\"Mystery\"]</td>\n",
       "      <td>World War II soldier-turned-U.S. Marshal Teddy...</td>\n",
       "      <td>7.660970</td>\n",
       "      <td>3979</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>ex-machina-2014</td>\n",
       "      <td>[\"Drama\",\"Science Fiction\"]</td>\n",
       "      <td>Caleb, a coder at the world's largest internet...</td>\n",
       "      <td>8.040278</td>\n",
       "      <td>4022</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>forrest-gump</td>\n",
       "      <td>[\"Comedy\",\"Drama\",\"Romance\"]</td>\n",
       "      <td>A man with a low IQ has accomplished great thi...</td>\n",
       "      <td>7.242766</td>\n",
       "      <td>3905</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>split-2016</td>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>Though Kevin has evidenced 23 personalities to...</td>\n",
       "      <td>6.657855</td>\n",
       "      <td>3972</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    movie_id  \\\n",
       "80                   raiders-of-the-lost-ark   \n",
       "2138                              black-swan   \n",
       "2212                             the-lobster   \n",
       "4552                                hot-fuzz   \n",
       "4225  star-wars-episode-i-the-phantom-menace   \n",
       "4248                                 memento   \n",
       "1330                          shutter-island   \n",
       "4746                         ex-machina-2014   \n",
       "1674                            forrest-gump   \n",
       "1192                              split-2016   \n",
       "\n",
       "                                        genres  \\\n",
       "80                      [\"Adventure\",\"Action\"]   \n",
       "2138             [\"Drama\",\"Thriller\",\"Horror\"]   \n",
       "2212              [\"Comedy\",\"Drama\",\"Romance\"]   \n",
       "4552               [\"Crime\",\"Action\",\"Comedy\"]   \n",
       "4225  [\"Adventure\",\"Action\",\"Science Fiction\"]   \n",
       "4248                    [\"Mystery\",\"Thriller\"]   \n",
       "1330            [\"Drama\",\"Thriller\",\"Mystery\"]   \n",
       "4746               [\"Drama\",\"Science Fiction\"]   \n",
       "1674              [\"Comedy\",\"Drama\",\"Romance\"]   \n",
       "1192                     [\"Horror\",\"Thriller\"]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "80    When Dr. Indiana Jones  the tweed-suited prof...    8.481832   \n",
       "2138  A journey through the psyche of a young baller...    8.233835   \n",
       "2212  In a dystopian near future, single people, acc...    7.707893   \n",
       "4552  As a former London constable, Nicholas Angel f...    8.225370   \n",
       "4225  Anakin Skywalker, a young slave strong with th...    4.863177   \n",
       "4248  Leonard Shelby is tracking down the man who ra...    8.231520   \n",
       "1330  World War II soldier-turned-U.S. Marshal Teddy...    7.660970   \n",
       "4746  Caleb, a coder at the world's largest internet...    8.040278   \n",
       "1674  A man with a low IQ has accomplished great thi...    7.242766   \n",
       "1192  Though Kevin has evidenced 23 personalities to...    6.657855   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "80            3908          0.00000  \n",
       "2138          3990          0.00001  \n",
       "2212          3978          0.00001  \n",
       "4552          3989          0.00001  \n",
       "4225          3954          0.00001  \n",
       "4248          3896          0.00001  \n",
       "1330          3979          0.00002  \n",
       "4746          4022          0.00002  \n",
       "1674          3905          0.00002  \n",
       "1192          3972          0.00003  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies(df_1, X, NearestNeighbour, 'raiders-of-the-lost-ark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d96de4",
   "metadata": {},
   "source": [
    "Definitely worse - we are no longer seeing any other indiana jones movies. Best reccomendation here is probably Star Wars.\n",
    "\n",
    "Lets look at Interstellar again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "419bdfa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_26094/1483608306.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>interstellar</td>\n",
       "      <td>[\"Adventure\",\"Drama\",\"Science Fiction\"]</td>\n",
       "      <td>The adventures of a group of explorers who mak...</td>\n",
       "      <td>7.918451</td>\n",
       "      <td>4905</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>inglourious-basterds</td>\n",
       "      <td>[\"Drama\",\"Action\",\"Thriller\",\"War\"]</td>\n",
       "      <td>In Nazi-occupied France during World War II, a...</td>\n",
       "      <td>8.699797</td>\n",
       "      <td>4930</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>black-panther</td>\n",
       "      <td>[\"Action\",\"Adventure\",\"Science Fiction\"]</td>\n",
       "      <td>King T'Challa returns home to the reclusive, t...</td>\n",
       "      <td>7.069473</td>\n",
       "      <td>4894</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>the-matrix</td>\n",
       "      <td>[\"Action\",\"Science Fiction\"]</td>\n",
       "      <td>Set in the 22nd century, The Matrix tells the ...</td>\n",
       "      <td>8.334081</td>\n",
       "      <td>4903</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>star-wars-the-force-awakens</td>\n",
       "      <td>[\"Action\",\"Adventure\",\"Science Fiction\",\"Fanta...</td>\n",
       "      <td>Thirty years after defeating the Galactic Empi...</td>\n",
       "      <td>7.227872</td>\n",
       "      <td>4858</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>star-wars</td>\n",
       "      <td>[\"Adventure\",\"Action\",\"Science Fiction\"]</td>\n",
       "      <td>Princess Leia is captured and held hostage by ...</td>\n",
       "      <td>8.470662</td>\n",
       "      <td>4789</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>fight-club</td>\n",
       "      <td>[\"Drama\"]</td>\n",
       "      <td>A ticking-time-bomb insomniac and a slippery s...</td>\n",
       "      <td>8.410448</td>\n",
       "      <td>4824</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>mad-max-fury-road</td>\n",
       "      <td>[\"Action\",\"Adventure\",\"Science Fiction\"]</td>\n",
       "      <td>An apocalyptic story set in the furthest reach...</td>\n",
       "      <td>8.638393</td>\n",
       "      <td>4928</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>gone-girl</td>\n",
       "      <td>[\"Mystery\",\"Thriller\",\"Drama\"]</td>\n",
       "      <td>With his wife's disappearance having become th...</td>\n",
       "      <td>8.357028</td>\n",
       "      <td>4994</td>\n",
       "      <td>0.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>midsommar</td>\n",
       "      <td>[\"Horror\",\"Drama\",\"Mystery\"]</td>\n",
       "      <td>Several friends travel to Sweden to study as a...</td>\n",
       "      <td>7.468957</td>\n",
       "      <td>4977</td>\n",
       "      <td>0.00007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         movie_id  \\\n",
       "926                  interstellar   \n",
       "4388         inglourious-basterds   \n",
       "4968                black-panther   \n",
       "2407                   the-matrix   \n",
       "290   star-wars-the-force-awakens   \n",
       "2907                    star-wars   \n",
       "3686                   fight-club   \n",
       "3175            mad-max-fury-road   \n",
       "1964                    gone-girl   \n",
       "2495                    midsommar   \n",
       "\n",
       "                                                 genres  \\\n",
       "926             [\"Adventure\",\"Drama\",\"Science Fiction\"]   \n",
       "4388                [\"Drama\",\"Action\",\"Thriller\",\"War\"]   \n",
       "4968           [\"Action\",\"Adventure\",\"Science Fiction\"]   \n",
       "2407                       [\"Action\",\"Science Fiction\"]   \n",
       "290   [\"Action\",\"Adventure\",\"Science Fiction\",\"Fanta...   \n",
       "2907           [\"Adventure\",\"Action\",\"Science Fiction\"]   \n",
       "3686                                          [\"Drama\"]   \n",
       "3175           [\"Action\",\"Adventure\",\"Science Fiction\"]   \n",
       "1964                     [\"Mystery\",\"Thriller\",\"Drama\"]   \n",
       "2495                       [\"Horror\",\"Drama\",\"Mystery\"]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "926   The adventures of a group of explorers who mak...    7.918451   \n",
       "4388  In Nazi-occupied France during World War II, a...    8.699797   \n",
       "4968  King T'Challa returns home to the reclusive, t...    7.069473   \n",
       "2407  Set in the 22nd century, The Matrix tells the ...    8.334081   \n",
       "290   Thirty years after defeating the Galactic Empi...    7.227872   \n",
       "2907  Princess Leia is captured and held hostage by ...    8.470662   \n",
       "3686  A ticking-time-bomb insomniac and a slippery s...    8.410448   \n",
       "3175  An apocalyptic story set in the furthest reach...    8.638393   \n",
       "1964  With his wife's disappearance having become th...    8.357028   \n",
       "2495  Several friends travel to Sweden to study as a...    7.468957   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "926           4905          0.00000  \n",
       "4388          4930          0.00001  \n",
       "4968          4894          0.00003  \n",
       "2407          4903          0.00003  \n",
       "290           4858          0.00004  \n",
       "2907          4789          0.00005  \n",
       "3686          4824          0.00006  \n",
       "3175          4928          0.00006  \n",
       "1964          4994          0.00007  \n",
       "2495          4977          0.00007  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies(df_1, X, NearestNeighbour, 'interstellar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f95f19",
   "metadata": {},
   "source": [
    "I think we can safely assume that with the way we are currently handling the numerical data, when we train the model on just the BERT embeddings we are getting significantly more similar movies.\n",
    "\n",
    "**Note:** We did not scale our numerical data and there is certainly a chance to toy around with scale and add some weighting that would tweak the model. However for scope of the project we will go with the assumption that our embedding alone will perform the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J_JUcBZBJfpI",
   "metadata": {
    "id": "J_JUcBZBJfpI"
   },
   "source": [
    "# Hugging Face Content Reccomender Insights\n",
    "Our recommender is performing better at finding similar movies with just the BERT word embeddings as features than also including our other original features.\n",
    "\n",
    "We used BERT for our first run at word embedding, lets try using Generative Pre-Train Transformer-2 (GPT-2). We will also look at doing the same thing with GPT so we can comapre and contrast the transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pBRoE5ylJiRs",
   "metadata": {
    "id": "pBRoE5ylJiRs"
   },
   "source": [
    "# GPT Based Model\n",
    "Now lets check out what using the GPT pre-trained model will yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "zFpc4sh7Ltcy",
   "metadata": {
    "id": "zFpc4sh7Ltcy"
   },
   "outputs": [],
   "source": [
    "df_for_gpt = df_1.iloc[:, :8].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "uaj3P3lJL5Q_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "uaj3P3lJL5Q_",
    "outputId": "b01c1401-eca7-433c-82fa-ae5ab5bb3d5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id  \\\n",
       "0  house-at-the-end-of-the-street   \n",
       "1          green-street-hooligans   \n",
       "2           beverly-hills-cop-iii   \n",
       "3                     bad-boys-ii   \n",
       "4                    a-single-man   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  \n",
       "0         2012.0    3.880987           689  \n",
       "1         2005.0    5.953771           411  \n",
       "2         1994.0    4.492424           528  \n",
       "3         2003.0    6.021593          1343  \n",
       "4         2009.0    7.660256          1404  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47LIaCGyKR7i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "1c7a0e282fea489f8298004000f1b804",
      "835a9e8fdb4e4fcb864ed7edba2e0a99",
      "0aeed3cfc49c49aea697fb38af187228",
      "ba030df2970e472eacc4629dfcebf567",
      "f3e28ffffa1141e2b1cd82ee3ded8635",
      "0ceb8faa61ba490ebb9afd366c962ffd",
      "0b3f2f83e8354f988321f11ef8ce396c",
      "abb60c9c134549489fcdd94edd75a9e7",
      "da9c43f2b1914214928a074d1d4eb232",
      "94f23f4c065645b1aba999af816adaa7",
      "de2dc60febfd4a4fb50fcf69d9b76168",
      "4ee2039250574c9dac5c811abecdedd3",
      "221df80acb4f45a9a61d0bbf49304348",
      "ddbf1e8ed3314cca842c37312dc702ee",
      "fbec5cc6ce7742688d9bf46fe8f78576",
      "b7daf8cf1b1447a3a54b64fb357cbf91",
      "9f7597e059bd4d97a68566245e375160",
      "a1f006322f2c4ad7b803ac032360c2ed",
      "744b94435cdd4f96b7bc9f51d30ea73c",
      "b1d83eef0d3846db8bad51643103fd71",
      "17b0e41c4b97468eb6ae844053facf59",
      "385edbca35a242d2b455263cf09ca71e",
      "a8cc96e980804af89f003635fe4c345f",
      "62ab81ef96434b5b9f7fccf0939a3a73",
      "44660d24f76244c2b0e3e55ded179519",
      "97d1ded4b6a94f9ea94f22c30fd547ec",
      "6aaac8fe66564d13900f7a640d697642",
      "4ab3e3584a68400ca3734c623857552a",
      "62a30695146a410d8d2d216e4fa5d493",
      "08bc8b6ca63e461197c16e14c3abcde8",
      "7bb99f3a63ae476392c9240c78e6a31d",
      "f2d0e81619b1455fa775701f5aa2fe47",
      "9452a16256454e99bf8e798104474b19",
      "167f54dc8ef64eb3b8117ddb7fb478a7",
      "92fd2292ef8b4e7ca9633f43c251fec2",
      "fa72f8c89c26461bbf7d1d1be938b510",
      "5f681bbf68984d8188f7277a6f42f641",
      "995ca7336ae84f3d9100ddc796d0f8a4",
      "d7ddf904b90044e9b15edeeabcb683fc",
      "8d7c979613214d259d1243000543ee8a",
      "212df07f193e4bfc8d40d2137594734c",
      "a6b10bb9ea7f4660a85f1f929fdaf809",
      "75830bb99e9a4b17b7dc173354d7719b",
      "b071f3f5b9684aa58f32fdb790c9ccf4",
      "58ced02798ba4a4bb439242d78da2e4e",
      "812a59a982ed4b18b989c4554d5e0255",
      "5ca725e476cf4463a71928f3514439b4",
      "48f36f906a714a38a0bf8895c02f4b01",
      "31b3ee1d5fe84d53bb077bcba7353254",
      "1c163bf0117a44aaa7c7cc9db8664375",
      "683914a18dfe44c9b527be5d15c7889f",
      "a9c39881a615487fbe597e5d39066ccb",
      "bc30697d347f477685a58e6ca9dbd734",
      "c3aa7567016346b58396a718195819fa",
      "2ad777be710744d59bef328dcb788146"
     ]
    },
    "id": "47LIaCGyKR7i",
    "outputId": "752a37dc-7774-4621-b345-3aec159cebb3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1042301/1042301 [00:00<00:00, 2358029.24B/s]\n",
      "100%|| 456318/456318 [00:00<00:00, 1519205.74B/s]\n",
      "100%|| 665/665 [00:00<00:00, 2381906.20B/s]\n",
      "100%|| 548118077/548118077 [00:17<00:00, 31250080.70B/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m GPT2Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 7\u001b[0m gpt_model \u001b[38;5;241m=\u001b[39m GPT2Model\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Tokenize and obtain GPT-2 embeddings for the 'overview' column\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gpt_embeddings\u001b[39m(text):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:318\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# redirect to the cache, if necessary\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_path(archive_file, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, force_download\u001b[38;5;241m=\u001b[39mforce_download, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_model_archive_map:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/file_utils.py:176\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies)\u001b[0m\n\u001b[1;32m    172\u001b[0m parsed \u001b[38;5;241m=\u001b[39m urlparse(url_or_filename)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_from_cache(url_or_filename, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, force_download\u001b[38;5;241m=\u001b[39mforce_download, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m url_or_filename\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/file_utils.py:295\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies)\u001b[0m\n\u001b[1;32m    290\u001b[0m         cache_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cache_dir, matching_files[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_path) \u001b[38;5;129;01mor\u001b[39;00m force_download:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# Download to temporary file, then copy to cache dir once finished.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# Otherwise you get corrupt cache entries if the download gets interrupted.\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile() \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n\u001b[1;32m    296\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not found in cache or force_download set to True, downloading to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, temp_file\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;66;03m# GET file object\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/tempfile.py:502\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.__exit__\u001b[0;34m(self, exc, value, tb)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc, value, tb):\n\u001b[1;32m    501\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(exc, value, tb)\n\u001b[0;32m--> 502\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/tempfile.py:509\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m    Close the temporary file, possibly deleting it.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closer\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/tempfile.py:446\u001b[0m, in \u001b[0;36m_TemporaryFileCloser.close\u001b[0;34m(self, unlink)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete:\n\u001b[0;32m--> 446\u001b[0m         unlink(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "gpt_model = GPT2Model.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize and obtain GPT-2 embeddings for the 'overview' column\n",
    "def get_gpt_embeddings(text):\n",
    "    \"\"\"\n",
    "    Get GPT-2 embeddings for the given text.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): Input text to generate GPT-2 embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - embeddings (numpy.ndarray): GPT-2 embeddings for the input text.\n",
    "\n",
    "    This function tokenizes the input text using a pre-trained GPT-2 tokenizer,\n",
    "    encodes it into tokens as PyTorch tensors, and passes them through a pre-trained\n",
    "    GPT-2 model to obtain embeddings. The obtained embeddings represent a fixed-size\n",
    "    numerical representation of the input text based on the learned patterns from the\n",
    "    pre-trained GPT-2 model. These embeddings are returned as a NumPy array for\n",
    "    further processing or analysis.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = gpt_model(tokens)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1) #the mean will condense the context information into a a single represenation\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Apply GPT-2 embeddings to the 'overview' column\n",
    "df_for_gpt['overview_embeddings'] = df_for_gpt['overview'].apply(get_gpt_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OFO8XI1hV2xP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "OFO8XI1hV2xP",
    "outputId": "f0c96a4b-bd6e-4aab-f067-9f5da2cec95a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2bc159f2-bb3a-4dbc-9bab-731f628742aa\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>overview_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "      <td>[[-0.09036886, 0.20265284, -0.47483757, -0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "      <td>[[-0.18209746, 0.08724547, -0.32389313, -0.128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "      <td>[[-0.21388283, -0.028339628, -0.11678762, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "      <td>[[-0.2679748, 0.15028058, 0.026118562, -0.0184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "      <td>[[-0.0611344, -0.042883042, -0.57777846, 0.044...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bc159f2-bb3a-4dbc-9bab-731f628742aa')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2bc159f2-bb3a-4dbc-9bab-731f628742aa button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2bc159f2-bb3a-4dbc-9bab-731f628742aa');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-622c554f-1bbe-4450-bbcd-e0039ebcf58c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-622c554f-1bbe-4450-bbcd-e0039ebcf58c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-622c554f-1bbe-4450-bbcd-e0039ebcf58c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id  \\\n",
       "0  house-at-the-end-of-the-street   \n",
       "1          green-street-hooligans   \n",
       "2           beverly-hills-cop-iii   \n",
       "3                     bad-boys-ii   \n",
       "4                    a-single-man   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  \\\n",
       "0         2012.0    3.880987           689   \n",
       "1         2005.0    5.953771           411   \n",
       "2         1994.0    4.492424           528   \n",
       "3         2003.0    6.021593          1343   \n",
       "4         2009.0    7.660256          1404   \n",
       "\n",
       "                                 overview_embeddings  \n",
       "0  [[-0.09036886, 0.20265284, -0.47483757, -0.029...  \n",
       "1  [[-0.18209746, 0.08724547, -0.32389313, -0.128...  \n",
       "2  [[-0.21388283, -0.028339628, -0.11678762, 0.09...  \n",
       "3  [[-0.2679748, 0.15028058, 0.026118562, -0.0184...  \n",
       "4  [[-0.0611344, -0.042883042, -0.57777846, 0.044...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "df_for_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miABEyv3VbN7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miABEyv3VbN7",
    "outputId": "d02708e2-570b-420a-ba58-9cb0c04830e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5061,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape of the entire 'overview_embeddings' column in the DataFrame\n",
    "df_for_gpt['overview_embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PCQdZ7y-YQ0j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCQdZ7y-YQ0j",
    "outputId": "06e3f996-2a64-4539-a638-6233ab006a8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape of the first row embeddings\n",
    "df_for_gpt['overview_embeddings'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KfiaxRMkYcs2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfiaxRMkYcs2",
    "outputId": "74862a40-c0f1-4fa0-800d-6df2a659006a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape of the second row embeddings\n",
    "df_for_gpt['overview_embeddings'][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wkxo8A5EWZ03",
   "metadata": {
    "id": "wkxo8A5EWZ03"
   },
   "source": [
    "Lets split the array containing our embedding out into their own column associated with the move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M0p0IkMqV3JQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M0p0IkMqV3JQ",
    "outputId": "c980b99b-af81-4d88-d37b-2363745e88d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n",
      "<ipython-input-75-25be2477699f>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtain the number of columns in the embedding array\n",
    "num_columns = df_for_gpt['overview_embeddings'][0].shape[1]\n",
    "\n",
    "# Create column names for the new columns\n",
    "new_columns = [f'gpt_embed{i+1}' for i in range(num_columns)]\n",
    "\n",
    "# Apply the split_array function to each row and assign the results to new columns\n",
    "df_for_gpt[new_columns] = df_for_gpt.apply(split_array, axis=1) #We defined split_array when doing this for the BERT model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dT2flasMZjxT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "dT2flasMZjxT",
    "outputId": "0ae1712e-b842-423b-a0f4-3cac731b179e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e4f625c3-cad0-4149-8349-460f45a4d2c5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>year_released</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>overview_embeddings</th>\n",
       "      <th>gpt_embed1</th>\n",
       "      <th>...</th>\n",
       "      <th>gpt_embed759</th>\n",
       "      <th>gpt_embed760</th>\n",
       "      <th>gpt_embed761</th>\n",
       "      <th>gpt_embed762</th>\n",
       "      <th>gpt_embed763</th>\n",
       "      <th>gpt_embed764</th>\n",
       "      <th>gpt_embed765</th>\n",
       "      <th>gpt_embed766</th>\n",
       "      <th>gpt_embed767</th>\n",
       "      <th>gpt_embed768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Horror\",\"Thriller\"]</td>\n",
       "      <td>house-at-the-end-of-the-street</td>\n",
       "      <td>A mother and daughter move to a new town and f...</td>\n",
       "      <td>11.088</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.880987</td>\n",
       "      <td>689</td>\n",
       "      <td>[[-0.09036886, 0.20265284, -0.47483757, -0.029...</td>\n",
       "      <td>-0.090369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193471</td>\n",
       "      <td>0.230882</td>\n",
       "      <td>0.096881</td>\n",
       "      <td>-0.034911</td>\n",
       "      <td>3.502983</td>\n",
       "      <td>-0.366724</td>\n",
       "      <td>-0.047527</td>\n",
       "      <td>-0.051946</td>\n",
       "      <td>0.157661</td>\n",
       "      <td>0.060185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"Crime\",\"Drama\"]</td>\n",
       "      <td>green-street-hooligans</td>\n",
       "      <td>After being wrongfully expelled from Harvard U...</td>\n",
       "      <td>14.690</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>5.953771</td>\n",
       "      <td>411</td>\n",
       "      <td>[[-0.18209746, 0.08724547, -0.32389313, -0.128...</td>\n",
       "      <td>-0.182097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274197</td>\n",
       "      <td>0.236360</td>\n",
       "      <td>0.218912</td>\n",
       "      <td>0.121857</td>\n",
       "      <td>3.173552</td>\n",
       "      <td>-0.077218</td>\n",
       "      <td>-0.052325</td>\n",
       "      <td>-0.129946</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.033552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"Action\",\"Comedy\",\"Crime\"]</td>\n",
       "      <td>beverly-hills-cop-iii</td>\n",
       "      <td>Back in sunny southern California and on the t...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>4.492424</td>\n",
       "      <td>528</td>\n",
       "      <td>[[-0.21388283, -0.028339628, -0.11678762, 0.09...</td>\n",
       "      <td>-0.213883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011604</td>\n",
       "      <td>-0.065188</td>\n",
       "      <td>-0.105765</td>\n",
       "      <td>0.054851</td>\n",
       "      <td>1.803978</td>\n",
       "      <td>-0.182196</td>\n",
       "      <td>-0.106862</td>\n",
       "      <td>-0.087162</td>\n",
       "      <td>-0.047632</td>\n",
       "      <td>-0.219411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...</td>\n",
       "      <td>bad-boys-ii</td>\n",
       "      <td>Out-of-control, trash-talking buddy cops Marcu...</td>\n",
       "      <td>32.121</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>6.021593</td>\n",
       "      <td>1343</td>\n",
       "      <td>[[-0.2679748, 0.15028058, 0.026118562, -0.0184...</td>\n",
       "      <td>-0.267975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145959</td>\n",
       "      <td>0.178233</td>\n",
       "      <td>0.011197</td>\n",
       "      <td>-0.153843</td>\n",
       "      <td>1.640131</td>\n",
       "      <td>-0.180906</td>\n",
       "      <td>-0.034100</td>\n",
       "      <td>-0.034205</td>\n",
       "      <td>0.046168</td>\n",
       "      <td>0.062116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>a-single-man</td>\n",
       "      <td>The life of George Falconer, a British college...</td>\n",
       "      <td>11.640</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.660256</td>\n",
       "      <td>1404</td>\n",
       "      <td>[[-0.0611344, -0.042883042, -0.57777846, 0.044...</td>\n",
       "      <td>-0.061134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124483</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.147079</td>\n",
       "      <td>0.113641</td>\n",
       "      <td>4.649726</td>\n",
       "      <td>-0.115314</td>\n",
       "      <td>-0.153491</td>\n",
       "      <td>-0.099130</td>\n",
       "      <td>0.032001</td>\n",
       "      <td>-0.158277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  777 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4f625c3-cad0-4149-8349-460f45a4d2c5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e4f625c3-cad0-4149-8349-460f45a4d2c5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e4f625c3-cad0-4149-8349-460f45a4d2c5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-825d739b-6af2-4af6-82a5-23493293a6ab\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-825d739b-6af2-4af6-82a5-23493293a6ab')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-825d739b-6af2-4af6-82a5-23493293a6ab button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                              genres  \\\n",
       "0                              [\"Horror\",\"Thriller\"]   \n",
       "1                                  [\"Crime\",\"Drama\"]   \n",
       "2                        [\"Action\",\"Comedy\",\"Crime\"]   \n",
       "3  [\"Adventure\",\"Action\",\"Comedy\",\"Thriller\",\"Cri...   \n",
       "4                                [\"Romance\",\"Drama\"]   \n",
       "\n",
       "                         movie_id  \\\n",
       "0  house-at-the-end-of-the-street   \n",
       "1          green-street-hooligans   \n",
       "2           beverly-hills-cop-iii   \n",
       "3                     bad-boys-ii   \n",
       "4                    a-single-man   \n",
       "\n",
       "                                            overview  popularity  runtime  \\\n",
       "0  A mother and daughter move to a new town and f...      11.088    101.0   \n",
       "1  After being wrongfully expelled from Harvard U...      14.690    109.0   \n",
       "2  Back in sunny southern California and on the t...      13.890    105.0   \n",
       "3  Out-of-control, trash-talking buddy cops Marcu...      32.121    147.0   \n",
       "4  The life of George Falconer, a British college...      11.640     97.0   \n",
       "\n",
       "   year_released  avg_rating  rating_count  \\\n",
       "0         2012.0    3.880987           689   \n",
       "1         2005.0    5.953771           411   \n",
       "2         1994.0    4.492424           528   \n",
       "3         2003.0    6.021593          1343   \n",
       "4         2009.0    7.660256          1404   \n",
       "\n",
       "                                 overview_embeddings  gpt_embed1  ...  \\\n",
       "0  [[-0.09036886, 0.20265284, -0.47483757, -0.029...   -0.090369  ...   \n",
       "1  [[-0.18209746, 0.08724547, -0.32389313, -0.128...   -0.182097  ...   \n",
       "2  [[-0.21388283, -0.028339628, -0.11678762, 0.09...   -0.213883  ...   \n",
       "3  [[-0.2679748, 0.15028058, 0.026118562, -0.0184...   -0.267975  ...   \n",
       "4  [[-0.0611344, -0.042883042, -0.57777846, 0.044...   -0.061134  ...   \n",
       "\n",
       "   gpt_embed759  gpt_embed760  gpt_embed761  gpt_embed762  gpt_embed763  \\\n",
       "0      0.193471      0.230882      0.096881     -0.034911      3.502983   \n",
       "1      0.274197      0.236360      0.218912      0.121857      3.173552   \n",
       "2     -0.011604     -0.065188     -0.105765      0.054851      1.803978   \n",
       "3      0.145959      0.178233      0.011197     -0.153843      1.640131   \n",
       "4     -0.124483      0.357500      0.147079      0.113641      4.649726   \n",
       "\n",
       "   gpt_embed764  gpt_embed765  gpt_embed766  gpt_embed767  gpt_embed768  \n",
       "0     -0.366724     -0.047527     -0.051946      0.157661      0.060185  \n",
       "1     -0.077218     -0.052325     -0.129946      0.005951      0.033552  \n",
       "2     -0.182196     -0.106862     -0.087162     -0.047632     -0.219411  \n",
       "3     -0.180906     -0.034100     -0.034205      0.046168      0.062116  \n",
       "4     -0.115314     -0.153491     -0.099130      0.032001     -0.158277  \n",
       "\n",
       "[5 rows x 777 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "df_for_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ld8uL8IBZqnz",
   "metadata": {
    "id": "ld8uL8IBZqnz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Wbec3Ef2ZyNb",
   "metadata": {
    "id": "Wbec3Ef2ZyNb"
   },
   "source": [
    "Sweet! Looks good to go, before we run Nearest Neighbours on this lets save this df as a csv so we can easily upload it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vWhOQ4fxbuEa",
   "metadata": {
    "id": "vWhOQ4fxbuEa"
   },
   "outputs": [],
   "source": [
    "#saving into CSV\n",
    "df_for_gpt.to_csv('data/gpt_embeddings_df_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc78f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data back\n",
    "df_for_gpt = pd.read_csv('data/gpt_embeddings_df_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15hck4VdZ8Z",
   "metadata": {
    "id": "b15hck4VdZ8Z"
   },
   "source": [
    "## Modelling with GPT\n",
    "Now lets run our nearest neighbour model on our GPT embeddings.\n",
    "\n",
    "First, drop the non embedding columns so we van evaluate in isolation. It perfomred better in isolation with BERT anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58Iv9OTIWIvl",
   "metadata": {
    "id": "58Iv9OTIWIvl"
   },
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['genres', 'overview','overview_embeddings', 'runtime', 'popularity', 'year_released', 'avg_rating', 'rating_count']\n",
    "\n",
    "# Create a copy of df_1 and drop the specified columns\n",
    "df_GPT_only_embed = df_for_gpt.drop(columns=columns_to_drop).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "uK8vKioHfAKT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "uK8vKioHfAKT",
    "outputId": "30df87b1-1922-4024-d2bf-154b9a53bee4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gpt = df_GPT_only_embed.drop(['movie_id'], axis=1)\n",
    "\n",
    "# Initialize the NearestNeighbors model\n",
    "#Using cosine distance as distance metric\n",
    "NN_gpt = NearestNeighbors(n_neighbors=10, algorithm='auto', metric = 'cosine')\n",
    "\n",
    "# Fit the model to your data\n",
    "NN_gpt.fit(X_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "N1kbA4pUffIV",
   "metadata": {
    "id": "N1kbA4pUffIV"
   },
   "outputs": [],
   "source": [
    "def GPT_similar_movies(df_for_gpt, X_gpt, NN_gpt, movie_id):\n",
    "    \"\"\"\n",
    "    Finds movies similar to a given movie using nearest neighbors.\n",
    "\n",
    "    Parameters:\n",
    "    - movie_df (pandas.DataFrame): DataFrame containing movie details.\n",
    "    - X_scaled (numpy.ndarray): Scaled features of the movies.\n",
    "    - nn_model: Nearest neighbors model trained on the movie features.\n",
    "    - movie_name (str): Name of the movie to find similar movies for.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing details of similar movies.\n",
    "    Columns: 'movie_id', 'genres', 'overview', 'avg_rating', 'rating_count', 'cosine_distance'.\n",
    "    'cosine_distance' represents the cosine distance to the original movie (rounded to 5 decimal places).\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the index of the movie\n",
    "    movie_index = df_for_gpt[df_for_gpt['movie_id'] == movie_id].index[0]\n",
    "\n",
    "    # Get the features of the movie\n",
    "    input_movie_features = X_gpt.loc[[movie_index]]\n",
    "\n",
    "    # Find the nearest neighbors with the provided model\n",
    "    distances, indices = NN_gpt.kneighbors(input_movie_features, n_neighbors=10)\n",
    "\n",
    "    # Return the movies that are most similar\n",
    "    sim_movies = df_for_gpt.iloc[indices[0]]\n",
    "\n",
    "    # Create a DataFrame containing selected columns\n",
    "    similar_movies = sim_movies[['movie_id', 'genres', 'overview', 'avg_rating', 'rating_count']]\n",
    "\n",
    "    # Add a new column with cosine distance to the original movie (and round to 5 decimal places)\n",
    "    similar_movies['cosine_distance'] = np.round(distances[0], 5)\n",
    "\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea777f2e",
   "metadata": {},
   "source": [
    "## GPT Evaluation\n",
    "Lets look back into our movies and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ikbESdYvgPUb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "ikbESdYvgPUb",
    "outputId": "cfd39bac-02ae-420d-d3c7-a3b9bad463bd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_26094/1533068803.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>goodfellas</td>\n",
       "      <td>[\"Drama\",\"Crime\"]</td>\n",
       "      <td>The true story of Henry Hill, a half-Irish, ha...</td>\n",
       "      <td>8.858363</td>\n",
       "      <td>4215</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>devil-in-a-blue-dress</td>\n",
       "      <td>[\"Thriller\",\"Crime\",\"Drama\",\"Mystery\"]</td>\n",
       "      <td>In late 1940s Los Angeles, Easy Rawlins is an ...</td>\n",
       "      <td>7.334545</td>\n",
       "      <td>550</td>\n",
       "      <td>0.00034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>black-dynamite</td>\n",
       "      <td>[\"Comedy\",\"Action\"]</td>\n",
       "      <td>This is the story of 1970s African-American ac...</td>\n",
       "      <td>7.629000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.00034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>the-godfather</td>\n",
       "      <td>[\"Drama\",\"Crime\"]</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>9.052349</td>\n",
       "      <td>4279</td>\n",
       "      <td>0.00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>american-ultra</td>\n",
       "      <td>[\"Comedy\",\"Action\"]</td>\n",
       "      <td>Mike is an unmotivated stoner whose small-town...</td>\n",
       "      <td>5.590164</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.00038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>wake-in-fright</td>\n",
       "      <td>[\"Drama\",\"Thriller\"]</td>\n",
       "      <td>Wake in Fright is the story of John Grant, a b...</td>\n",
       "      <td>7.988095</td>\n",
       "      <td>840</td>\n",
       "      <td>0.00039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>the-long-day-closes</td>\n",
       "      <td>[\"Drama\"]</td>\n",
       "      <td>Set in Kensington, a working-class district of...</td>\n",
       "      <td>8.274047</td>\n",
       "      <td>551</td>\n",
       "      <td>0.00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>the-last-black-man-in-san-francisco</td>\n",
       "      <td>[\"Drama\"]</td>\n",
       "      <td>Jimmie Fails dreams of reclaiming the Victoria...</td>\n",
       "      <td>7.801729</td>\n",
       "      <td>1851</td>\n",
       "      <td>0.00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>kingpin</td>\n",
       "      <td>[\"Comedy\"]</td>\n",
       "      <td>After bowler Roy Munson swindles the wrong cro...</td>\n",
       "      <td>6.420000</td>\n",
       "      <td>700</td>\n",
       "      <td>0.00041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>the-foreigner-2017</td>\n",
       "      <td>[\"Action\",\"Thriller\"]</td>\n",
       "      <td>Quan is a humble London businessman whose long...</td>\n",
       "      <td>6.018116</td>\n",
       "      <td>828</td>\n",
       "      <td>0.00041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 movie_id  \\\n",
       "212                            goodfellas   \n",
       "699                 devil-in-a-blue-dress   \n",
       "3020                       black-dynamite   \n",
       "3151                        the-godfather   \n",
       "829                        american-ultra   \n",
       "2702                       wake-in-fright   \n",
       "1809                  the-long-day-closes   \n",
       "1917  the-last-black-man-in-san-francisco   \n",
       "4787                              kingpin   \n",
       "3878                   the-foreigner-2017   \n",
       "\n",
       "                                      genres  \\\n",
       "212                        [\"Drama\",\"Crime\"]   \n",
       "699   [\"Thriller\",\"Crime\",\"Drama\",\"Mystery\"]   \n",
       "3020                     [\"Comedy\",\"Action\"]   \n",
       "3151                       [\"Drama\",\"Crime\"]   \n",
       "829                      [\"Comedy\",\"Action\"]   \n",
       "2702                    [\"Drama\",\"Thriller\"]   \n",
       "1809                               [\"Drama\"]   \n",
       "1917                               [\"Drama\"]   \n",
       "4787                              [\"Comedy\"]   \n",
       "3878                   [\"Action\",\"Thriller\"]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "212   The true story of Henry Hill, a half-Irish, ha...    8.858363   \n",
       "699   In late 1940s Los Angeles, Easy Rawlins is an ...    7.334545   \n",
       "3020  This is the story of 1970s African-American ac...    7.629000   \n",
       "3151  Spanning the years 1945 to 1955, a chronicle o...    9.052349   \n",
       "829   Mike is an unmotivated stoner whose small-town...    5.590164   \n",
       "2702  Wake in Fright is the story of John Grant, a b...    7.988095   \n",
       "1809  Set in Kensington, a working-class district of...    8.274047   \n",
       "1917  Jimmie Fails dreams of reclaiming the Victoria...    7.801729   \n",
       "4787  After bowler Roy Munson swindles the wrong cro...    6.420000   \n",
       "3878  Quan is a humble London businessman whose long...    6.018116   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "212           4215          0.00000  \n",
       "699            550          0.00034  \n",
       "3020          1000          0.00034  \n",
       "3151          4279          0.00037  \n",
       "829           1281          0.00038  \n",
       "2702           840          0.00039  \n",
       "1809           551          0.00040  \n",
       "1917          1851          0.00040  \n",
       "4787           700          0.00041  \n",
       "3878           828          0.00041  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_similar_movies(df_for_gpt, X_gpt, NN_gpt, 'goodfellas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHEQY7DTnrEu",
   "metadata": {
    "id": "nHEQY7DTnrEu"
   },
   "source": [
    "Good reccomendations:\n",
    "* The Godfather\n",
    "* Devil in a Blue Dress \n",
    "\n",
    "Okay Reccomendations:\n",
    "* Black Dynamite \n",
    "\n",
    "Bad Reccomendations: \n",
    "* The Last Black Man in San Francisco\n",
    "* American Ultra\n",
    "\n",
    "\n",
    "Initially we can see GPT2 does not look to be performing as well as BERT - we can remember that goodfellas suggested all pretty similar maffia/mob crime movies.\n",
    "\n",
    "Look at movie descriptions of american ultra and goodfellas we can see how the comparison was drawn. Both include government agent and escape but the model doesnt seem to be understanding context quite as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "don19oXTniHV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 976
    },
    "id": "don19oXTniHV",
    "outputId": "12a57414-2102-44b3-c953-a92ae27f5cc3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/khpbl2351cn5d9k4dq8zj0x40000gn/T/ipykernel_26094/1533068803.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_movies['cosine_distance'] = np.round(distances[0], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>raiders-of-the-lost-ark</td>\n",
       "      <td>[\"Adventure\",\"Action\"]</td>\n",
       "      <td>When Dr. Indiana Jones  the tweed-suited prof...</td>\n",
       "      <td>8.481832</td>\n",
       "      <td>3908</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>oz-the-great-and-powerful</td>\n",
       "      <td>[\"Fantasy\",\"Adventure\",\"Family\"]</td>\n",
       "      <td>Oscar Diggs, a small-time circus illusionist a...</td>\n",
       "      <td>4.867397</td>\n",
       "      <td>1644</td>\n",
       "      <td>0.00034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>king-kong-2005</td>\n",
       "      <td>[\"Adventure\",\"Drama\",\"Action\"]</td>\n",
       "      <td>In 1933 New York, an overly ambitious movie pr...</td>\n",
       "      <td>6.616856</td>\n",
       "      <td>2195</td>\n",
       "      <td>0.00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>the-bourne-ultimatum</td>\n",
       "      <td>[\"Action\",\"Drama\",\"Mystery\",\"Thriller\"]</td>\n",
       "      <td>Bourne is brought out of hiding once again by ...</td>\n",
       "      <td>7.303784</td>\n",
       "      <td>1850</td>\n",
       "      <td>0.00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>lara-croft-tomb-raider-the-cradle-of-life</td>\n",
       "      <td>[\"Action\",\"Adventure\",\"Fantasy\",\"Thriller\"]</td>\n",
       "      <td>Lara Croft ventures to an underwater temple in...</td>\n",
       "      <td>4.088859</td>\n",
       "      <td>754</td>\n",
       "      <td>0.00039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>a-shaun-the-sheep-movie-farmageddon</td>\n",
       "      <td>[\"Comedy\",\"Animation\",\"Family\"]</td>\n",
       "      <td>When an alien with amazing powers crash-lands ...</td>\n",
       "      <td>6.557123</td>\n",
       "      <td>709</td>\n",
       "      <td>0.00039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>die-hard-with-a-vengeance</td>\n",
       "      <td>[\"Action\",\"Thriller\"]</td>\n",
       "      <td>New York detective John McClane is back and ki...</td>\n",
       "      <td>7.320188</td>\n",
       "      <td>1699</td>\n",
       "      <td>0.00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>madagascar-3-europes-most-wanted</td>\n",
       "      <td>[\"Animation\",\"Family\",\"Comedy\",\"Adventure\"]</td>\n",
       "      <td>Animal pals Alex, Marty, Melman, and Gloria ar...</td>\n",
       "      <td>5.260902</td>\n",
       "      <td>1330</td>\n",
       "      <td>0.00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>scooby-doo-on-zombie-island</td>\n",
       "      <td>[\"Animation\",\"Comedy\",\"Family\",\"Mystery\",\"Adve...</td>\n",
       "      <td>The Mystery Gang reunite and visit Moonscar Is...</td>\n",
       "      <td>7.123249</td>\n",
       "      <td>714</td>\n",
       "      <td>0.00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>ant-man</td>\n",
       "      <td>[\"Science Fiction\",\"Action\",\"Adventure\"]</td>\n",
       "      <td>Armed with the astonishing ability to shrink i...</td>\n",
       "      <td>6.396859</td>\n",
       "      <td>4266</td>\n",
       "      <td>0.00041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       movie_id  \\\n",
       "80                      raiders-of-the-lost-ark   \n",
       "2291                  oz-the-great-and-powerful   \n",
       "254                              king-kong-2005   \n",
       "129                        the-bourne-ultimatum   \n",
       "2400  lara-croft-tomb-raider-the-cradle-of-life   \n",
       "4888        a-shaun-the-sheep-movie-farmageddon   \n",
       "2585                  die-hard-with-a-vengeance   \n",
       "2859           madagascar-3-europes-most-wanted   \n",
       "3257                scooby-doo-on-zombie-island   \n",
       "3731                                    ant-man   \n",
       "\n",
       "                                                 genres  \\\n",
       "80                               [\"Adventure\",\"Action\"]   \n",
       "2291                   [\"Fantasy\",\"Adventure\",\"Family\"]   \n",
       "254                      [\"Adventure\",\"Drama\",\"Action\"]   \n",
       "129             [\"Action\",\"Drama\",\"Mystery\",\"Thriller\"]   \n",
       "2400        [\"Action\",\"Adventure\",\"Fantasy\",\"Thriller\"]   \n",
       "4888                    [\"Comedy\",\"Animation\",\"Family\"]   \n",
       "2585                              [\"Action\",\"Thriller\"]   \n",
       "2859        [\"Animation\",\"Family\",\"Comedy\",\"Adventure\"]   \n",
       "3257  [\"Animation\",\"Comedy\",\"Family\",\"Mystery\",\"Adve...   \n",
       "3731           [\"Science Fiction\",\"Action\",\"Adventure\"]   \n",
       "\n",
       "                                               overview  avg_rating  \\\n",
       "80    When Dr. Indiana Jones  the tweed-suited prof...    8.481832   \n",
       "2291  Oscar Diggs, a small-time circus illusionist a...    4.867397   \n",
       "254   In 1933 New York, an overly ambitious movie pr...    6.616856   \n",
       "129   Bourne is brought out of hiding once again by ...    7.303784   \n",
       "2400  Lara Croft ventures to an underwater temple in...    4.088859   \n",
       "4888  When an alien with amazing powers crash-lands ...    6.557123   \n",
       "2585  New York detective John McClane is back and ki...    7.320188   \n",
       "2859  Animal pals Alex, Marty, Melman, and Gloria ar...    5.260902   \n",
       "3257  The Mystery Gang reunite and visit Moonscar Is...    7.123249   \n",
       "3731  Armed with the astonishing ability to shrink i...    6.396859   \n",
       "\n",
       "      rating_count  cosine_distance  \n",
       "80            3908          0.00000  \n",
       "2291          1644          0.00034  \n",
       "254           2195          0.00037  \n",
       "129           1850          0.00037  \n",
       "2400           754          0.00039  \n",
       "4888           709          0.00039  \n",
       "2585          1699          0.00040  \n",
       "2859          1330          0.00040  \n",
       "3257           714          0.00040  \n",
       "3731          4266          0.00041  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_similar_movies(df_for_gpt, X_gpt, NN_gpt, 'raiders-of-the-lost-ark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SXCtqxxjpHMb",
   "metadata": {
    "id": "SXCtqxxjpHMb"
   },
   "source": [
    "With the scope of finding similar movies, this model is definitely performing worse than BERT. BERT model provided several other Indiana Jones movies for us, as well as some other good adventure hero movies.\n",
    "\n",
    "There are still some decent suggestions here. I think King Kong is similar adventure action, lara croft is similar theme. However movies like madagascar 3 and scooby doo zombie island and even the top suggestion oz the great and powerful show that GPT isn't quite doing as consistent of a job understanding context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442c2ba",
   "metadata": {},
   "source": [
    "# Content Based Reccomendation Conclusion\n",
    "\n",
    "Though we were unable to perform quantitatitve evaluation of our models here, it is obvious that using the BERT transformer in Hugging Face allowed us to reccomend the most similar movies. Better than our GPT version, and certainly better than TF-IDF approach with our other numerical columsn such as release date, genre, popularity etc. \n",
    "\n",
    "This is may be due to the BERT transformer's ability to capture complex contextual relationships within the movie descriptions, enabling it to generate more accurate and contextually relevant recommendations. Its capacity to understand nuanced semantic meanings and similarities among movie plots likely surpassed the simpler methods like TF-IDF, which primarily focus on keyword frequencies. \n",
    "\n",
    "BERT stands for Bidirectional Encoder Representations from Transformers, and this Bidirectional nature may be the reason it outperformed GPT. Understanding of bidirectional context is crucial for understanding nuances in movie descriptions.\n",
    "\n",
    "The work we did here highlights the significance of leveraging transformer-based models like BERT for content-based recommendation systems, especially in contexts where understanding text nuances is crucial for accurate recommendations.\n",
    "\n",
    "\n",
    "# Next Steps\n",
    "* **Quantitative Evaluation**  - though our our best model was clear, using some metric such as a precision score could help us evaluate our model more objectively. However, it is hard to incorporate quanititative with our unsupervised reccomendation approach user here.\n",
    "* **Feature Consideration** - Rather than include all of our stock numerical factors in our models, I would like to look at including, scaling, and weighting some features individually. Features I would like to do this with:\n",
    "    * Genres\n",
    "    * Release Year\n",
    "* **Multi-Movie Consideration** - Rather than reccomend similar movies based on a single movie, I would like to see if we can get take a series of movies a user has enjoyed so that we can find them movies similar to the bunch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07dc74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0097bdb96fb14638ad6b6a0402c32639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40faf633c757434384d547d2d514c843",
      "placeholder": "",
      "style": "IPY_MODEL_e6634286cade4f27b7c80430ec5ff499",
      "value": " 440M/440M [00:08&lt;00:00, 51.7MB/s]"
     }
    },
    "01ea18352a4a425b8bd3dc18e9fdf2f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08bc8b6ca63e461197c16e14c3abcde8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0aeed3cfc49c49aea697fb38af187228": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abb60c9c134549489fcdd94edd75a9e7",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da9c43f2b1914214928a074d1d4eb232",
      "value": 1042301
     }
    },
    "0b3f2f83e8354f988321f11ef8ce396c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ceb8faa61ba490ebb9afd366c962ffd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1293d7e33c8a40578790afad29791e5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "167f54dc8ef64eb3b8117ddb7fb478a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92fd2292ef8b4e7ca9633f43c251fec2",
       "IPY_MODEL_fa72f8c89c26461bbf7d1d1be938b510",
       "IPY_MODEL_5f681bbf68984d8188f7277a6f42f641"
      ],
      "layout": "IPY_MODEL_995ca7336ae84f3d9100ddc796d0f8a4"
     }
    },
    "17b0e41c4b97468eb6ae844053facf59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bcd092ee3434014a948d0dfa6e88a67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c163bf0117a44aaa7c7cc9db8664375": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c7a0e282fea489f8298004000f1b804": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_835a9e8fdb4e4fcb864ed7edba2e0a99",
       "IPY_MODEL_0aeed3cfc49c49aea697fb38af187228",
       "IPY_MODEL_ba030df2970e472eacc4629dfcebf567"
      ],
      "layout": "IPY_MODEL_f3e28ffffa1141e2b1cd82ee3ded8635"
     }
    },
    "1c857e48a86541c3aa47c3bc9eebbd15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae8cad26821c4a94886a830adcc7a71f",
      "placeholder": "",
      "style": "IPY_MODEL_9a98df6bdb594d4d897926bd63329c65",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "212df07f193e4bfc8d40d2137594734c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "221df80acb4f45a9a61d0bbf49304348": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f7597e059bd4d97a68566245e375160",
      "placeholder": "",
      "style": "IPY_MODEL_a1f006322f2c4ad7b803ac032360c2ed",
      "value": "merges.txt: 100%"
     }
    },
    "24b8719d7e2f4a22851da4efff8d79bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27095043607b4435bd2a46a790469474": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27cd7054ec8f4bb89035d899c6cd74a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "290bbb0005d942b6af66df3bbf684cbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2a3d6895f842457da5af6f76b9f6d6ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ad777be710744d59bef328dcb788146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2bbf983010b14b57a12488b005526bd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c857e48a86541c3aa47c3bc9eebbd15",
       "IPY_MODEL_b9989b46ba5f454e9d989a509b45df53",
       "IPY_MODEL_49017e693a394253bc794f8ae6393f89"
      ],
      "layout": "IPY_MODEL_dbca2e3c6194421d9874aea3a416ba85"
     }
    },
    "2d9e7317666e44a388bf38ac381baee8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e64ef73f8924b4e8d7a1b4ee41e13e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "314cc8d49dd946c5843134380d06d39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0ddbe231e984fc485a4b1a73e780c2f",
      "placeholder": "",
      "style": "IPY_MODEL_2e64ef73f8924b4e8d7a1b4ee41e13e0",
      "value": "config.json: 100%"
     }
    },
    "31b3ee1d5fe84d53bb077bcba7353254": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "385edbca35a242d2b455263cf09ca71e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b80661d94a149bb937da9bf11a10ce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40faf633c757434384d547d2d514c843": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44660d24f76244c2b0e3e55ded179519": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08bc8b6ca63e461197c16e14c3abcde8",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7bb99f3a63ae476392c9240c78e6a31d",
      "value": 1355256
     }
    },
    "46a8354e3a084e86afe64ed8a9b6ae00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_625ed3cdc21d4aeea80e2c2a63f82db3",
      "placeholder": "",
      "style": "IPY_MODEL_f2ed7b8541a94459a8cadaecaecff9b6",
      "value": "tokenizer.json: 100%"
     }
    },
    "48f36f906a714a38a0bf8895c02f4b01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3aa7567016346b58396a718195819fa",
      "placeholder": "",
      "style": "IPY_MODEL_2ad777be710744d59bef328dcb788146",
      "value": " 548M/548M [00:05&lt;00:00, 106MB/s]"
     }
    },
    "49017e693a394253bc794f8ae6393f89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70fc1fea1f934eae8b703eb290460cf9",
      "placeholder": "",
      "style": "IPY_MODEL_d5ee10fd99eb4e9f913bb6eb51325b13",
      "value": " 28.0/28.0 [00:00&lt;00:00, 443B/s]"
     }
    },
    "4ab3e3584a68400ca3734c623857552a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c19bc709c474f9a9f4fb8c389c8db72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4ee2039250574c9dac5c811abecdedd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_221df80acb4f45a9a61d0bbf49304348",
       "IPY_MODEL_ddbf1e8ed3314cca842c37312dc702ee",
       "IPY_MODEL_fbec5cc6ce7742688d9bf46fe8f78576"
      ],
      "layout": "IPY_MODEL_b7daf8cf1b1447a3a54b64fb357cbf91"
     }
    },
    "58ced02798ba4a4bb439242d78da2e4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_812a59a982ed4b18b989c4554d5e0255",
       "IPY_MODEL_5ca725e476cf4463a71928f3514439b4",
       "IPY_MODEL_48f36f906a714a38a0bf8895c02f4b01"
      ],
      "layout": "IPY_MODEL_31b3ee1d5fe84d53bb077bcba7353254"
     }
    },
    "5ca725e476cf4463a71928f3514439b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9c39881a615487fbe597e5d39066ccb",
      "max": 548105171,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bc30697d347f477685a58e6ca9dbd734",
      "value": 548105171
     }
    },
    "5f681bbf68984d8188f7277a6f42f641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75830bb99e9a4b17b7dc173354d7719b",
      "placeholder": "",
      "style": "IPY_MODEL_b071f3f5b9684aa58f32fdb790c9ccf4",
      "value": " 665/665 [00:00&lt;00:00, 28.4kB/s]"
     }
    },
    "625ed3cdc21d4aeea80e2c2a63f82db3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62a30695146a410d8d2d216e4fa5d493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62ab81ef96434b5b9f7fccf0939a3a73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ab3e3584a68400ca3734c623857552a",
      "placeholder": "",
      "style": "IPY_MODEL_62a30695146a410d8d2d216e4fa5d493",
      "value": "tokenizer.json: 100%"
     }
    },
    "66db178a05034f1489e15e3995a98d8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27cd7054ec8f4bb89035d899c6cd74a6",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c3fa5c727f945ba8fa79c10db4873d9",
      "value": 440449768
     }
    },
    "683914a18dfe44c9b527be5d15c7889f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6aaac8fe66564d13900f7a640d697642": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c3fa5c727f945ba8fa79c10db4873d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "70dad2a045194258befc7483c9e8249d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5a77dd0dde44b8b8cb25ca0625495c6",
      "placeholder": "",
      "style": "IPY_MODEL_7cae2b09f1764cf9923ff928f04debc6",
      "value": "vocab.txt: 100%"
     }
    },
    "70fc1fea1f934eae8b703eb290460cf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "744b94435cdd4f96b7bc9f51d30ea73c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75830bb99e9a4b17b7dc173354d7719b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "784067dc1ec34e478b27e619974d72e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da7aa017905943169508891c71e7f9cb",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_290bbb0005d942b6af66df3bbf684cbe",
      "value": 231508
     }
    },
    "7bb99f3a63ae476392c9240c78e6a31d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7cae2b09f1764cf9923ff928f04debc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "812a59a982ed4b18b989c4554d5e0255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c163bf0117a44aaa7c7cc9db8664375",
      "placeholder": "",
      "style": "IPY_MODEL_683914a18dfe44c9b527be5d15c7889f",
      "value": "model.safetensors: 100%"
     }
    },
    "835a9e8fdb4e4fcb864ed7edba2e0a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ceb8faa61ba490ebb9afd366c962ffd",
      "placeholder": "",
      "style": "IPY_MODEL_0b3f2f83e8354f988321f11ef8ce396c",
      "value": "vocab.json: 100%"
     }
    },
    "8d7c979613214d259d1243000543ee8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e07b958b76247aab9d9b627223aea73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90f904a4319b41ffb3dfe5889ba5db60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70dad2a045194258befc7483c9e8249d",
       "IPY_MODEL_784067dc1ec34e478b27e619974d72e8",
       "IPY_MODEL_efc83b9245a748f5825bc66d2246e7c0"
      ],
      "layout": "IPY_MODEL_01ea18352a4a425b8bd3dc18e9fdf2f6"
     }
    },
    "92fd2292ef8b4e7ca9633f43c251fec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7ddf904b90044e9b15edeeabcb683fc",
      "placeholder": "",
      "style": "IPY_MODEL_8d7c979613214d259d1243000543ee8a",
      "value": "config.json: 100%"
     }
    },
    "9452a16256454e99bf8e798104474b19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94f23f4c065645b1aba999af816adaa7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9784318aecac40839350e1f83dedec51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97d1ded4b6a94f9ea94f22c30fd547ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2d0e81619b1455fa775701f5aa2fe47",
      "placeholder": "",
      "style": "IPY_MODEL_9452a16256454e99bf8e798104474b19",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 25.6MB/s]"
     }
    },
    "995ca7336ae84f3d9100ddc796d0f8a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99d5e44c9c4a4acc8d39d31a40581aba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9a5ea63e4994fc181ce1e0bff1242d4",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f66e0724e1f24f52ab0965f7c110efca",
      "value": 570
     }
    },
    "9a98df6bdb594d4d897926bd63329c65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b9de5eeb96b47deab49b97cdba5edfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cdd199b391d47a3aa077490ddc6ea9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b9de5eeb96b47deab49b97cdba5edfe",
      "placeholder": "",
      "style": "IPY_MODEL_f46c9e1547be443886c934f6b1c87765",
      "value": " 466k/466k [00:00&lt;00:00, 4.32MB/s]"
     }
    },
    "9d5a054aa2a546528f6bebb69ca17f60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bcd092ee3434014a948d0dfa6e88a67",
      "placeholder": "",
      "style": "IPY_MODEL_2a3d6895f842457da5af6f76b9f6d6ad",
      "value": " 570/570 [00:00&lt;00:00, 14.5kB/s]"
     }
    },
    "9d7f9c17f3b144f798c5d85e1b342ecf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e450458d3744198b451b0476ab1e453": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_314cc8d49dd946c5843134380d06d39d",
       "IPY_MODEL_99d5e44c9c4a4acc8d39d31a40581aba",
       "IPY_MODEL_9d5a054aa2a546528f6bebb69ca17f60"
      ],
      "layout": "IPY_MODEL_27095043607b4435bd2a46a790469474"
     }
    },
    "9f7597e059bd4d97a68566245e375160": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1df12bfebf542899e51f2aeb2d9f6f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_46a8354e3a084e86afe64ed8a9b6ae00",
       "IPY_MODEL_b2d7967b9d554cf387691920f0296bb8",
       "IPY_MODEL_9cdd199b391d47a3aa077490ddc6ea9e"
      ],
      "layout": "IPY_MODEL_1293d7e33c8a40578790afad29791e5a"
     }
    },
    "a1f006322f2c4ad7b803ac032360c2ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6b10bb9ea7f4660a85f1f929fdaf809": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a8cc96e980804af89f003635fe4c345f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62ab81ef96434b5b9f7fccf0939a3a73",
       "IPY_MODEL_44660d24f76244c2b0e3e55ded179519",
       "IPY_MODEL_97d1ded4b6a94f9ea94f22c30fd547ec"
      ],
      "layout": "IPY_MODEL_6aaac8fe66564d13900f7a640d697642"
     }
    },
    "a9c39881a615487fbe597e5d39066ccb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab5e454f57bc42a0bebc89b3b7e77eac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e07b958b76247aab9d9b627223aea73",
      "placeholder": "",
      "style": "IPY_MODEL_3b80661d94a149bb937da9bf11a10ce0",
      "value": "model.safetensors: 100%"
     }
    },
    "abb60c9c134549489fcdd94edd75a9e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae8cad26821c4a94886a830adcc7a71f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b071f3f5b9684aa58f32fdb790c9ccf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1d83eef0d3846db8bad51643103fd71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2d7967b9d554cf387691920f0296bb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9784318aecac40839350e1f83dedec51",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c19bc709c474f9a9f4fb8c389c8db72",
      "value": 466062
     }
    },
    "b7daf8cf1b1447a3a54b64fb357cbf91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9989b46ba5f454e9d989a509b45df53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d9e7317666e44a388bf38ac381baee8",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d641fb36b35a48348db0c0b7709f9bb2",
      "value": 28
     }
    },
    "ba030df2970e472eacc4629dfcebf567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94f23f4c065645b1aba999af816adaa7",
      "placeholder": "",
      "style": "IPY_MODEL_de2dc60febfd4a4fb50fcf69d9b76168",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 6.39MB/s]"
     }
    },
    "bc30697d347f477685a58e6ca9dbd734": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3aa7567016346b58396a718195819fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb8683e872f749feb1c11c89c6795da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab5e454f57bc42a0bebc89b3b7e77eac",
       "IPY_MODEL_66db178a05034f1489e15e3995a98d8b",
       "IPY_MODEL_0097bdb96fb14638ad6b6a0402c32639"
      ],
      "layout": "IPY_MODEL_9d7f9c17f3b144f798c5d85e1b342ecf"
     }
    },
    "d5ee10fd99eb4e9f913bb6eb51325b13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d641fb36b35a48348db0c0b7709f9bb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d78c7682c1e14a6fb5d4123e5d42f68e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7ddf904b90044e9b15edeeabcb683fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da7aa017905943169508891c71e7f9cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da9c43f2b1914214928a074d1d4eb232": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dbca2e3c6194421d9874aea3a416ba85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddbf1e8ed3314cca842c37312dc702ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_744b94435cdd4f96b7bc9f51d30ea73c",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1d83eef0d3846db8bad51643103fd71",
      "value": 456318
     }
    },
    "de2dc60febfd4a4fb50fcf69d9b76168": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0ddbe231e984fc485a4b1a73e780c2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6634286cade4f27b7c80430ec5ff499": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efc83b9245a748f5825bc66d2246e7c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24b8719d7e2f4a22851da4efff8d79bb",
      "placeholder": "",
      "style": "IPY_MODEL_d78c7682c1e14a6fb5d4123e5d42f68e",
      "value": " 232k/232k [00:00&lt;00:00, 2.47MB/s]"
     }
    },
    "f2d0e81619b1455fa775701f5aa2fe47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2ed7b8541a94459a8cadaecaecff9b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3e28ffffa1141e2b1cd82ee3ded8635": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f46c9e1547be443886c934f6b1c87765": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5a77dd0dde44b8b8cb25ca0625495c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f66e0724e1f24f52ab0965f7c110efca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9a5ea63e4994fc181ce1e0bff1242d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa72f8c89c26461bbf7d1d1be938b510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_212df07f193e4bfc8d40d2137594734c",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6b10bb9ea7f4660a85f1f929fdaf809",
      "value": 665
     }
    },
    "fbec5cc6ce7742688d9bf46fe8f78576": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17b0e41c4b97468eb6ae844053facf59",
      "placeholder": "",
      "style": "IPY_MODEL_385edbca35a242d2b455263cf09ca71e",
      "value": " 456k/456k [00:00&lt;00:00, 9.84MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
